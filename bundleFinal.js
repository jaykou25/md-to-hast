import proc from 'process';
import { fileURLToPath } from 'url';
import path$1 from 'path';

/**
 * Throw a given error.
 *
 * @param {Error|null|undefined} [error]
 *   Maybe error.
 * @returns {asserts error is null|undefined}
 */
function bail(error) {
  if (error) {
    throw error
  }
}

/*!
 * Determine if an object is a Buffer
 *
 * @author   Feross Aboukhadijeh <https://feross.org>
 * @license  MIT
 */

var isBuffer = function isBuffer (obj) {
  return obj != null && obj.constructor != null &&
    typeof obj.constructor.isBuffer === 'function' && obj.constructor.isBuffer(obj)
};

var hasOwn = Object.prototype.hasOwnProperty;
var toStr = Object.prototype.toString;
var defineProperty = Object.defineProperty;
var gOPD = Object.getOwnPropertyDescriptor;

var isArray = function isArray(arr) {
	if (typeof Array.isArray === 'function') {
		return Array.isArray(arr);
	}

	return toStr.call(arr) === '[object Array]';
};

var isPlainObject$1 = function isPlainObject(obj) {
	if (!obj || toStr.call(obj) !== '[object Object]') {
		return false;
	}

	var hasOwnConstructor = hasOwn.call(obj, 'constructor');
	var hasIsPrototypeOf = obj.constructor && obj.constructor.prototype && hasOwn.call(obj.constructor.prototype, 'isPrototypeOf');
	// Not own constructor property must be Object
	if (obj.constructor && !hasOwnConstructor && !hasIsPrototypeOf) {
		return false;
	}

	// Own properties are enumerated firstly, so to speed up,
	// if last one is own, then all properties are own.
	var key;
	for (key in obj) { /**/ }

	return typeof key === 'undefined' || hasOwn.call(obj, key);
};

// If name is '__proto__', and Object.defineProperty is available, define __proto__ as an own property on target
var setProperty = function setProperty(target, options) {
	if (defineProperty && options.name === '__proto__') {
		defineProperty(target, options.name, {
			enumerable: true,
			configurable: true,
			value: options.newValue,
			writable: true
		});
	} else {
		target[options.name] = options.newValue;
	}
};

// Return undefined instead of __proto__ if '__proto__' is not an own property
var getProperty = function getProperty(obj, name) {
	if (name === '__proto__') {
		if (!hasOwn.call(obj, name)) {
			return void 0;
		} else if (gOPD) {
			// In early versions of node, obj['__proto__'] is buggy when obj has
			// __proto__ as an own property. Object.getOwnPropertyDescriptor() works.
			return gOPD(obj, name).value;
		}
	}

	return obj[name];
};

var extend = function extend() {
	var options, name, src, copy, copyIsArray, clone;
	var target = arguments[0];
	var i = 1;
	var length = arguments.length;
	var deep = false;

	// Handle a deep copy situation
	if (typeof target === 'boolean') {
		deep = target;
		target = arguments[1] || {};
		// skip the boolean and the target
		i = 2;
	}
	if (target == null || (typeof target !== 'object' && typeof target !== 'function')) {
		target = {};
	}

	for (; i < length; ++i) {
		options = arguments[i];
		// Only deal with non-null/undefined values
		if (options != null) {
			// Extend the base object
			for (name in options) {
				src = getProperty(target, name);
				copy = getProperty(options, name);

				// Prevent never-ending loop
				if (target !== copy) {
					// Recurse if we're merging plain objects or arrays
					if (deep && copy && (isPlainObject$1(copy) || (copyIsArray = isArray(copy)))) {
						if (copyIsArray) {
							copyIsArray = false;
							clone = src && isArray(src) ? src : [];
						} else {
							clone = src && isPlainObject$1(src) ? src : {};
						}

						// Never move original objects, clone them
						setProperty(target, { name: name, newValue: extend(deep, clone, copy) });

					// Don't bring in undefined values
					} else if (typeof copy !== 'undefined') {
						setProperty(target, { name: name, newValue: copy });
					}
				}
			}
		}
	}

	// Return the modified object
	return target;
};

function isPlainObject(value) {
	if (typeof value !== 'object' || value === null) {
		return false;
	}

	const prototype = Object.getPrototypeOf(value);
	return (prototype === null || prototype === Object.prototype || Object.getPrototypeOf(prototype) === null) && !(Symbol.toStringTag in value) && !(Symbol.iterator in value);
}

/**
 * @typedef {(error?: Error|null|undefined, ...output: Array<any>) => void} Callback
 * @typedef {(...input: Array<any>) => any} Middleware
 *
 * @typedef {(...input: Array<any>) => void} Run
 *   Call all middleware.
 * @typedef {(fn: Middleware) => Pipeline} Use
 *   Add `fn` (middleware) to the list.
 * @typedef {{run: Run, use: Use}} Pipeline
 *   Middleware.
 */

/**
 * Create new middleware.
 *
 * @returns {Pipeline}
 */
function trough() {
  /** @type {Array<Middleware>} */
  const fns = [];
  /** @type {Pipeline} */
  const pipeline = {run, use};

  return pipeline

  /** @type {Run} */
  function run(...values) {
    let middlewareIndex = -1;
    /** @type {Callback} */
    const callback = values.pop();

    if (typeof callback !== 'function') {
      throw new TypeError('Expected function as last argument, not ' + callback)
    }

    next(null, ...values);

    /**
     * Run the next `fn`, or we‚Äôre done.
     *
     * @param {Error|null|undefined} error
     * @param {Array<any>} output
     */
    function next(error, ...output) {
      const fn = fns[++middlewareIndex];
      let index = -1;

      if (error) {
        callback(error);
        return
      }

      // Copy non-nullish input into values.
      while (++index < values.length) {
        if (output[index] === null || output[index] === undefined) {
          output[index] = values[index];
        }
      }

      // Save the newly created `output` for the next call.
      values = output;

      // Next or done.
      if (fn) {
        wrap$1(fn, next)(...output);
      } else {
        callback(null, ...output);
      }
    }
  }

  /** @type {Use} */
  function use(middelware) {
    if (typeof middelware !== 'function') {
      throw new TypeError(
        'Expected `middelware` to be a function, not ' + middelware
      )
    }

    fns.push(middelware);
    return pipeline
  }
}

/**
 * Wrap `middleware`.
 * Can be sync or async; return a promise, receive a callback, or return new
 * values and errors.
 *
 * @param {Middleware} middleware
 * @param {Callback} callback
 */
function wrap$1(middleware, callback) {
  /** @type {boolean} */
  let called;

  return wrapped

  /**
   * Call `middleware`.
   * @this {any}
   * @param {Array<any>} parameters
   * @returns {void}
   */
  function wrapped(...parameters) {
    const fnExpectsCallback = middleware.length > parameters.length;
    /** @type {any} */
    let result;

    if (fnExpectsCallback) {
      parameters.push(done);
    }

    try {
      result = middleware.apply(this, parameters);
    } catch (error) {
      const exception = /** @type {Error} */ (error);

      // Well, this is quite the pickle.
      // `middleware` received a callback and called it synchronously, but that
      // threw an error.
      // The only thing left to do is to throw the thing instead.
      if (fnExpectsCallback && called) {
        throw exception
      }

      return done(exception)
    }

    if (!fnExpectsCallback) {
      if (result instanceof Promise) {
        result.then(then, done);
      } else if (result instanceof Error) {
        done(result);
      } else {
        then(result);
      }
    }
  }

  /**
   * Call `callback`, only once.
   * @type {Callback}
   */
  function done(error, ...output) {
    if (!called) {
      called = true;
      callback(error, ...output);
    }
  }

  /**
   * Call `done` with one value.
   *
   * @param {any} [value]
   */
  function then(value) {
    done(null, value);
  }
}

/**
 * @typedef {import('unist').Node} Node
 * @typedef {import('unist').Point} Point
 * @typedef {import('unist').Position} Position
 */

/**
 * @typedef NodeLike
 * @property {string} type
 * @property {PositionLike | null | undefined} [position]
 *
 * @typedef PositionLike
 * @property {PointLike | null | undefined} [start]
 * @property {PointLike | null | undefined} [end]
 *
 * @typedef PointLike
 * @property {number | null | undefined} [line]
 * @property {number | null | undefined} [column]
 * @property {number | null | undefined} [offset]
 */

/**
 * Serialize the positional info of a point, position (start and end points),
 * or node.
 *
 * @param {Node | NodeLike | Position | PositionLike | Point | PointLike | null | undefined} [value]
 *   Node, position, or point.
 * @returns {string}
 *   Pretty printed positional info of a node (`string`).
 *
 *   In the format of a range `ls:cs-le:ce` (when given `node` or `position`)
 *   or a point `l:c` (when given `point`), where `l` stands for line, `c` for
 *   column, `s` for `start`, and `e` for end.
 *   An empty string (`''`) is returned if the given value is neither `node`,
 *   `position`, nor `point`.
 */
function stringifyPosition(value) {
  // Nothing.
  if (!value || typeof value !== 'object') {
    return ''
  }

  // Node.
  if ('position' in value || 'type' in value) {
    return position$1(value.position)
  }

  // Position.
  if ('start' in value || 'end' in value) {
    return position$1(value)
  }

  // Point.
  if ('line' in value || 'column' in value) {
    return point$2(value)
  }

  // ?
  return ''
}

/**
 * @param {Point | PointLike | null | undefined} point
 * @returns {string}
 */
function point$2(point) {
  return index(point && point.line) + ':' + index(point && point.column)
}

/**
 * @param {Position | PositionLike | null | undefined} pos
 * @returns {string}
 */
function position$1(pos) {
  return point$2(pos && pos.start) + '-' + point$2(pos && pos.end)
}

/**
 * @param {number | null | undefined} value
 * @returns {number}
 */
function index(value) {
  return value && typeof value === 'number' ? value : 1
}

/**
 * @typedef {import('unist').Node} Node
 * @typedef {import('unist').Position} Position
 * @typedef {import('unist').Point} Point
 * @typedef {object & {type: string, position?: Position | undefined}} NodeLike
 */

/**
 * Message.
 */
class VFileMessage extends Error {
  /**
   * Create a message for `reason` at `place` from `origin`.
   *
   * When an error is passed in as `reason`, the `stack` is copied.
   *
   * @param {string | Error | VFileMessage} reason
   *   Reason for message, uses the stack and message of the error if given.
   *
   *   > üëâ **Note**: you should use markdown.
   * @param {Node | NodeLike | Position | Point | null | undefined} [place]
   *   Place in file where the message occurred.
   * @param {string | null | undefined} [origin]
   *   Place in code where the message originates (example:
   *   `'my-package:my-rule'` or `'my-rule'`).
   * @returns
   *   Instance of `VFileMessage`.
   */
  // To do: next major: expose `undefined` everywhere instead of `null`.
  constructor(reason, place, origin) {
    /** @type {[string | null, string | null]} */
    const parts = [null, null];
    /** @type {Position} */
    let position = {
      // @ts-expect-error: we always follows the structure of `position`.
      start: {line: null, column: null},
      // @ts-expect-error: "
      end: {line: null, column: null}
    };

    super();

    if (typeof place === 'string') {
      origin = place;
      place = undefined;
    }

    if (typeof origin === 'string') {
      const index = origin.indexOf(':');

      if (index === -1) {
        parts[1] = origin;
      } else {
        parts[0] = origin.slice(0, index);
        parts[1] = origin.slice(index + 1);
      }
    }

    if (place) {
      // Node.
      if ('type' in place || 'position' in place) {
        if (place.position) {
          // To do: next major: deep clone.
          // @ts-expect-error: looks like a position.
          position = place.position;
        }
      }
      // Position.
      else if ('start' in place || 'end' in place) {
        // @ts-expect-error: looks like a position.
        // To do: next major: deep clone.
        position = place;
      }
      // Point.
      else if ('line' in place || 'column' in place) {
        // To do: next major: deep clone.
        position.start = place;
      }
    }

    // Fields from `Error`.
    /**
     * Serialized positional info of error.
     *
     * On normal errors, this would be something like `ParseError`, buit in
     * `VFile` messages we use this space to show where an error happened.
     */
    this.name = stringifyPosition(place) || '1:1';

    /**
     * Reason for message.
     *
     * @type {string}
     */
    this.message = typeof reason === 'object' ? reason.message : reason;

    /**
     * Stack of message.
     *
     * This is used by normal errors to show where something happened in
     * programming code, irrelevant for `VFile` messages,
     *
     * @type {string}
     */
    this.stack = '';

    if (typeof reason === 'object' && reason.stack) {
      this.stack = reason.stack;
    }

    /**
     * Reason for message.
     *
     * > üëâ **Note**: you should use markdown.
     *
     * @type {string}
     */
    this.reason = this.message;

    /* eslint-disable no-unused-expressions */
    /**
     * State of problem.
     *
     * * `true` ‚Äî marks associated file as no longer processable (error)
     * * `false` ‚Äî necessitates a (potential) change (warning)
     * * `null | undefined` ‚Äî for things that might not need changing (info)
     *
     * @type {boolean | null | undefined}
     */
    this.fatal;

    /**
     * Starting line of error.
     *
     * @type {number | null}
     */
    this.line = position.start.line;

    /**
     * Starting column of error.
     *
     * @type {number | null}
     */
    this.column = position.start.column;

    /**
     * Full unist position.
     *
     * @type {Position | null}
     */
    this.position = position;

    /**
     * Namespace of message (example: `'my-package'`).
     *
     * @type {string | null}
     */
    this.source = parts[0];

    /**
     * Category of message (example: `'my-rule'`).
     *
     * @type {string | null}
     */
    this.ruleId = parts[1];

    /**
     * Path of a file (used throughout the `VFile` ecosystem).
     *
     * @type {string | null}
     */
    this.file;

    // The following fields are ‚Äúwell known‚Äù.
    // Not standard.
    // Feel free to add other non-standard fields to your messages.

    /**
     * Specify the source value that‚Äôs being reported, which is deemed
     * incorrect.
     *
     * @type {string | null}
     */
    this.actual;

    /**
     * Suggest acceptable values that can be used instead of `actual`.
     *
     * @type {Array<string> | null}
     */
    this.expected;

    /**
     * Link to docs for the message.
     *
     * > üëâ **Note**: this must be an absolute URL that can be passed as `x`
     * > to `new URL(x)`.
     *
     * @type {string | null}
     */
    this.url;

    /**
     * Long form description of the message (you should use markdown).
     *
     * @type {string | null}
     */
    this.note;
    /* eslint-enable no-unused-expressions */
  }
}

VFileMessage.prototype.file = '';
VFileMessage.prototype.name = '';
VFileMessage.prototype.reason = '';
VFileMessage.prototype.message = '';
VFileMessage.prototype.stack = '';
VFileMessage.prototype.fatal = null;
VFileMessage.prototype.column = null;
VFileMessage.prototype.line = null;
VFileMessage.prototype.source = null;
VFileMessage.prototype.ruleId = null;
VFileMessage.prototype.position = null;

/**
 * @typedef URL
 * @property {string} hash
 * @property {string} host
 * @property {string} hostname
 * @property {string} href
 * @property {string} origin
 * @property {string} password
 * @property {string} pathname
 * @property {string} port
 * @property {string} protocol
 * @property {string} search
 * @property {any} searchParams
 * @property {string} username
 * @property {() => string} toString
 * @property {() => string} toJSON
 */

/**
 * Check if `fileUrlOrPath` looks like a URL.
 *
 * @param {unknown} fileUrlOrPath
 *   File path or URL.
 * @returns {fileUrlOrPath is URL}
 *   Whether it‚Äôs a URL.
 */
// From: <https://github.com/nodejs/node/blob/fcf8ba4/lib/internal/url.js#L1501>
function isUrl(fileUrlOrPath) {
  return (
    fileUrlOrPath !== null &&
    typeof fileUrlOrPath === 'object' &&
    // @ts-expect-error: indexable.
    fileUrlOrPath.href &&
    // @ts-expect-error: indexable.
    fileUrlOrPath.origin
  )
}

/**
 * @typedef {import('unist').Node} Node
 * @typedef {import('unist').Position} Position
 * @typedef {import('unist').Point} Point
 * @typedef {import('./minurl.shared.js').URL} URL
 * @typedef {import('../index.js').Data} Data
 * @typedef {import('../index.js').Value} Value
 */

/**
 * Order of setting (least specific to most), we need this because otherwise
 * `{stem: 'a', path: '~/b.js'}` would throw, as a path is needed before a
 * stem can be set.
 *
 * @type {Array<'basename' | 'dirname' | 'extname' | 'history' | 'path' | 'stem'>}
 */
const order = ['history', 'path', 'basename', 'stem', 'extname', 'dirname'];

class VFile {
  /**
   * Create a new virtual file.
   *
   * `options` is treated as:
   *
   * *   `string` or `Buffer` ‚Äî `{value: options}`
   * *   `URL` ‚Äî `{path: options}`
   * *   `VFile` ‚Äî shallow copies its data over to the new file
   * *   `object` ‚Äî all fields are shallow copied over to the new file
   *
   * Path related fields are set in the following order (least specific to
   * most specific): `history`, `path`, `basename`, `stem`, `extname`,
   * `dirname`.
   *
   * You cannot set `dirname` or `extname` without setting either `history`,
   * `path`, `basename`, or `stem` too.
   *
   * @param {Compatible | null | undefined} [value]
   *   File value.
   * @returns
   *   New instance.
   */
  constructor(value) {
    /** @type {Options | VFile} */
    let options;

    if (!value) {
      options = {};
    } else if (typeof value === 'string' || buffer(value)) {
      options = {value};
    } else if (isUrl(value)) {
      options = {path: value};
    } else {
      options = value;
    }

    /**
     * Place to store custom information (default: `{}`).
     *
     * It‚Äôs OK to store custom data directly on the file but moving it to
     * `data` is recommended.
     *
     * @type {Data}
     */
    this.data = {};

    /**
     * List of messages associated with the file.
     *
     * @type {Array<VFileMessage>}
     */
    this.messages = [];

    /**
     * List of filepaths the file moved between.
     *
     * The first is the original path and the last is the current path.
     *
     * @type {Array<string>}
     */
    this.history = [];

    /**
     * Base of `path` (default: `process.cwd()` or `'/'` in browsers).
     *
     * @type {string}
     */
    this.cwd = proc.cwd();

    /* eslint-disable no-unused-expressions */
    /**
     * Raw value.
     *
     * @type {Value}
     */
    this.value;

    // The below are non-standard, they are ‚Äúwell-known‚Äù.
    // As in, used in several tools.

    /**
     * Whether a file was saved to disk.
     *
     * This is used by vfile reporters.
     *
     * @type {boolean}
     */
    this.stored;

    /**
     * Custom, non-string, compiled, representation.
     *
     * This is used by unified to store non-string results.
     * One example is when turning markdown into React nodes.
     *
     * @type {unknown}
     */
    this.result;

    /**
     * Source map.
     *
     * This type is equivalent to the `RawSourceMap` type from the `source-map`
     * module.
     *
     * @type {Map | null | undefined}
     */
    this.map;
    /* eslint-enable no-unused-expressions */

    // Set path related properties in the correct order.
    let index = -1;

    while (++index < order.length) {
      const prop = order[index];

      // Note: we specifically use `in` instead of `hasOwnProperty` to accept
      // `vfile`s too.
      if (
        prop in options &&
        options[prop] !== undefined &&
        options[prop] !== null
      ) {
        // @ts-expect-error: TS doesn‚Äôt understand basic reality.
        this[prop] = prop === 'history' ? [...options[prop]] : options[prop];
      }
    }

    /** @type {string} */
    let prop;

    // Set non-path related properties.
    for (prop in options) {
      // @ts-expect-error: fine to set other things.
      if (!order.includes(prop)) {
        // @ts-expect-error: fine to set other things.
        this[prop] = options[prop];
      }
    }
  }

  /**
   * Get the full path (example: `'~/index.min.js'`).
   *
   * @returns {string}
   */
  get path() {
    return this.history[this.history.length - 1]
  }

  /**
   * Set the full path (example: `'~/index.min.js'`).
   *
   * Cannot be nullified.
   * You can set a file URL (a `URL` object with a `file:` protocol) which will
   * be turned into a path with `url.fileURLToPath`.
   *
   * @param {string | URL} path
   */
  set path(path) {
    if (isUrl(path)) {
      path = fileURLToPath(path);
    }

    assertNonEmpty(path, 'path');

    if (this.path !== path) {
      this.history.push(path);
    }
  }

  /**
   * Get the parent path (example: `'~'`).
   */
  get dirname() {
    return typeof this.path === 'string' ? path$1.dirname(this.path) : undefined
  }

  /**
   * Set the parent path (example: `'~'`).
   *
   * Cannot be set if there‚Äôs no `path` yet.
   */
  set dirname(dirname) {
    assertPath(this.basename, 'dirname');
    this.path = path$1.join(dirname || '', this.basename);
  }

  /**
   * Get the basename (including extname) (example: `'index.min.js'`).
   */
  get basename() {
    return typeof this.path === 'string' ? path$1.basename(this.path) : undefined
  }

  /**
   * Set basename (including extname) (`'index.min.js'`).
   *
   * Cannot contain path separators (`'/'` on unix, macOS, and browsers, `'\'`
   * on windows).
   * Cannot be nullified (use `file.path = file.dirname` instead).
   */
  set basename(basename) {
    assertNonEmpty(basename, 'basename');
    assertPart(basename, 'basename');
    this.path = path$1.join(this.dirname || '', basename);
  }

  /**
   * Get the extname (including dot) (example: `'.js'`).
   */
  get extname() {
    return typeof this.path === 'string' ? path$1.extname(this.path) : undefined
  }

  /**
   * Set the extname (including dot) (example: `'.js'`).
   *
   * Cannot contain path separators (`'/'` on unix, macOS, and browsers, `'\'`
   * on windows).
   * Cannot be set if there‚Äôs no `path` yet.
   */
  set extname(extname) {
    assertPart(extname, 'extname');
    assertPath(this.dirname, 'extname');

    if (extname) {
      if (extname.charCodeAt(0) !== 46 /* `.` */) {
        throw new Error('`extname` must start with `.`')
      }

      if (extname.includes('.', 1)) {
        throw new Error('`extname` cannot contain multiple dots')
      }
    }

    this.path = path$1.join(this.dirname, this.stem + (extname || ''));
  }

  /**
   * Get the stem (basename w/o extname) (example: `'index.min'`).
   */
  get stem() {
    return typeof this.path === 'string'
      ? path$1.basename(this.path, this.extname)
      : undefined
  }

  /**
   * Set the stem (basename w/o extname) (example: `'index.min'`).
   *
   * Cannot contain path separators (`'/'` on unix, macOS, and browsers, `'\'`
   * on windows).
   * Cannot be nullified (use `file.path = file.dirname` instead).
   */
  set stem(stem) {
    assertNonEmpty(stem, 'stem');
    assertPart(stem, 'stem');
    this.path = path$1.join(this.dirname || '', stem + (this.extname || ''));
  }

  /**
   * Serialize the file.
   *
   * @param {BufferEncoding | null | undefined} [encoding='utf8']
   *   Character encoding to understand `value` as when it‚Äôs a `Buffer`
   *   (default: `'utf8'`).
   * @returns {string}
   *   Serialized file.
   */
  toString(encoding) {
    return (this.value || '').toString(encoding || undefined)
  }

  /**
   * Create a warning message associated with the file.
   *
   * Its `fatal` is set to `false` and `file` is set to the current file path.
   * Its added to `file.messages`.
   *
   * @param {string | Error | VFileMessage} reason
   *   Reason for message, uses the stack and message of the error if given.
   * @param {Node | NodeLike | Position | Point | null | undefined} [place]
   *   Place in file where the message occurred.
   * @param {string | null | undefined} [origin]
   *   Place in code where the message originates (example:
   *   `'my-package:my-rule'` or `'my-rule'`).
   * @returns {VFileMessage}
   *   Message.
   */
  message(reason, place, origin) {
    const message = new VFileMessage(reason, place, origin);

    if (this.path) {
      message.name = this.path + ':' + message.name;
      message.file = this.path;
    }

    message.fatal = false;

    this.messages.push(message);

    return message
  }

  /**
   * Create an info message associated with the file.
   *
   * Its `fatal` is set to `null` and `file` is set to the current file path.
   * Its added to `file.messages`.
   *
   * @param {string | Error | VFileMessage} reason
   *   Reason for message, uses the stack and message of the error if given.
   * @param {Node | NodeLike | Position | Point | null | undefined} [place]
   *   Place in file where the message occurred.
   * @param {string | null | undefined} [origin]
   *   Place in code where the message originates (example:
   *   `'my-package:my-rule'` or `'my-rule'`).
   * @returns {VFileMessage}
   *   Message.
   */
  info(reason, place, origin) {
    const message = this.message(reason, place, origin);

    message.fatal = null;

    return message
  }

  /**
   * Create a fatal error associated with the file.
   *
   * Its `fatal` is set to `true` and `file` is set to the current file path.
   * Its added to `file.messages`.
   *
   * > üëâ **Note**: a fatal error means that a file is no longer processable.
   *
   * @param {string | Error | VFileMessage} reason
   *   Reason for message, uses the stack and message of the error if given.
   * @param {Node | NodeLike | Position | Point | null | undefined} [place]
   *   Place in file where the message occurred.
   * @param {string | null | undefined} [origin]
   *   Place in code where the message originates (example:
   *   `'my-package:my-rule'` or `'my-rule'`).
   * @returns {never}
   *   Message.
   * @throws {VFileMessage}
   *   Message.
   */
  fail(reason, place, origin) {
    const message = this.message(reason, place, origin);

    message.fatal = true;

    throw message
  }
}

/**
 * Assert that `part` is not a path (as in, does not contain `path.sep`).
 *
 * @param {string | null | undefined} part
 *   File path part.
 * @param {string} name
 *   Part name.
 * @returns {void}
 *   Nothing.
 */
function assertPart(part, name) {
  if (part && part.includes(path$1.sep)) {
    throw new Error(
      '`' + name + '` cannot be a path: did not expect `' + path$1.sep + '`'
    )
  }
}

/**
 * Assert that `part` is not empty.
 *
 * @param {string | undefined} part
 *   Thing.
 * @param {string} name
 *   Part name.
 * @returns {asserts part is string}
 *   Nothing.
 */
function assertNonEmpty(part, name) {
  if (!part) {
    throw new Error('`' + name + '` cannot be empty')
  }
}

/**
 * Assert `path` exists.
 *
 * @param {string | undefined} path
 *   Path.
 * @param {string} name
 *   Dependency name.
 * @returns {asserts path is string}
 *   Nothing.
 */
function assertPath(path, name) {
  if (!path) {
    throw new Error('Setting `' + name + '` requires `path` to be set too')
  }
}

/**
 * Assert `value` is a buffer.
 *
 * @param {unknown} value
 *   thing.
 * @returns {value is Buffer}
 *   Whether `value` is a Node.js buffer.
 */
function buffer(value) {
  return isBuffer(value)
}

/**
 * @typedef {import('unist').Node} Node
 * @typedef {import('vfile').VFileCompatible} VFileCompatible
 * @typedef {import('vfile').VFileValue} VFileValue
 * @typedef {import('..').Processor} Processor
 * @typedef {import('..').Plugin} Plugin
 * @typedef {import('..').Preset} Preset
 * @typedef {import('..').Pluggable} Pluggable
 * @typedef {import('..').PluggableList} PluggableList
 * @typedef {import('..').Transformer} Transformer
 * @typedef {import('..').Parser} Parser
 * @typedef {import('..').Compiler} Compiler
 * @typedef {import('..').RunCallback} RunCallback
 * @typedef {import('..').ProcessCallback} ProcessCallback
 *
 * @typedef Context
 * @property {Node} tree
 * @property {VFile} file
 */

// Expose a frozen processor.
const unified = base().freeze();

const own$7 = {}.hasOwnProperty;

// Function to create the first processor.
/**
 * @returns {Processor}
 */
function base() {
  const transformers = trough();
  /** @type {Processor['attachers']} */
  const attachers = [];
  /** @type {Record<string, unknown>} */
  let namespace = {};
  /** @type {boolean|undefined} */
  let frozen;
  let freezeIndex = -1;

  // Data management.
  // @ts-expect-error: overloads are handled.
  processor.data = data;
  processor.Parser = undefined;
  processor.Compiler = undefined;

  // Lock.
  processor.freeze = freeze;

  // Plugins.
  processor.attachers = attachers;
  // @ts-expect-error: overloads are handled.
  processor.use = use;

  // API.
  processor.parse = parse;
  processor.stringify = stringify;
  // @ts-expect-error: overloads are handled.
  processor.run = run;
  processor.runSync = runSync;
  // @ts-expect-error: overloads are handled.
  processor.process = process;
  processor.processSync = processSync;

  // Expose.
  return processor

  // Create a new processor based on the processor in the current scope.
  /** @type {Processor} */
  function processor() {
    const destination = base();
    let index = -1;

    while (++index < attachers.length) {
      destination.use(...attachers[index]);
    }

    destination.data(extend(true, {}, namespace));

    return destination
  }

  /**
   * @param {string|Record<string, unknown>} [key]
   * @param {unknown} [value]
   * @returns {unknown}
   */
  function data(key, value) {
    if (typeof key === 'string') {
      // Set `key`.
      if (arguments.length === 2) {
        assertUnfrozen('data', frozen);
        namespace[key] = value;
        return processor
      }

      // Get `key`.
      return (own$7.call(namespace, key) && namespace[key]) || null
    }

    // Set space.
    if (key) {
      assertUnfrozen('data', frozen);
      namespace = key;
      return processor
    }

    // Get space.
    return namespace
  }

  /** @type {Processor['freeze']} */
  function freeze() {
    if (frozen) {
      return processor
    }

    while (++freezeIndex < attachers.length) {
      const [attacher, ...options] = attachers[freezeIndex];

      if (options[0] === false) {
        continue
      }

      if (options[0] === true) {
        options[0] = undefined;
      }

      /** @type {Transformer|void} */
      const transformer = attacher.call(processor, ...options);

      if (typeof transformer === 'function') {
        transformers.use(transformer);
      }
    }

    frozen = true;
    freezeIndex = Number.POSITIVE_INFINITY;

    return processor
  }

  /**
   * @param {Pluggable|null|undefined} [value]
   * @param {...unknown} options
   * @returns {Processor}
   */
  function use(value, ...options) {
    /** @type {Record<string, unknown>|undefined} */
    let settings;

    assertUnfrozen('use', frozen);

    if (value === null || value === undefined) ; else if (typeof value === 'function') {
      addPlugin(value, ...options);
    } else if (typeof value === 'object') {
      if (Array.isArray(value)) {
        addList(value);
      } else {
        addPreset(value);
      }
    } else {
      throw new TypeError('Expected usable value, not `' + value + '`')
    }

    if (settings) {
      namespace.settings = Object.assign(namespace.settings || {}, settings);
    }

    return processor

    /**
     * @param {import('..').Pluggable<unknown[]>} value
     * @returns {void}
     */
    function add(value) {
      if (typeof value === 'function') {
        addPlugin(value);
      } else if (typeof value === 'object') {
        if (Array.isArray(value)) {
          const [plugin, ...options] = value;
          addPlugin(plugin, ...options);
        } else {
          addPreset(value);
        }
      } else {
        throw new TypeError('Expected usable value, not `' + value + '`')
      }
    }

    /**
     * @param {Preset} result
     * @returns {void}
     */
    function addPreset(result) {
      addList(result.plugins);

      if (result.settings) {
        settings = Object.assign(settings || {}, result.settings);
      }
    }

    /**
     * @param {PluggableList|null|undefined} [plugins]
     * @returns {void}
     */
    function addList(plugins) {
      let index = -1;

      if (plugins === null || plugins === undefined) ; else if (Array.isArray(plugins)) {
        while (++index < plugins.length) {
          const thing = plugins[index];
          add(thing);
        }
      } else {
        throw new TypeError('Expected a list of plugins, not `' + plugins + '`')
      }
    }

    /**
     * @param {Plugin} plugin
     * @param {...unknown} [value]
     * @returns {void}
     */
    function addPlugin(plugin, value) {
      let index = -1;
      /** @type {Processor['attachers'][number]|undefined} */
      let entry;

      while (++index < attachers.length) {
        if (attachers[index][0] === plugin) {
          entry = attachers[index];
          break
        }
      }

      if (entry) {
        if (isPlainObject(entry[1]) && isPlainObject(value)) {
          value = extend(true, entry[1], value);
        }

        entry[1] = value;
      } else {
        // @ts-expect-error: fine.
        attachers.push([...arguments]);
      }
    }
  }

  /** @type {Processor['parse']} */
  function parse(doc) {
    processor.freeze();
    const file = vfile(doc);
    const Parser = processor.Parser;
    assertParser('parse', Parser);

    if (newable(Parser, 'parse')) {
      // @ts-expect-error: `newable` checks this.
      return new Parser(String(file), file).parse()
    }

    // @ts-expect-error: `newable` checks this.
    return Parser(String(file), file) // eslint-disable-line new-cap
  }

  /** @type {Processor['stringify']} */
  function stringify(node, doc) {
    processor.freeze();
    const file = vfile(doc);
    const Compiler = processor.Compiler;
    assertCompiler('stringify', Compiler);
    assertNode(node);

    if (newable(Compiler, 'compile')) {
      // @ts-expect-error: `newable` checks this.
      return new Compiler(node, file).compile()
    }

    // @ts-expect-error: `newable` checks this.
    return Compiler(node, file) // eslint-disable-line new-cap
  }

  /**
   * @param {Node} node
   * @param {VFileCompatible|RunCallback} [doc]
   * @param {RunCallback} [callback]
   * @returns {Promise<Node>|void}
   */
  function run(node, doc, callback) {
    assertNode(node);
    processor.freeze();

    if (!callback && typeof doc === 'function') {
      callback = doc;
      doc = undefined;
    }

    if (!callback) {
      return new Promise(executor)
    }

    executor(null, callback);

    /**
     * @param {null|((node: Node) => void)} resolve
     * @param {(error: Error) => void} reject
     * @returns {void}
     */
    function executor(resolve, reject) {
      // @ts-expect-error: `doc` can‚Äôt be a callback anymore, we checked.
      transformers.run(node, vfile(doc), done);

      /**
       * @param {Error|null} error
       * @param {Node} tree
       * @param {VFile} file
       * @returns {void}
       */
      function done(error, tree, file) {
        tree = tree || node;
        if (error) {
          reject(error);
        } else if (resolve) {
          resolve(tree);
        } else {
          // @ts-expect-error: `callback` is defined if `resolve` is not.
          callback(null, tree, file);
        }
      }
    }
  }

  /** @type {Processor['runSync']} */
  function runSync(node, file) {
    /** @type {Node|undefined} */
    let result;
    /** @type {boolean|undefined} */
    let complete;

    processor.run(node, file, done);

    assertDone('runSync', 'run', complete);

    // @ts-expect-error: we either bailed on an error or have a tree.
    return result

    /**
     * @param {Error|null} [error]
     * @param {Node} [tree]
     * @returns {void}
     */
    function done(error, tree) {
      bail(error);
      result = tree;
      complete = true;
    }
  }

  /**
   * @param {VFileCompatible} doc
   * @param {ProcessCallback} [callback]
   * @returns {Promise<VFile>|undefined}
   */
  function process(doc, callback) {
    processor.freeze();
    assertParser('process', processor.Parser);
    assertCompiler('process', processor.Compiler);

    if (!callback) {
      return new Promise(executor)
    }

    executor(null, callback);

    /**
     * @param {null|((file: VFile) => void)} resolve
     * @param {(error?: Error|null|undefined) => void} reject
     * @returns {void}
     */
    function executor(resolve, reject) {
      const file = vfile(doc);

      processor.run(processor.parse(file), file, (error, tree, file) => {
        if (error || !tree || !file) {
          done(error);
        } else {
          /** @type {unknown} */
          const result = processor.stringify(tree, file);

          if (result === undefined || result === null) ; else if (looksLikeAVFileValue(result)) {
            file.value = result;
          } else {
            file.result = result;
          }

          done(error, file);
        }
      });

      /**
       * @param {Error|null|undefined} [error]
       * @param {VFile|undefined} [file]
       * @returns {void}
       */
      function done(error, file) {
        if (error || !file) {
          reject(error);
        } else if (resolve) {
          resolve(file);
        } else {
          // @ts-expect-error: `callback` is defined if `resolve` is not.
          callback(null, file);
        }
      }
    }
  }

  /** @type {Processor['processSync']} */
  function processSync(doc) {
    /** @type {boolean|undefined} */
    let complete;

    processor.freeze();
    assertParser('processSync', processor.Parser);
    assertCompiler('processSync', processor.Compiler);

    const file = vfile(doc);

    processor.process(file, done);

    assertDone('processSync', 'process', complete);

    return file

    /**
     * @param {Error|null|undefined} [error]
     * @returns {void}
     */
    function done(error) {
      complete = true;
      bail(error);
    }
  }
}

/**
 * Check if `value` is a constructor.
 *
 * @param {unknown} value
 * @param {string} name
 * @returns {boolean}
 */
function newable(value, name) {
  return (
    typeof value === 'function' &&
    // Prototypes do exist.
    // type-coverage:ignore-next-line
    value.prototype &&
    // A function with keys in its prototype is probably a constructor.
    // Classes‚Äô prototype methods are not enumerable, so we check if some value
    // exists in the prototype.
    // type-coverage:ignore-next-line
    (keys(value.prototype) || name in value.prototype)
  )
}

/**
 * Check if `value` is an object with keys.
 *
 * @param {Record<string, unknown>} value
 * @returns {boolean}
 */
function keys(value) {
  /** @type {string} */
  let key;

  for (key in value) {
    if (own$7.call(value, key)) {
      return true
    }
  }

  return false
}

/**
 * Assert a parser is available.
 *
 * @param {string} name
 * @param {unknown} value
 * @returns {asserts value is Parser}
 */
function assertParser(name, value) {
  if (typeof value !== 'function') {
    throw new TypeError('Cannot `' + name + '` without `Parser`')
  }
}

/**
 * Assert a compiler is available.
 *
 * @param {string} name
 * @param {unknown} value
 * @returns {asserts value is Compiler}
 */
function assertCompiler(name, value) {
  if (typeof value !== 'function') {
    throw new TypeError('Cannot `' + name + '` without `Compiler`')
  }
}

/**
 * Assert the processor is not frozen.
 *
 * @param {string} name
 * @param {unknown} frozen
 * @returns {asserts frozen is false}
 */
function assertUnfrozen(name, frozen) {
  if (frozen) {
    throw new Error(
      'Cannot call `' +
        name +
        '` on a frozen processor.\nCreate a new processor first, by calling it: use `processor()` instead of `processor`.'
    )
  }
}

/**
 * Assert `node` is a unist node.
 *
 * @param {unknown} node
 * @returns {asserts node is Node}
 */
function assertNode(node) {
  // `isPlainObj` unfortunately uses `any` instead of `unknown`.
  // type-coverage:ignore-next-line
  if (!isPlainObject(node) || typeof node.type !== 'string') {
    throw new TypeError('Expected node, got `' + node + '`')
    // Fine.
  }
}

/**
 * Assert that `complete` is `true`.
 *
 * @param {string} name
 * @param {string} asyncName
 * @param {unknown} complete
 * @returns {asserts complete is true}
 */
function assertDone(name, asyncName, complete) {
  if (!complete) {
    throw new Error(
      '`' + name + '` finished async. Use `' + asyncName + '` instead'
    )
  }
}

/**
 * @param {VFileCompatible} [value]
 * @returns {VFile}
 */
function vfile(value) {
  return looksLikeAVFile(value) ? value : new VFile(value)
}

/**
 * @param {VFileCompatible} [value]
 * @returns {value is VFile}
 */
function looksLikeAVFile(value) {
  return Boolean(
    value &&
      typeof value === 'object' &&
      'message' in value &&
      'messages' in value
  )
}

/**
 * @param {unknown} [value]
 * @returns {value is VFileValue}
 */
function looksLikeAVFileValue(value) {
  return typeof value === 'string' || isBuffer(value)
}

/**
 * @typedef {import('mdast').Root|import('mdast').Content} Node
 *
 * @typedef Options
 *   Configuration (optional).
 * @property {boolean | null | undefined} [includeImageAlt=true]
 *   Whether to use `alt` for `image`s.
 */

/**
 * Get the text content of a node or list of nodes.
 *
 * Prefers the node‚Äôs plain-text fields, otherwise serializes its children,
 * and if the given value is an array, serialize the nodes in it.
 *
 * @param {unknown} value
 *   Thing to serialize, typically `Node`.
 * @param {Options | null | undefined} [options]
 *   Configuration (optional).
 * @returns {string}
 *   Serialized `value`.
 */
function toString(value, options) {
  const includeImageAlt = (options || {}).includeImageAlt;
  return one$1(
    value,
    typeof includeImageAlt === 'boolean' ? includeImageAlt : true
  )
}

/**
 * One node or several nodes.
 *
 * @param {unknown} value
 *   Thing to serialize.
 * @param {boolean} includeImageAlt
 *   Include image `alt`s.
 * @returns {string}
 *   Serialized node.
 */
function one$1(value, includeImageAlt) {
  return (
    (node(value) &&
      (('value' in value && value.value) ||
        (includeImageAlt && 'alt' in value && value.alt) ||
        ('children' in value && all$1(value.children, includeImageAlt)))) ||
    (Array.isArray(value) && all$1(value, includeImageAlt)) ||
    ''
  )
}

/**
 * Serialize a list of nodes.
 *
 * @param {Array<unknown>} values
 *   Thing to serialize.
 * @param {boolean} includeImageAlt
 *   Include image `alt`s.
 * @returns {string}
 *   Serialized nodes.
 */
function all$1(values, includeImageAlt) {
  /** @type {Array<string>} */
  const result = [];
  let index = -1;

  while (++index < values.length) {
    result[index] = one$1(values[index], includeImageAlt);
  }

  return result.join('')
}

/**
 * Check if `value` looks like a node.
 *
 * @param {unknown} value
 *   Thing.
 * @returns {value is Node}
 *   Whether `value` is a node.
 */
function node(value) {
  return Boolean(value && typeof value === 'object')
}

/**
 * Like `Array#splice`, but smarter for giant arrays.
 *
 * `Array#splice` takes all items to be inserted as individual argument which
 * causes a stack overflow in V8 when trying to insert 100k items for instance.
 *
 * Otherwise, this does not return the removed items, and takes `items` as an
 * array instead of rest parameters.
 *
 * @template {unknown} T
 * @param {T[]} list
 * @param {number} start
 * @param {number} remove
 * @param {T[]} items
 * @returns {void}
 */
function splice(list, start, remove, items) {
  const end = list.length;
  let chunkStart = 0;
  /** @type {unknown[]} */

  let parameters; // Make start between zero and `end` (included).

  if (start < 0) {
    start = -start > end ? 0 : end + start;
  } else {
    start = start > end ? end : start;
  }

  remove = remove > 0 ? remove : 0; // No need to chunk the items if there‚Äôs only a couple (10k) items.

  if (items.length < 10000) {
    parameters = Array.from(items);
    parameters.unshift(start, remove) // @ts-expect-error Hush, it‚Äôs fine.
    ;[].splice.apply(list, parameters);
  } else {
    // Delete `remove` items starting from `start`
    if (remove) [].splice.apply(list, [start, remove]); // Insert the items in chunks to not cause stack overflows.

    while (chunkStart < items.length) {
      parameters = items.slice(chunkStart, chunkStart + 10000);
      parameters.unshift(start, 0) // @ts-expect-error Hush, it‚Äôs fine.
      ;[].splice.apply(list, parameters);
      chunkStart += 10000;
      start += 10000;
    }
  }
}
/**
 * Append `items` (an array) at the end of `list` (another array).
 * When `list` was empty, returns `items` instead.
 *
 * This prevents a potentially expensive operation when `list` is empty,
 * and adds items in batches to prevent V8 from hanging.
 *
 * @template {unknown} T
 * @param {T[]} list
 * @param {T[]} items
 * @returns {T[]}
 */

function push(list, items) {
  if (list.length > 0) {
    splice(list, list.length, 0, items);
    return list
  }

  return items
}

/**
 * @typedef {import('micromark-util-types').NormalizedExtension} NormalizedExtension
 * @typedef {import('micromark-util-types').Extension} Extension
 * @typedef {import('micromark-util-types').Construct} Construct
 * @typedef {import('micromark-util-types').HtmlExtension} HtmlExtension
 */

const hasOwnProperty = {}.hasOwnProperty;

/**
 * Combine several syntax extensions into one.
 *
 * @param {Extension[]} extensions List of syntax extensions.
 * @returns {NormalizedExtension} A single combined extension.
 */
function combineExtensions(extensions) {
  /** @type {NormalizedExtension} */
  const all = {};
  let index = -1;

  while (++index < extensions.length) {
    syntaxExtension(all, extensions[index]);
  }

  return all
}

/**
 * Merge `extension` into `all`.
 *
 * @param {NormalizedExtension} all Extension to merge into.
 * @param {Extension} extension Extension to merge.
 * @returns {void}
 */
function syntaxExtension(all, extension) {
  /** @type {string} */
  let hook;

  for (hook in extension) {
    const maybe = hasOwnProperty.call(all, hook) ? all[hook] : undefined;
    const left = maybe || (all[hook] = {});
    const right = extension[hook];
    /** @type {string} */
    let code;

    for (code in right) {
      if (!hasOwnProperty.call(left, code)) left[code] = [];
      const value = right[code];
      constructs(
        // @ts-expect-error Looks like a list.
        left[code],
        Array.isArray(value) ? value : value ? [value] : []
      );
    }
  }
}

/**
 * Merge `list` into `existing` (both lists of constructs).
 * Mutates `existing`.
 *
 * @param {unknown[]} existing
 * @param {unknown[]} list
 * @returns {void}
 */
function constructs(existing, list) {
  let index = -1;
  /** @type {unknown[]} */
  const before = [];

  while (++index < list.length) {
(list[index].add === 'after' ? existing : before).push(list[index]);
  }

  splice(existing, 0, 0, before);
}

// This module is generated by `script/`.
//
// CommonMark handles attention (emphasis, strong) markers based on what comes
// before or after them.
// One such difference is if those characters are Unicode punctuation.
// This script is generated from the Unicode data.
const unicodePunctuationRegex =
  /[!-/:-@[-`{-~\u00A1\u00A7\u00AB\u00B6\u00B7\u00BB\u00BF\u037E\u0387\u055A-\u055F\u0589\u058A\u05BE\u05C0\u05C3\u05C6\u05F3\u05F4\u0609\u060A\u060C\u060D\u061B\u061E\u061F\u066A-\u066D\u06D4\u0700-\u070D\u07F7-\u07F9\u0830-\u083E\u085E\u0964\u0965\u0970\u09FD\u0A76\u0AF0\u0C77\u0C84\u0DF4\u0E4F\u0E5A\u0E5B\u0F04-\u0F12\u0F14\u0F3A-\u0F3D\u0F85\u0FD0-\u0FD4\u0FD9\u0FDA\u104A-\u104F\u10FB\u1360-\u1368\u1400\u166E\u169B\u169C\u16EB-\u16ED\u1735\u1736\u17D4-\u17D6\u17D8-\u17DA\u1800-\u180A\u1944\u1945\u1A1E\u1A1F\u1AA0-\u1AA6\u1AA8-\u1AAD\u1B5A-\u1B60\u1BFC-\u1BFF\u1C3B-\u1C3F\u1C7E\u1C7F\u1CC0-\u1CC7\u1CD3\u2010-\u2027\u2030-\u2043\u2045-\u2051\u2053-\u205E\u207D\u207E\u208D\u208E\u2308-\u230B\u2329\u232A\u2768-\u2775\u27C5\u27C6\u27E6-\u27EF\u2983-\u2998\u29D8-\u29DB\u29FC\u29FD\u2CF9-\u2CFC\u2CFE\u2CFF\u2D70\u2E00-\u2E2E\u2E30-\u2E4F\u2E52\u3001-\u3003\u3008-\u3011\u3014-\u301F\u3030\u303D\u30A0\u30FB\uA4FE\uA4FF\uA60D-\uA60F\uA673\uA67E\uA6F2-\uA6F7\uA874-\uA877\uA8CE\uA8CF\uA8F8-\uA8FA\uA8FC\uA92E\uA92F\uA95F\uA9C1-\uA9CD\uA9DE\uA9DF\uAA5C-\uAA5F\uAADE\uAADF\uAAF0\uAAF1\uABEB\uFD3E\uFD3F\uFE10-\uFE19\uFE30-\uFE52\uFE54-\uFE61\uFE63\uFE68\uFE6A\uFE6B\uFF01-\uFF03\uFF05-\uFF0A\uFF0C-\uFF0F\uFF1A\uFF1B\uFF1F\uFF20\uFF3B-\uFF3D\uFF3F\uFF5B\uFF5D\uFF5F-\uFF65]/;

/**
 * @typedef {import('micromark-util-types').Code} Code
 */
/**
 * Check whether the character code represents an ASCII alpha (`a` through `z`,
 * case insensitive).
 *
 * An **ASCII alpha** is an ASCII upper alpha or ASCII lower alpha.
 *
 * An **ASCII upper alpha** is a character in the inclusive range U+0041 (`A`)
 * to U+005A (`Z`).
 *
 * An **ASCII lower alpha** is a character in the inclusive range U+0061 (`a`)
 * to U+007A (`z`).
 */

const asciiAlpha = regexCheck(/[A-Za-z]/);
/**
 * Check whether the character code represents an ASCII digit (`0` through `9`).
 *
 * An **ASCII digit** is a character in the inclusive range U+0030 (`0`) to
 * U+0039 (`9`).
 */

const asciiDigit = regexCheck(/\d/);
/**
 * Check whether the character code represents an ASCII hex digit (`a` through
 * `f`, case insensitive, or `0` through `9`).
 *
 * An **ASCII hex digit** is an ASCII digit (see `asciiDigit`), ASCII upper hex
 * digit, or an ASCII lower hex digit.
 *
 * An **ASCII upper hex digit** is a character in the inclusive range U+0041
 * (`A`) to U+0046 (`F`).
 *
 * An **ASCII lower hex digit** is a character in the inclusive range U+0061
 * (`a`) to U+0066 (`f`).
 */

const asciiHexDigit = regexCheck(/[\dA-Fa-f]/);
/**
 * Check whether the character code represents an ASCII alphanumeric (`a`
 * through `z`, case insensitive, or `0` through `9`).
 *
 * An **ASCII alphanumeric** is an ASCII digit (see `asciiDigit`) or ASCII alpha
 * (see `asciiAlpha`).
 */

const asciiAlphanumeric = regexCheck(/[\dA-Za-z]/);
/**
 * Check whether the character code represents ASCII punctuation.
 *
 * An **ASCII punctuation** is a character in the inclusive ranges U+0021
 * EXCLAMATION MARK (`!`) to U+002F SLASH (`/`), U+003A COLON (`:`) to U+0040 AT
 * SIGN (`@`), U+005B LEFT SQUARE BRACKET (`[`) to U+0060 GRAVE ACCENT
 * (`` ` ``), or U+007B LEFT CURLY BRACE (`{`) to U+007E TILDE (`~`).
 */

const asciiPunctuation = regexCheck(/[!-/:-@[-`{-~]/);
/**
 * Check whether the character code represents an ASCII atext.
 *
 * atext is an ASCII alphanumeric (see `asciiAlphanumeric`), or a character in
 * the inclusive ranges U+0023 NUMBER SIGN (`#`) to U+0027 APOSTROPHE (`'`),
 * U+002A ASTERISK (`*`), U+002B PLUS SIGN (`+`), U+002D DASH (`-`), U+002F
 * SLASH (`/`), U+003D EQUALS TO (`=`), U+003F QUESTION MARK (`?`), U+005E
 * CARET (`^`) to U+0060 GRAVE ACCENT (`` ` ``), or U+007B LEFT CURLY BRACE
 * (`{`) to U+007E TILDE (`~`).
 *
 * See:
 * **\[RFC5322]**:
 * [Internet Message Format](https://tools.ietf.org/html/rfc5322).
 * P. Resnick.
 * IETF.
 */

const asciiAtext = regexCheck(/[#-'*+\--9=?A-Z^-~]/);
/**
 * Check whether a character code is an ASCII control character.
 *
 * An **ASCII control** is a character in the inclusive range U+0000 NULL (NUL)
 * to U+001F (US), or U+007F (DEL).
 *
 * @param {Code} code
 * @returns {code is number}
 */

function asciiControl(code) {
  return (
    // Special whitespace codes (which have negative values), C0 and Control
    // character DEL
    code !== null && (code < 32 || code === 127)
  )
}
/**
 * Check whether a character code is a markdown line ending (see
 * `markdownLineEnding`) or markdown space (see `markdownSpace`).
 *
 * @param {Code} code
 * @returns {code is number}
 */

function markdownLineEndingOrSpace(code) {
  return code !== null && (code < 0 || code === 32)
}
/**
 * Check whether a character code is a markdown line ending.
 *
 * A **markdown line ending** is the virtual characters M-0003 CARRIAGE RETURN
 * LINE FEED (CRLF), M-0004 LINE FEED (LF) and M-0005 CARRIAGE RETURN (CR).
 *
 * In micromark, the actual character U+000A LINE FEED (LF) and U+000D CARRIAGE
 * RETURN (CR) are replaced by these virtual characters depending on whether
 * they occurred together.
 *
 * @param {Code} code
 * @returns {code is number}
 */

function markdownLineEnding(code) {
  return code !== null && code < -2
}
/**
 * Check whether a character code is a markdown space.
 *
 * A **markdown space** is the concrete character U+0020 SPACE (SP) and the
 * virtual characters M-0001 VIRTUAL SPACE (VS) and M-0002 HORIZONTAL TAB (HT).
 *
 * In micromark, the actual character U+0009 CHARACTER TABULATION (HT) is
 * replaced by one M-0002 HORIZONTAL TAB (HT) and between 0 and 3 M-0001 VIRTUAL
 * SPACE (VS) characters, depending on the column at which the tab occurred.
 *
 * @param {Code} code
 * @returns {code is number}
 */

function markdownSpace(code) {
  return code === -2 || code === -1 || code === 32
}
/**
 * Check whether the character code represents Unicode whitespace.
 *
 * Note that this does handle micromark specific markdown whitespace characters.
 * See `markdownLineEndingOrSpace` to check that.
 *
 * A **Unicode whitespace** is a character in the Unicode `Zs` (Separator,
 * Space) category, or U+0009 CHARACTER TABULATION (HT), U+000A LINE FEED (LF),
 * U+000C (FF), or U+000D CARRIAGE RETURN (CR) (**\[UNICODE]**).
 *
 * See:
 * **\[UNICODE]**:
 * [The Unicode Standard](https://www.unicode.org/versions/).
 * Unicode Consortium.
 */

const unicodeWhitespace = regexCheck(/\s/);
/**
 * Check whether the character code represents Unicode punctuation.
 *
 * A **Unicode punctuation** is a character in the Unicode `Pc` (Punctuation,
 * Connector), `Pd` (Punctuation, Dash), `Pe` (Punctuation, Close), `Pf`
 * (Punctuation, Final quote), `Pi` (Punctuation, Initial quote), `Po`
 * (Punctuation, Other), or `Ps` (Punctuation, Open) categories, or an ASCII
 * punctuation (see `asciiPunctuation`).
 *
 * See:
 * **\[UNICODE]**:
 * [The Unicode Standard](https://www.unicode.org/versions/).
 * Unicode Consortium.
 */
// Size note: removing ASCII from the regex and using `asciiPunctuation` here
// In fact adds to the bundle size.

const unicodePunctuation = regexCheck(unicodePunctuationRegex);
/**
 * Create a code check from a regex.
 *
 * @param {RegExp} regex
 * @returns {(code: Code) => code is number}
 */

function regexCheck(regex) {
  return check
  /**
   * Check whether a code matches the bound regex.
   *
   * @param {Code} code Character code
   * @returns {code is number} Whether the character code matches the bound regex
   */

  function check(code) {
    return code !== null && regex.test(String.fromCharCode(code))
  }
}

/**
 * @typedef {import('micromark-util-types').Effects} Effects
 * @typedef {import('micromark-util-types').State} State
 */
/**
 * @param {Effects} effects
 * @param {State} ok
 * @param {string} type
 * @param {number} [max=Infinity]
 * @returns {State}
 */

function factorySpace(effects, ok, type, max) {
  const limit = max ? max - 1 : Number.POSITIVE_INFINITY;
  let size = 0;
  return start
  /** @type {State} */

  function start(code) {
    if (markdownSpace(code)) {
      effects.enter(type);
      return prefix(code)
    }

    return ok(code)
  }
  /** @type {State} */

  function prefix(code) {
    if (markdownSpace(code) && size++ < limit) {
      effects.consume(code);
      return prefix
    }

    effects.exit(type);
    return ok(code)
  }
}

/**
 * @typedef {import('micromark-util-types').InitialConstruct} InitialConstruct
 * @typedef {import('micromark-util-types').Initializer} Initializer
 * @typedef {import('micromark-util-types').Token} Token
 * @typedef {import('micromark-util-types').State} State
 */

/** @type {InitialConstruct} */
const content$1 = {
  tokenize: initializeContent
};
/** @type {Initializer} */

function initializeContent(effects) {
  const contentStart = effects.attempt(
    this.parser.constructs.contentInitial,
    afterContentStartConstruct,
    paragraphInitial
  );
  /** @type {Token} */

  let previous;
  return contentStart
  /** @type {State} */

  function afterContentStartConstruct(code) {
    if (code === null) {
      effects.consume(code);
      return
    }

    effects.enter('lineEnding');
    effects.consume(code);
    effects.exit('lineEnding');
    return factorySpace(effects, contentStart, 'linePrefix')
  }
  /** @type {State} */

  function paragraphInitial(code) {
    effects.enter('paragraph');
    return lineStart(code)
  }
  /** @type {State} */

  function lineStart(code) {
    const token = effects.enter('chunkText', {
      contentType: 'text',
      previous
    });

    if (previous) {
      previous.next = token;
    }

    previous = token;
    return data(code)
  }
  /** @type {State} */

  function data(code) {
    if (code === null) {
      effects.exit('chunkText');
      effects.exit('paragraph');
      effects.consume(code);
      return
    }

    if (markdownLineEnding(code)) {
      effects.consume(code);
      effects.exit('chunkText');
      return lineStart
    } // Data.

    effects.consume(code);
    return data
  }
}

/**
 * @typedef {import('micromark-util-types').InitialConstruct} InitialConstruct
 * @typedef {import('micromark-util-types').Initializer} Initializer
 * @typedef {import('micromark-util-types').Construct} Construct
 * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext
 * @typedef {import('micromark-util-types').Tokenizer} Tokenizer
 * @typedef {import('micromark-util-types').Token} Token
 * @typedef {import('micromark-util-types').State} State
 * @typedef {import('micromark-util-types').Point} Point
 */
/** @type {InitialConstruct} */

const document$1 = {
  tokenize: initializeDocument
};
/** @type {Construct} */

const containerConstruct = {
  tokenize: tokenizeContainer
};
/** @type {Initializer} */

function initializeDocument(effects) {
  const self = this;
  /** @type {Array<StackItem>} */

  const stack = [];
  let continued = 0;
  /** @type {TokenizeContext|undefined} */

  let childFlow;
  /** @type {Token|undefined} */

  let childToken;
  /** @type {number} */

  let lineStartOffset;
  return start
  /** @type {State} */

  function start(code) {
    // First we iterate through the open blocks, starting with the root
    // document, and descending through last children down to the last open
    // block.
    // Each block imposes a condition that the line must satisfy if the block is
    // to remain open.
    // For example, a block quote requires a `>` character.
    // A paragraph requires a non-blank line.
    // In this phase we may match all or just some of the open blocks.
    // But we cannot close unmatched blocks yet, because we may have a lazy
    // continuation line.
    if (continued < stack.length) {
      const item = stack[continued];
      self.containerState = item[1];
      return effects.attempt(
        item[0].continuation,
        documentContinue,
        checkNewContainers
      )(code)
    } // Done.

    return checkNewContainers(code)
  }
  /** @type {State} */

  function documentContinue(code) {
    continued++; // Note: this field is called `_closeFlow` but it also closes containers.
    // Perhaps a good idea to rename it but it‚Äôs already used in the wild by
    // extensions.

    if (self.containerState._closeFlow) {
      self.containerState._closeFlow = undefined;

      if (childFlow) {
        closeFlow();
      } // Note: this algorithm for moving events around is similar to the
      // algorithm when dealing with lazy lines in `writeToChild`.

      const indexBeforeExits = self.events.length;
      let indexBeforeFlow = indexBeforeExits;
      /** @type {Point|undefined} */

      let point; // Find the flow chunk.

      while (indexBeforeFlow--) {
        if (
          self.events[indexBeforeFlow][0] === 'exit' &&
          self.events[indexBeforeFlow][1].type === 'chunkFlow'
        ) {
          point = self.events[indexBeforeFlow][1].end;
          break
        }
      }

      exitContainers(continued); // Fix positions.

      let index = indexBeforeExits;

      while (index < self.events.length) {
        self.events[index][1].end = Object.assign({}, point);
        index++;
      } // Inject the exits earlier (they‚Äôre still also at the end).

      splice(
        self.events,
        indexBeforeFlow + 1,
        0,
        self.events.slice(indexBeforeExits)
      ); // Discard the duplicate exits.

      self.events.length = index;
      return checkNewContainers(code)
    }

    return start(code)
  }
  /** @type {State} */

  function checkNewContainers(code) {
    // Next, after consuming the continuation markers for existing blocks, we
    // look for new block starts (e.g. `>` for a block quote).
    // If we encounter a new block start, we close any blocks unmatched in
    // step 1 before creating the new block as a child of the last matched
    // block.
    if (continued === stack.length) {
      // No need to `check` whether there‚Äôs a container, of `exitContainers`
      // would be moot.
      // We can instead immediately `attempt` to parse one.
      if (!childFlow) {
        return documentContinued(code)
      } // If we have concrete content, such as block HTML or fenced code,
      // we can‚Äôt have containers ‚Äúpierce‚Äù into them, so we can immediately
      // start.

      if (childFlow.currentConstruct && childFlow.currentConstruct.concrete) {
        return flowStart(code)
      } // If we do have flow, it could still be a blank line,
      // but we‚Äôd be interrupting it w/ a new container if there‚Äôs a current
      // construct.

      self.interrupt = Boolean(
        childFlow.currentConstruct && !childFlow._gfmTableDynamicInterruptHack
      );
    } // Check if there is a new container.

    self.containerState = {};
    return effects.check(
      containerConstruct,
      thereIsANewContainer,
      thereIsNoNewContainer
    )(code)
  }
  /** @type {State} */

  function thereIsANewContainer(code) {
    if (childFlow) closeFlow();
    exitContainers(continued);
    return documentContinued(code)
  }
  /** @type {State} */

  function thereIsNoNewContainer(code) {
    self.parser.lazy[self.now().line] = continued !== stack.length;
    lineStartOffset = self.now().offset;
    return flowStart(code)
  }
  /** @type {State} */

  function documentContinued(code) {
    // Try new containers.
    self.containerState = {};
    return effects.attempt(
      containerConstruct,
      containerContinue,
      flowStart
    )(code)
  }
  /** @type {State} */

  function containerContinue(code) {
    continued++;
    stack.push([self.currentConstruct, self.containerState]); // Try another.

    return documentContinued(code)
  }
  /** @type {State} */

  function flowStart(code) {
    if (code === null) {
      if (childFlow) closeFlow();
      exitContainers(0);
      effects.consume(code);
      return
    }

    childFlow = childFlow || self.parser.flow(self.now());
    effects.enter('chunkFlow', {
      contentType: 'flow',
      previous: childToken,
      _tokenizer: childFlow
    });
    return flowContinue(code)
  }
  /** @type {State} */

  function flowContinue(code) {
    if (code === null) {
      writeToChild(effects.exit('chunkFlow'), true);
      exitContainers(0);
      effects.consume(code);
      return
    }

    if (markdownLineEnding(code)) {
      effects.consume(code);
      writeToChild(effects.exit('chunkFlow')); // Get ready for the next line.

      continued = 0;
      self.interrupt = undefined;
      return start
    }

    effects.consume(code);
    return flowContinue
  }
  /**
   * @param {Token} token
   * @param {boolean} [eof]
   * @returns {void}
   */

  function writeToChild(token, eof) {
    const stream = self.sliceStream(token);
    if (eof) stream.push(null);
    token.previous = childToken;
    if (childToken) childToken.next = token;
    childToken = token;
    childFlow.defineSkip(token.start);
    childFlow.write(stream); // Alright, so we just added a lazy line:
    //
    // ```markdown
    // > a
    // b.
    //
    // Or:
    //
    // > ~~~c
    // d
    //
    // Or:
    //
    // > | e |
    // f
    // ```
    //
    // The construct in the second example (fenced code) does not accept lazy
    // lines, so it marked itself as done at the end of its first line, and
    // then the content construct parses `d`.
    // Most constructs in markdown match on the first line: if the first line
    // forms a construct, a non-lazy line can‚Äôt ‚Äúunmake‚Äù it.
    //
    // The construct in the third example is potentially a GFM table, and
    // those are *weird*.
    // It *could* be a table, from the first line, if the following line
    // matches a condition.
    // In this case, that second line is lazy, which ‚Äúunmakes‚Äù the first line
    // and turns the whole into one content block.
    //
    // We‚Äôve now parsed the non-lazy and the lazy line, and can figure out
    // whether the lazy line started a new flow block.
    // If it did, we exit the current containers between the two flow blocks.

    if (self.parser.lazy[token.start.line]) {
      let index = childFlow.events.length;

      while (index--) {
        if (
          // The token starts before the line ending‚Ä¶
          childFlow.events[index][1].start.offset < lineStartOffset && // ‚Ä¶and either is not ended yet‚Ä¶
          (!childFlow.events[index][1].end || // ‚Ä¶or ends after it.
            childFlow.events[index][1].end.offset > lineStartOffset)
        ) {
          // Exit: there‚Äôs still something open, which means it‚Äôs a lazy line
          // part of something.
          return
        }
      } // Note: this algorithm for moving events around is similar to the
      // algorithm when closing flow in `documentContinue`.

      const indexBeforeExits = self.events.length;
      let indexBeforeFlow = indexBeforeExits;
      /** @type {boolean|undefined} */

      let seen;
      /** @type {Point|undefined} */

      let point; // Find the previous chunk (the one before the lazy line).

      while (indexBeforeFlow--) {
        if (
          self.events[indexBeforeFlow][0] === 'exit' &&
          self.events[indexBeforeFlow][1].type === 'chunkFlow'
        ) {
          if (seen) {
            point = self.events[indexBeforeFlow][1].end;
            break
          }

          seen = true;
        }
      }

      exitContainers(continued); // Fix positions.

      index = indexBeforeExits;

      while (index < self.events.length) {
        self.events[index][1].end = Object.assign({}, point);
        index++;
      } // Inject the exits earlier (they‚Äôre still also at the end).

      splice(
        self.events,
        indexBeforeFlow + 1,
        0,
        self.events.slice(indexBeforeExits)
      ); // Discard the duplicate exits.

      self.events.length = index;
    }
  }
  /**
   * @param {number} size
   * @returns {void}
   */

  function exitContainers(size) {
    let index = stack.length; // Exit open containers.

    while (index-- > size) {
      const entry = stack[index];
      self.containerState = entry[1];
      entry[0].exit.call(self, effects);
    }

    stack.length = size;
  }

  function closeFlow() {
    childFlow.write([null]);
    childToken = undefined;
    childFlow = undefined;
    self.containerState._closeFlow = undefined;
  }
}
/** @type {Tokenizer} */

function tokenizeContainer(effects, ok, nok) {
  return factorySpace(
    effects,
    effects.attempt(this.parser.constructs.document, ok, nok),
    'linePrefix',
    this.parser.constructs.disable.null.includes('codeIndented') ? undefined : 4
  )
}

/**
 * @typedef {import('micromark-util-types').Code} Code
 */

/**
 * Classify whether a character code represents whitespace, punctuation, or
 * something else.
 *
 * Used for attention (emphasis, strong), whose sequences can open or close
 * based on the class of surrounding characters.
 *
 * Note that eof (`null`) is seen as whitespace.
 *
 * @param {Code} code
 * @returns {number|undefined}
 */
function classifyCharacter(code) {
  if (
    code === null ||
    markdownLineEndingOrSpace(code) ||
    unicodeWhitespace(code)
  ) {
    return 1
  }

  if (unicodePunctuation(code)) {
    return 2
  }
}

/**
 * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext
 * @typedef {import('micromark-util-types').Event} Event
 * @typedef {import('micromark-util-types').Resolver} Resolver
 */

/**
 * Call all `resolveAll`s.
 *
 * @param {{resolveAll?: Resolver}[]} constructs
 * @param {Event[]} events
 * @param {TokenizeContext} context
 * @returns {Event[]}
 */
function resolveAll(constructs, events, context) {
  /** @type {Resolver[]} */
  const called = [];
  let index = -1;

  while (++index < constructs.length) {
    const resolve = constructs[index].resolveAll;

    if (resolve && !called.includes(resolve)) {
      events = resolve(events, context);
      called.push(resolve);
    }
  }

  return events
}

/**
 * @typedef {import('micromark-util-types').Construct} Construct
 * @typedef {import('micromark-util-types').Tokenizer} Tokenizer
 * @typedef {import('micromark-util-types').Resolver} Resolver
 * @typedef {import('micromark-util-types').State} State
 * @typedef {import('micromark-util-types').Token} Token
 * @typedef {import('micromark-util-types').Event} Event
 * @typedef {import('micromark-util-types').Code} Code
 * @typedef {import('micromark-util-types').Point} Point
 */

/** @type {Construct} */
const attention = {
  name: 'attention',
  tokenize: tokenizeAttention,
  resolveAll: resolveAllAttention
};
/**
 * Take all events and resolve attention to emphasis or strong.
 *
 * @type {Resolver}
 */

function resolveAllAttention(events, context) {
  let index = -1;
  /** @type {number} */

  let open;
  /** @type {Token} */

  let group;
  /** @type {Token} */

  let text;
  /** @type {Token} */

  let openingSequence;
  /** @type {Token} */

  let closingSequence;
  /** @type {number} */

  let use;
  /** @type {Event[]} */

  let nextEvents;
  /** @type {number} */

  let offset; // Walk through all events.
  //
  // Note: performance of this is fine on an mb of normal markdown, but it‚Äôs
  // a bottleneck for malicious stuff.

  while (++index < events.length) {
    // Find a token that can close.
    if (
      events[index][0] === 'enter' &&
      events[index][1].type === 'attentionSequence' &&
      events[index][1]._close
    ) {
      open = index; // Now walk back to find an opener.

      while (open--) {
        // Find a token that can open the closer.
        if (
          events[open][0] === 'exit' &&
          events[open][1].type === 'attentionSequence' &&
          events[open][1]._open && // If the markers are the same:
          context.sliceSerialize(events[open][1]).charCodeAt(0) ===
            context.sliceSerialize(events[index][1]).charCodeAt(0)
        ) {
          // If the opening can close or the closing can open,
          // and the close size *is not* a multiple of three,
          // but the sum of the opening and closing size *is* multiple of three,
          // then don‚Äôt match.
          if (
            (events[open][1]._close || events[index][1]._open) &&
            (events[index][1].end.offset - events[index][1].start.offset) % 3 &&
            !(
              (events[open][1].end.offset -
                events[open][1].start.offset +
                events[index][1].end.offset -
                events[index][1].start.offset) %
              3
            )
          ) {
            continue
          } // Number of markers to use from the sequence.

          use =
            events[open][1].end.offset - events[open][1].start.offset > 1 &&
            events[index][1].end.offset - events[index][1].start.offset > 1
              ? 2
              : 1;
          const start = Object.assign({}, events[open][1].end);
          const end = Object.assign({}, events[index][1].start);
          movePoint(start, -use);
          movePoint(end, use);
          openingSequence = {
            type: use > 1 ? 'strongSequence' : 'emphasisSequence',
            start,
            end: Object.assign({}, events[open][1].end)
          };
          closingSequence = {
            type: use > 1 ? 'strongSequence' : 'emphasisSequence',
            start: Object.assign({}, events[index][1].start),
            end
          };
          text = {
            type: use > 1 ? 'strongText' : 'emphasisText',
            start: Object.assign({}, events[open][1].end),
            end: Object.assign({}, events[index][1].start)
          };
          group = {
            type: use > 1 ? 'strong' : 'emphasis',
            start: Object.assign({}, openingSequence.start),
            end: Object.assign({}, closingSequence.end)
          };
          events[open][1].end = Object.assign({}, openingSequence.start);
          events[index][1].start = Object.assign({}, closingSequence.end);
          nextEvents = []; // If there are more markers in the opening, add them before.

          if (events[open][1].end.offset - events[open][1].start.offset) {
            nextEvents = push(nextEvents, [
              ['enter', events[open][1], context],
              ['exit', events[open][1], context]
            ]);
          } // Opening.

          nextEvents = push(nextEvents, [
            ['enter', group, context],
            ['enter', openingSequence, context],
            ['exit', openingSequence, context],
            ['enter', text, context]
          ]); // Between.

          nextEvents = push(
            nextEvents,
            resolveAll(
              context.parser.constructs.insideSpan.null,
              events.slice(open + 1, index),
              context
            )
          ); // Closing.

          nextEvents = push(nextEvents, [
            ['exit', text, context],
            ['enter', closingSequence, context],
            ['exit', closingSequence, context],
            ['exit', group, context]
          ]); // If there are more markers in the closing, add them after.

          if (events[index][1].end.offset - events[index][1].start.offset) {
            offset = 2;
            nextEvents = push(nextEvents, [
              ['enter', events[index][1], context],
              ['exit', events[index][1], context]
            ]);
          } else {
            offset = 0;
          }

          splice(events, open - 1, index - open + 3, nextEvents);
          index = open + nextEvents.length - offset - 2;
          break
        }
      }
    }
  } // Remove remaining sequences.

  index = -1;

  while (++index < events.length) {
    if (events[index][1].type === 'attentionSequence') {
      events[index][1].type = 'data';
    }
  }

  return events
}
/** @type {Tokenizer} */

function tokenizeAttention(effects, ok) {
  const attentionMarkers = this.parser.constructs.attentionMarkers.null;
  const previous = this.previous;
  const before = classifyCharacter(previous);
  /** @type {NonNullable<Code>} */

  let marker;
  return start
  /** @type {State} */

  function start(code) {
    effects.enter('attentionSequence');
    marker = code;
    return sequence(code)
  }
  /** @type {State} */

  function sequence(code) {
    if (code === marker) {
      effects.consume(code);
      return sequence
    }

    const token = effects.exit('attentionSequence');
    const after = classifyCharacter(code);
    const open =
      !after || (after === 2 && before) || attentionMarkers.includes(code);
    const close =
      !before || (before === 2 && after) || attentionMarkers.includes(previous);
    token._open = Boolean(marker === 42 ? open : open && (before || !close));
    token._close = Boolean(marker === 42 ? close : close && (after || !open));
    return ok(code)
  }
}
/**
 * Move a point a bit.
 *
 * Note: `move` only works inside lines! It‚Äôs not possible to move past other
 * chunks (replacement characters, tabs, or line endings).
 *
 * @param {Point} point
 * @param {number} offset
 * @returns {void}
 */

function movePoint(point, offset) {
  point.column += offset;
  point.offset += offset;
  point._bufferIndex += offset;
}

/**
 * @typedef {import('micromark-util-types').Construct} Construct
 * @typedef {import('micromark-util-types').Tokenizer} Tokenizer
 * @typedef {import('micromark-util-types').State} State
 */

/** @type {Construct} */
const autolink = {
  name: 'autolink',
  tokenize: tokenizeAutolink
};
/** @type {Tokenizer} */

function tokenizeAutolink(effects, ok, nok) {
  let size = 1;
  return start
  /** @type {State} */

  function start(code) {
    effects.enter('autolink');
    effects.enter('autolinkMarker');
    effects.consume(code);
    effects.exit('autolinkMarker');
    effects.enter('autolinkProtocol');
    return open
  }
  /** @type {State} */

  function open(code) {
    if (asciiAlpha(code)) {
      effects.consume(code);
      return schemeOrEmailAtext
    }

    return asciiAtext(code) ? emailAtext(code) : nok(code)
  }
  /** @type {State} */

  function schemeOrEmailAtext(code) {
    return code === 43 || code === 45 || code === 46 || asciiAlphanumeric(code)
      ? schemeInsideOrEmailAtext(code)
      : emailAtext(code)
  }
  /** @type {State} */

  function schemeInsideOrEmailAtext(code) {
    if (code === 58) {
      effects.consume(code);
      return urlInside
    }

    if (
      (code === 43 || code === 45 || code === 46 || asciiAlphanumeric(code)) &&
      size++ < 32
    ) {
      effects.consume(code);
      return schemeInsideOrEmailAtext
    }

    return emailAtext(code)
  }
  /** @type {State} */

  function urlInside(code) {
    if (code === 62) {
      effects.exit('autolinkProtocol');
      return end(code)
    }

    if (code === null || code === 32 || code === 60 || asciiControl(code)) {
      return nok(code)
    }

    effects.consume(code);
    return urlInside
  }
  /** @type {State} */

  function emailAtext(code) {
    if (code === 64) {
      effects.consume(code);
      size = 0;
      return emailAtSignOrDot
    }

    if (asciiAtext(code)) {
      effects.consume(code);
      return emailAtext
    }

    return nok(code)
  }
  /** @type {State} */

  function emailAtSignOrDot(code) {
    return asciiAlphanumeric(code) ? emailLabel(code) : nok(code)
  }
  /** @type {State} */

  function emailLabel(code) {
    if (code === 46) {
      effects.consume(code);
      size = 0;
      return emailAtSignOrDot
    }

    if (code === 62) {
      // Exit, then change the type.
      effects.exit('autolinkProtocol').type = 'autolinkEmail';
      return end(code)
    }

    return emailValue(code)
  }
  /** @type {State} */

  function emailValue(code) {
    if ((code === 45 || asciiAlphanumeric(code)) && size++ < 63) {
      effects.consume(code);
      return code === 45 ? emailValue : emailLabel
    }

    return nok(code)
  }
  /** @type {State} */

  function end(code) {
    effects.enter('autolinkMarker');
    effects.consume(code);
    effects.exit('autolinkMarker');
    effects.exit('autolink');
    return ok
  }
}

/**
 * @typedef {import('micromark-util-types').Construct} Construct
 * @typedef {import('micromark-util-types').Tokenizer} Tokenizer
 * @typedef {import('micromark-util-types').State} State
 */

/** @type {Construct} */
const blankLine = {
  tokenize: tokenizeBlankLine,
  partial: true
};
/** @type {Tokenizer} */

function tokenizeBlankLine(effects, ok, nok) {
  return factorySpace(effects, afterWhitespace, 'linePrefix')
  /** @type {State} */

  function afterWhitespace(code) {
    return code === null || markdownLineEnding(code) ? ok(code) : nok(code)
  }
}

/**
 * @typedef {import('micromark-util-types').Construct} Construct
 * @typedef {import('micromark-util-types').Tokenizer} Tokenizer
 * @typedef {import('micromark-util-types').Exiter} Exiter
 * @typedef {import('micromark-util-types').State} State
 */

/** @type {Construct} */
const blockQuote = {
  name: 'blockQuote',
  tokenize: tokenizeBlockQuoteStart,
  continuation: {
    tokenize: tokenizeBlockQuoteContinuation
  },
  exit: exit$1
};
/** @type {Tokenizer} */

function tokenizeBlockQuoteStart(effects, ok, nok) {
  const self = this;
  return start
  /** @type {State} */

  function start(code) {
    if (code === 62) {
      const state = self.containerState;

      if (!state.open) {
        effects.enter('blockQuote', {
          _container: true
        });
        state.open = true;
      }

      effects.enter('blockQuotePrefix');
      effects.enter('blockQuoteMarker');
      effects.consume(code);
      effects.exit('blockQuoteMarker');
      return after
    }

    return nok(code)
  }
  /** @type {State} */

  function after(code) {
    if (markdownSpace(code)) {
      effects.enter('blockQuotePrefixWhitespace');
      effects.consume(code);
      effects.exit('blockQuotePrefixWhitespace');
      effects.exit('blockQuotePrefix');
      return ok
    }

    effects.exit('blockQuotePrefix');
    return ok(code)
  }
}
/** @type {Tokenizer} */

function tokenizeBlockQuoteContinuation(effects, ok, nok) {
  return factorySpace(
    effects,
    effects.attempt(blockQuote, ok, nok),
    'linePrefix',
    this.parser.constructs.disable.null.includes('codeIndented') ? undefined : 4
  )
}
/** @type {Exiter} */

function exit$1(effects) {
  effects.exit('blockQuote');
}

/**
 * @typedef {import('micromark-util-types').Construct} Construct
 * @typedef {import('micromark-util-types').Tokenizer} Tokenizer
 * @typedef {import('micromark-util-types').State} State
 */

/** @type {Construct} */
const characterEscape = {
  name: 'characterEscape',
  tokenize: tokenizeCharacterEscape
};
/** @type {Tokenizer} */

function tokenizeCharacterEscape(effects, ok, nok) {
  return start
  /** @type {State} */

  function start(code) {
    effects.enter('characterEscape');
    effects.enter('escapeMarker');
    effects.consume(code);
    effects.exit('escapeMarker');
    return open
  }
  /** @type {State} */

  function open(code) {
    if (asciiPunctuation(code)) {
      effects.enter('characterEscapeValue');
      effects.consume(code);
      effects.exit('characterEscapeValue');
      effects.exit('characterEscape');
      return ok
    }

    return nok(code)
  }
}

/**
 * Map of named character references.
 *
 * @type {Record<string, string>}
 */
const characterEntities = {
  AElig: '√Ü',
  AMP: '&',
  Aacute: '√Å',
  Abreve: 'ƒÇ',
  Acirc: '√Ç',
  Acy: '–ê',
  Afr: 'ùîÑ',
  Agrave: '√Ä',
  Alpha: 'Œë',
  Amacr: 'ƒÄ',
  And: '‚©ì',
  Aogon: 'ƒÑ',
  Aopf: 'ùî∏',
  ApplyFunction: '‚Å°',
  Aring: '√Ö',
  Ascr: 'ùíú',
  Assign: '‚âî',
  Atilde: '√É',
  Auml: '√Ñ',
  Backslash: '‚àñ',
  Barv: '‚´ß',
  Barwed: '‚åÜ',
  Bcy: '–ë',
  Because: '‚àµ',
  Bernoullis: '‚Ñ¨',
  Beta: 'Œí',
  Bfr: 'ùîÖ',
  Bopf: 'ùîπ',
  Breve: 'Àò',
  Bscr: '‚Ñ¨',
  Bumpeq: '‚âé',
  CHcy: '–ß',
  COPY: '¬©',
  Cacute: 'ƒÜ',
  Cap: '‚ãí',
  CapitalDifferentialD: '‚ÖÖ',
  Cayleys: '‚Ñ≠',
  Ccaron: 'ƒå',
  Ccedil: '√á',
  Ccirc: 'ƒà',
  Cconint: '‚à∞',
  Cdot: 'ƒä',
  Cedilla: '¬∏',
  CenterDot: '¬∑',
  Cfr: '‚Ñ≠',
  Chi: 'Œß',
  CircleDot: '‚äô',
  CircleMinus: '‚äñ',
  CirclePlus: '‚äï',
  CircleTimes: '‚äó',
  ClockwiseContourIntegral: '‚à≤',
  CloseCurlyDoubleQuote: '‚Äù',
  CloseCurlyQuote: '‚Äô',
  Colon: '‚à∑',
  Colone: '‚©¥',
  Congruent: '‚â°',
  Conint: '‚àØ',
  ContourIntegral: '‚àÆ',
  Copf: '‚ÑÇ',
  Coproduct: '‚àê',
  CounterClockwiseContourIntegral: '‚à≥',
  Cross: '‚®Ø',
  Cscr: 'ùíû',
  Cup: '‚ãì',
  CupCap: '‚âç',
  DD: '‚ÖÖ',
  DDotrahd: '‚§ë',
  DJcy: '–Ç',
  DScy: '–Ö',
  DZcy: '–è',
  Dagger: '‚Ä°',
  Darr: '‚Ü°',
  Dashv: '‚´§',
  Dcaron: 'ƒé',
  Dcy: '–î',
  Del: '‚àá',
  Delta: 'Œî',
  Dfr: 'ùîá',
  DiacriticalAcute: '¬¥',
  DiacriticalDot: 'Àô',
  DiacriticalDoubleAcute: 'Àù',
  DiacriticalGrave: '`',
  DiacriticalTilde: 'Àú',
  Diamond: '‚ãÑ',
  DifferentialD: '‚ÖÜ',
  Dopf: 'ùîª',
  Dot: '¬®',
  DotDot: '‚Éú',
  DotEqual: '‚âê',
  DoubleContourIntegral: '‚àØ',
  DoubleDot: '¬®',
  DoubleDownArrow: '‚áì',
  DoubleLeftArrow: '‚áê',
  DoubleLeftRightArrow: '‚áî',
  DoubleLeftTee: '‚´§',
  DoubleLongLeftArrow: '‚ü∏',
  DoubleLongLeftRightArrow: '‚ü∫',
  DoubleLongRightArrow: '‚üπ',
  DoubleRightArrow: '‚áí',
  DoubleRightTee: '‚ä®',
  DoubleUpArrow: '‚áë',
  DoubleUpDownArrow: '‚áï',
  DoubleVerticalBar: '‚à•',
  DownArrow: '‚Üì',
  DownArrowBar: '‚§ì',
  DownArrowUpArrow: '‚áµ',
  DownBreve: 'Ãë',
  DownLeftRightVector: '‚•ê',
  DownLeftTeeVector: '‚•û',
  DownLeftVector: '‚ÜΩ',
  DownLeftVectorBar: '‚•ñ',
  DownRightTeeVector: '‚•ü',
  DownRightVector: '‚áÅ',
  DownRightVectorBar: '‚•ó',
  DownTee: '‚ä§',
  DownTeeArrow: '‚Üß',
  Downarrow: '‚áì',
  Dscr: 'ùíü',
  Dstrok: 'ƒê',
  ENG: '≈ä',
  ETH: '√ê',
  Eacute: '√â',
  Ecaron: 'ƒö',
  Ecirc: '√ä',
  Ecy: '–≠',
  Edot: 'ƒñ',
  Efr: 'ùîà',
  Egrave: '√à',
  Element: '‚àà',
  Emacr: 'ƒí',
  EmptySmallSquare: '‚óª',
  EmptyVerySmallSquare: '‚ñ´',
  Eogon: 'ƒò',
  Eopf: 'ùîº',
  Epsilon: 'Œï',
  Equal: '‚©µ',
  EqualTilde: '‚âÇ',
  Equilibrium: '‚áå',
  Escr: '‚Ñ∞',
  Esim: '‚©≥',
  Eta: 'Œó',
  Euml: '√ã',
  Exists: '‚àÉ',
  ExponentialE: '‚Öá',
  Fcy: '–§',
  Ffr: 'ùîâ',
  FilledSmallSquare: '‚óº',
  FilledVerySmallSquare: '‚ñ™',
  Fopf: 'ùîΩ',
  ForAll: '‚àÄ',
  Fouriertrf: '‚Ñ±',
  Fscr: '‚Ñ±',
  GJcy: '–É',
  GT: '>',
  Gamma: 'Œì',
  Gammad: 'œú',
  Gbreve: 'ƒû',
  Gcedil: 'ƒ¢',
  Gcirc: 'ƒú',
  Gcy: '–ì',
  Gdot: 'ƒ†',
  Gfr: 'ùîä',
  Gg: '‚ãô',
  Gopf: 'ùîæ',
  GreaterEqual: '‚â•',
  GreaterEqualLess: '‚ãõ',
  GreaterFullEqual: '‚âß',
  GreaterGreater: '‚™¢',
  GreaterLess: '‚â∑',
  GreaterSlantEqual: '‚©æ',
  GreaterTilde: '‚â≥',
  Gscr: 'ùí¢',
  Gt: '‚â´',
  HARDcy: '–™',
  Hacek: 'Àá',
  Hat: '^',
  Hcirc: 'ƒ§',
  Hfr: '‚Ñå',
  HilbertSpace: '‚Ñã',
  Hopf: '‚Ñç',
  HorizontalLine: '‚îÄ',
  Hscr: '‚Ñã',
  Hstrok: 'ƒ¶',
  HumpDownHump: '‚âé',
  HumpEqual: '‚âè',
  IEcy: '–ï',
  IJlig: 'ƒ≤',
  IOcy: '–Å',
  Iacute: '√ç',
  Icirc: '√é',
  Icy: '–ò',
  Idot: 'ƒ∞',
  Ifr: '‚Ñë',
  Igrave: '√å',
  Im: '‚Ñë',
  Imacr: 'ƒ™',
  ImaginaryI: '‚Öà',
  Implies: '‚áí',
  Int: '‚à¨',
  Integral: '‚à´',
  Intersection: '‚ãÇ',
  InvisibleComma: '‚Å£',
  InvisibleTimes: '‚Å¢',
  Iogon: 'ƒÆ',
  Iopf: 'ùïÄ',
  Iota: 'Œô',
  Iscr: '‚Ñê',
  Itilde: 'ƒ®',
  Iukcy: '–Ü',
  Iuml: '√è',
  Jcirc: 'ƒ¥',
  Jcy: '–ô',
  Jfr: 'ùîç',
  Jopf: 'ùïÅ',
  Jscr: 'ùí•',
  Jsercy: '–à',
  Jukcy: '–Ñ',
  KHcy: '–•',
  KJcy: '–å',
  Kappa: 'Œö',
  Kcedil: 'ƒ∂',
  Kcy: '–ö',
  Kfr: 'ùîé',
  Kopf: 'ùïÇ',
  Kscr: 'ùí¶',
  LJcy: '–â',
  LT: '<',
  Lacute: 'ƒπ',
  Lambda: 'Œõ',
  Lang: '‚ü™',
  Laplacetrf: '‚Ñí',
  Larr: '‚Üû',
  Lcaron: 'ƒΩ',
  Lcedil: 'ƒª',
  Lcy: '–õ',
  LeftAngleBracket: '‚ü®',
  LeftArrow: '‚Üê',
  LeftArrowBar: '‚á§',
  LeftArrowRightArrow: '‚áÜ',
  LeftCeiling: '‚åà',
  LeftDoubleBracket: '‚ü¶',
  LeftDownTeeVector: '‚•°',
  LeftDownVector: '‚áÉ',
  LeftDownVectorBar: '‚•ô',
  LeftFloor: '‚åä',
  LeftRightArrow: '‚Üî',
  LeftRightVector: '‚•é',
  LeftTee: '‚ä£',
  LeftTeeArrow: '‚Ü§',
  LeftTeeVector: '‚•ö',
  LeftTriangle: '‚ä≤',
  LeftTriangleBar: '‚ßè',
  LeftTriangleEqual: '‚ä¥',
  LeftUpDownVector: '‚•ë',
  LeftUpTeeVector: '‚•†',
  LeftUpVector: '‚Üø',
  LeftUpVectorBar: '‚•ò',
  LeftVector: '‚Üº',
  LeftVectorBar: '‚•í',
  Leftarrow: '‚áê',
  Leftrightarrow: '‚áî',
  LessEqualGreater: '‚ãö',
  LessFullEqual: '‚â¶',
  LessGreater: '‚â∂',
  LessLess: '‚™°',
  LessSlantEqual: '‚©Ω',
  LessTilde: '‚â≤',
  Lfr: 'ùîè',
  Ll: '‚ãò',
  Lleftarrow: '‚áö',
  Lmidot: 'ƒø',
  LongLeftArrow: '‚üµ',
  LongLeftRightArrow: '‚ü∑',
  LongRightArrow: '‚ü∂',
  Longleftarrow: '‚ü∏',
  Longleftrightarrow: '‚ü∫',
  Longrightarrow: '‚üπ',
  Lopf: 'ùïÉ',
  LowerLeftArrow: '‚Üô',
  LowerRightArrow: '‚Üò',
  Lscr: '‚Ñí',
  Lsh: '‚Ü∞',
  Lstrok: '≈Å',
  Lt: '‚â™',
  Map: '‚§Ö',
  Mcy: '–ú',
  MediumSpace: '‚Åü',
  Mellintrf: '‚Ñ≥',
  Mfr: 'ùîê',
  MinusPlus: '‚àì',
  Mopf: 'ùïÑ',
  Mscr: '‚Ñ≥',
  Mu: 'Œú',
  NJcy: '–ä',
  Nacute: '≈É',
  Ncaron: '≈á',
  Ncedil: '≈Ö',
  Ncy: '–ù',
  NegativeMediumSpace: '‚Äã',
  NegativeThickSpace: '‚Äã',
  NegativeThinSpace: '‚Äã',
  NegativeVeryThinSpace: '‚Äã',
  NestedGreaterGreater: '‚â´',
  NestedLessLess: '‚â™',
  NewLine: '\n',
  Nfr: 'ùîë',
  NoBreak: '‚Å†',
  NonBreakingSpace: '¬†',
  Nopf: '‚Ñï',
  Not: '‚´¨',
  NotCongruent: '‚â¢',
  NotCupCap: '‚â≠',
  NotDoubleVerticalBar: '‚à¶',
  NotElement: '‚àâ',
  NotEqual: '‚â†',
  NotEqualTilde: '‚âÇÃ∏',
  NotExists: '‚àÑ',
  NotGreater: '‚âØ',
  NotGreaterEqual: '‚â±',
  NotGreaterFullEqual: '‚âßÃ∏',
  NotGreaterGreater: '‚â´Ã∏',
  NotGreaterLess: '‚âπ',
  NotGreaterSlantEqual: '‚©æÃ∏',
  NotGreaterTilde: '‚âµ',
  NotHumpDownHump: '‚âéÃ∏',
  NotHumpEqual: '‚âèÃ∏',
  NotLeftTriangle: '‚ã™',
  NotLeftTriangleBar: '‚ßèÃ∏',
  NotLeftTriangleEqual: '‚ã¨',
  NotLess: '‚âÆ',
  NotLessEqual: '‚â∞',
  NotLessGreater: '‚â∏',
  NotLessLess: '‚â™Ã∏',
  NotLessSlantEqual: '‚©ΩÃ∏',
  NotLessTilde: '‚â¥',
  NotNestedGreaterGreater: '‚™¢Ã∏',
  NotNestedLessLess: '‚™°Ã∏',
  NotPrecedes: '‚äÄ',
  NotPrecedesEqual: '‚™ØÃ∏',
  NotPrecedesSlantEqual: '‚ã†',
  NotReverseElement: '‚àå',
  NotRightTriangle: '‚ã´',
  NotRightTriangleBar: '‚ßêÃ∏',
  NotRightTriangleEqual: '‚ã≠',
  NotSquareSubset: '‚äèÃ∏',
  NotSquareSubsetEqual: '‚ã¢',
  NotSquareSuperset: '‚äêÃ∏',
  NotSquareSupersetEqual: '‚ã£',
  NotSubset: '‚äÇ‚Éí',
  NotSubsetEqual: '‚äà',
  NotSucceeds: '‚äÅ',
  NotSucceedsEqual: '‚™∞Ã∏',
  NotSucceedsSlantEqual: '‚ã°',
  NotSucceedsTilde: '‚âøÃ∏',
  NotSuperset: '‚äÉ‚Éí',
  NotSupersetEqual: '‚äâ',
  NotTilde: '‚âÅ',
  NotTildeEqual: '‚âÑ',
  NotTildeFullEqual: '‚âá',
  NotTildeTilde: '‚ââ',
  NotVerticalBar: '‚à§',
  Nscr: 'ùí©',
  Ntilde: '√ë',
  Nu: 'Œù',
  OElig: '≈í',
  Oacute: '√ì',
  Ocirc: '√î',
  Ocy: '–û',
  Odblac: '≈ê',
  Ofr: 'ùîí',
  Ograve: '√í',
  Omacr: '≈å',
  Omega: 'Œ©',
  Omicron: 'Œü',
  Oopf: 'ùïÜ',
  OpenCurlyDoubleQuote: '‚Äú',
  OpenCurlyQuote: '‚Äò',
  Or: '‚©î',
  Oscr: 'ùí™',
  Oslash: '√ò',
  Otilde: '√ï',
  Otimes: '‚®∑',
  Ouml: '√ñ',
  OverBar: '‚Äæ',
  OverBrace: '‚èû',
  OverBracket: '‚é¥',
  OverParenthesis: '‚èú',
  PartialD: '‚àÇ',
  Pcy: '–ü',
  Pfr: 'ùîì',
  Phi: 'Œ¶',
  Pi: 'Œ†',
  PlusMinus: '¬±',
  Poincareplane: '‚Ñå',
  Popf: '‚Ñô',
  Pr: '‚™ª',
  Precedes: '‚â∫',
  PrecedesEqual: '‚™Ø',
  PrecedesSlantEqual: '‚âº',
  PrecedesTilde: '‚âæ',
  Prime: '‚Ä≥',
  Product: '‚àè',
  Proportion: '‚à∑',
  Proportional: '‚àù',
  Pscr: 'ùí´',
  Psi: 'Œ®',
  QUOT: '"',
  Qfr: 'ùîî',
  Qopf: '‚Ñö',
  Qscr: 'ùí¨',
  RBarr: '‚§ê',
  REG: '¬Æ',
  Racute: '≈î',
  Rang: '‚ü´',
  Rarr: '‚Ü†',
  Rarrtl: '‚§ñ',
  Rcaron: '≈ò',
  Rcedil: '≈ñ',
  Rcy: '–†',
  Re: '‚Ñú',
  ReverseElement: '‚àã',
  ReverseEquilibrium: '‚áã',
  ReverseUpEquilibrium: '‚•Ø',
  Rfr: '‚Ñú',
  Rho: 'Œ°',
  RightAngleBracket: '‚ü©',
  RightArrow: '‚Üí',
  RightArrowBar: '‚á•',
  RightArrowLeftArrow: '‚áÑ',
  RightCeiling: '‚åâ',
  RightDoubleBracket: '‚üß',
  RightDownTeeVector: '‚•ù',
  RightDownVector: '‚áÇ',
  RightDownVectorBar: '‚•ï',
  RightFloor: '‚åã',
  RightTee: '‚ä¢',
  RightTeeArrow: '‚Ü¶',
  RightTeeVector: '‚•õ',
  RightTriangle: '‚ä≥',
  RightTriangleBar: '‚ßê',
  RightTriangleEqual: '‚äµ',
  RightUpDownVector: '‚•è',
  RightUpTeeVector: '‚•ú',
  RightUpVector: '‚Üæ',
  RightUpVectorBar: '‚•î',
  RightVector: '‚áÄ',
  RightVectorBar: '‚•ì',
  Rightarrow: '‚áí',
  Ropf: '‚Ñù',
  RoundImplies: '‚•∞',
  Rrightarrow: '‚áõ',
  Rscr: '‚Ñõ',
  Rsh: '‚Ü±',
  RuleDelayed: '‚ß¥',
  SHCHcy: '–©',
  SHcy: '–®',
  SOFTcy: '–¨',
  Sacute: '≈ö',
  Sc: '‚™º',
  Scaron: '≈†',
  Scedil: '≈û',
  Scirc: '≈ú',
  Scy: '–°',
  Sfr: 'ùîñ',
  ShortDownArrow: '‚Üì',
  ShortLeftArrow: '‚Üê',
  ShortRightArrow: '‚Üí',
  ShortUpArrow: '‚Üë',
  Sigma: 'Œ£',
  SmallCircle: '‚àò',
  Sopf: 'ùïä',
  Sqrt: '‚àö',
  Square: '‚ñ°',
  SquareIntersection: '‚äì',
  SquareSubset: '‚äè',
  SquareSubsetEqual: '‚äë',
  SquareSuperset: '‚äê',
  SquareSupersetEqual: '‚äí',
  SquareUnion: '‚äî',
  Sscr: 'ùíÆ',
  Star: '‚ãÜ',
  Sub: '‚ãê',
  Subset: '‚ãê',
  SubsetEqual: '‚äÜ',
  Succeeds: '‚âª',
  SucceedsEqual: '‚™∞',
  SucceedsSlantEqual: '‚âΩ',
  SucceedsTilde: '‚âø',
  SuchThat: '‚àã',
  Sum: '‚àë',
  Sup: '‚ãë',
  Superset: '‚äÉ',
  SupersetEqual: '‚äá',
  Supset: '‚ãë',
  THORN: '√û',
  TRADE: '‚Ñ¢',
  TSHcy: '–ã',
  TScy: '–¶',
  Tab: '\t',
  Tau: 'Œ§',
  Tcaron: '≈§',
  Tcedil: '≈¢',
  Tcy: '–¢',
  Tfr: 'ùîó',
  Therefore: '‚à¥',
  Theta: 'Œò',
  ThickSpace: '‚Åü‚Ää',
  ThinSpace: '‚Äâ',
  Tilde: '‚àº',
  TildeEqual: '‚âÉ',
  TildeFullEqual: '‚âÖ',
  TildeTilde: '‚âà',
  Topf: 'ùïã',
  TripleDot: '‚Éõ',
  Tscr: 'ùíØ',
  Tstrok: '≈¶',
  Uacute: '√ö',
  Uarr: '‚Üü',
  Uarrocir: '‚•â',
  Ubrcy: '–é',
  Ubreve: '≈¨',
  Ucirc: '√õ',
  Ucy: '–£',
  Udblac: '≈∞',
  Ufr: 'ùîò',
  Ugrave: '√ô',
  Umacr: '≈™',
  UnderBar: '_',
  UnderBrace: '‚èü',
  UnderBracket: '‚éµ',
  UnderParenthesis: '‚èù',
  Union: '‚ãÉ',
  UnionPlus: '‚äé',
  Uogon: '≈≤',
  Uopf: 'ùïå',
  UpArrow: '‚Üë',
  UpArrowBar: '‚§í',
  UpArrowDownArrow: '‚áÖ',
  UpDownArrow: '‚Üï',
  UpEquilibrium: '‚•Æ',
  UpTee: '‚ä•',
  UpTeeArrow: '‚Ü•',
  Uparrow: '‚áë',
  Updownarrow: '‚áï',
  UpperLeftArrow: '‚Üñ',
  UpperRightArrow: '‚Üó',
  Upsi: 'œí',
  Upsilon: 'Œ•',
  Uring: '≈Æ',
  Uscr: 'ùí∞',
  Utilde: '≈®',
  Uuml: '√ú',
  VDash: '‚ä´',
  Vbar: '‚´´',
  Vcy: '–í',
  Vdash: '‚ä©',
  Vdashl: '‚´¶',
  Vee: '‚ãÅ',
  Verbar: '‚Äñ',
  Vert: '‚Äñ',
  VerticalBar: '‚à£',
  VerticalLine: '|',
  VerticalSeparator: '‚ùò',
  VerticalTilde: '‚âÄ',
  VeryThinSpace: '‚Ää',
  Vfr: 'ùîô',
  Vopf: 'ùïç',
  Vscr: 'ùí±',
  Vvdash: '‚ä™',
  Wcirc: '≈¥',
  Wedge: '‚ãÄ',
  Wfr: 'ùîö',
  Wopf: 'ùïé',
  Wscr: 'ùí≤',
  Xfr: 'ùîõ',
  Xi: 'Œû',
  Xopf: 'ùïè',
  Xscr: 'ùí≥',
  YAcy: '–Ø',
  YIcy: '–á',
  YUcy: '–Æ',
  Yacute: '√ù',
  Ycirc: '≈∂',
  Ycy: '–´',
  Yfr: 'ùîú',
  Yopf: 'ùïê',
  Yscr: 'ùí¥',
  Yuml: '≈∏',
  ZHcy: '–ñ',
  Zacute: '≈π',
  Zcaron: '≈Ω',
  Zcy: '–ó',
  Zdot: '≈ª',
  ZeroWidthSpace: '‚Äã',
  Zeta: 'Œñ',
  Zfr: '‚Ñ®',
  Zopf: '‚Ñ§',
  Zscr: 'ùíµ',
  aacute: '√°',
  abreve: 'ƒÉ',
  ac: '‚àæ',
  acE: '‚àæÃ≥',
  acd: '‚àø',
  acirc: '√¢',
  acute: '¬¥',
  acy: '–∞',
  aelig: '√¶',
  af: '‚Å°',
  afr: 'ùîû',
  agrave: '√†',
  alefsym: '‚Ñµ',
  aleph: '‚Ñµ',
  alpha: 'Œ±',
  amacr: 'ƒÅ',
  amalg: '‚®ø',
  amp: '&',
  and: '‚àß',
  andand: '‚©ï',
  andd: '‚©ú',
  andslope: '‚©ò',
  andv: '‚©ö',
  ang: '‚à†',
  ange: '‚¶§',
  angle: '‚à†',
  angmsd: '‚à°',
  angmsdaa: '‚¶®',
  angmsdab: '‚¶©',
  angmsdac: '‚¶™',
  angmsdad: '‚¶´',
  angmsdae: '‚¶¨',
  angmsdaf: '‚¶≠',
  angmsdag: '‚¶Æ',
  angmsdah: '‚¶Ø',
  angrt: '‚àü',
  angrtvb: '‚äæ',
  angrtvbd: '‚¶ù',
  angsph: '‚à¢',
  angst: '√Ö',
  angzarr: '‚çº',
  aogon: 'ƒÖ',
  aopf: 'ùïí',
  ap: '‚âà',
  apE: '‚©∞',
  apacir: '‚©Ø',
  ape: '‚âä',
  apid: '‚âã',
  apos: "'",
  approx: '‚âà',
  approxeq: '‚âä',
  aring: '√•',
  ascr: 'ùí∂',
  ast: '*',
  asymp: '‚âà',
  asympeq: '‚âç',
  atilde: '√£',
  auml: '√§',
  awconint: '‚à≥',
  awint: '‚®ë',
  bNot: '‚´≠',
  backcong: '‚âå',
  backepsilon: 'œ∂',
  backprime: '‚Äµ',
  backsim: '‚àΩ',
  backsimeq: '‚ãç',
  barvee: '‚äΩ',
  barwed: '‚åÖ',
  barwedge: '‚åÖ',
  bbrk: '‚éµ',
  bbrktbrk: '‚é∂',
  bcong: '‚âå',
  bcy: '–±',
  bdquo: '‚Äû',
  becaus: '‚àµ',
  because: '‚àµ',
  bemptyv: '‚¶∞',
  bepsi: 'œ∂',
  bernou: '‚Ñ¨',
  beta: 'Œ≤',
  beth: '‚Ñ∂',
  between: '‚â¨',
  bfr: 'ùîü',
  bigcap: '‚ãÇ',
  bigcirc: '‚óØ',
  bigcup: '‚ãÉ',
  bigodot: '‚®Ä',
  bigoplus: '‚®Å',
  bigotimes: '‚®Ç',
  bigsqcup: '‚®Ü',
  bigstar: '‚òÖ',
  bigtriangledown: '‚ñΩ',
  bigtriangleup: '‚ñ≥',
  biguplus: '‚®Ñ',
  bigvee: '‚ãÅ',
  bigwedge: '‚ãÄ',
  bkarow: '‚§ç',
  blacklozenge: '‚ß´',
  blacksquare: '‚ñ™',
  blacktriangle: '‚ñ¥',
  blacktriangledown: '‚ñæ',
  blacktriangleleft: '‚óÇ',
  blacktriangleright: '‚ñ∏',
  blank: '‚ê£',
  blk12: '‚ñí',
  blk14: '‚ñë',
  blk34: '‚ñì',
  block: '‚ñà',
  bne: '=‚É•',
  bnequiv: '‚â°‚É•',
  bnot: '‚åê',
  bopf: 'ùïì',
  bot: '‚ä•',
  bottom: '‚ä•',
  bowtie: '‚ãà',
  boxDL: '‚ïó',
  boxDR: '‚ïî',
  boxDl: '‚ïñ',
  boxDr: '‚ïì',
  boxH: '‚ïê',
  boxHD: '‚ï¶',
  boxHU: '‚ï©',
  boxHd: '‚ï§',
  boxHu: '‚ïß',
  boxUL: '‚ïù',
  boxUR: '‚ïö',
  boxUl: '‚ïú',
  boxUr: '‚ïô',
  boxV: '‚ïë',
  boxVH: '‚ï¨',
  boxVL: '‚ï£',
  boxVR: '‚ï†',
  boxVh: '‚ï´',
  boxVl: '‚ï¢',
  boxVr: '‚ïü',
  boxbox: '‚ßâ',
  boxdL: '‚ïï',
  boxdR: '‚ïí',
  boxdl: '‚îê',
  boxdr: '‚îå',
  boxh: '‚îÄ',
  boxhD: '‚ï•',
  boxhU: '‚ï®',
  boxhd: '‚î¨',
  boxhu: '‚î¥',
  boxminus: '‚äü',
  boxplus: '‚äû',
  boxtimes: '‚ä†',
  boxuL: '‚ïõ',
  boxuR: '‚ïò',
  boxul: '‚îò',
  boxur: '‚îî',
  boxv: '‚îÇ',
  boxvH: '‚ï™',
  boxvL: '‚ï°',
  boxvR: '‚ïû',
  boxvh: '‚îº',
  boxvl: '‚î§',
  boxvr: '‚îú',
  bprime: '‚Äµ',
  breve: 'Àò',
  brvbar: '¬¶',
  bscr: 'ùí∑',
  bsemi: '‚Åè',
  bsim: '‚àΩ',
  bsime: '‚ãç',
  bsol: '\\',
  bsolb: '‚ßÖ',
  bsolhsub: '‚üà',
  bull: '‚Ä¢',
  bullet: '‚Ä¢',
  bump: '‚âé',
  bumpE: '‚™Æ',
  bumpe: '‚âè',
  bumpeq: '‚âè',
  cacute: 'ƒá',
  cap: '‚à©',
  capand: '‚©Ñ',
  capbrcup: '‚©â',
  capcap: '‚©ã',
  capcup: '‚©á',
  capdot: '‚©Ä',
  caps: '‚à©Ô∏Ä',
  caret: '‚ÅÅ',
  caron: 'Àá',
  ccaps: '‚©ç',
  ccaron: 'ƒç',
  ccedil: '√ß',
  ccirc: 'ƒâ',
  ccups: '‚©å',
  ccupssm: '‚©ê',
  cdot: 'ƒã',
  cedil: '¬∏',
  cemptyv: '‚¶≤',
  cent: '¬¢',
  centerdot: '¬∑',
  cfr: 'ùî†',
  chcy: '—á',
  check: '‚úì',
  checkmark: '‚úì',
  chi: 'œá',
  cir: '‚óã',
  cirE: '‚ßÉ',
  circ: 'ÀÜ',
  circeq: '‚âó',
  circlearrowleft: '‚Ü∫',
  circlearrowright: '‚Üª',
  circledR: '¬Æ',
  circledS: '‚ìà',
  circledast: '‚äõ',
  circledcirc: '‚äö',
  circleddash: '‚äù',
  cire: '‚âó',
  cirfnint: '‚®ê',
  cirmid: '‚´Ø',
  cirscir: '‚ßÇ',
  clubs: '‚ô£',
  clubsuit: '‚ô£',
  colon: ':',
  colone: '‚âî',
  coloneq: '‚âî',
  comma: ',',
  commat: '@',
  comp: '‚àÅ',
  compfn: '‚àò',
  complement: '‚àÅ',
  complexes: '‚ÑÇ',
  cong: '‚âÖ',
  congdot: '‚©≠',
  conint: '‚àÆ',
  copf: 'ùïî',
  coprod: '‚àê',
  copy: '¬©',
  copysr: '‚Ñó',
  crarr: '‚Üµ',
  cross: '‚úó',
  cscr: 'ùí∏',
  csub: '‚´è',
  csube: '‚´ë',
  csup: '‚´ê',
  csupe: '‚´í',
  ctdot: '‚ãØ',
  cudarrl: '‚§∏',
  cudarrr: '‚§µ',
  cuepr: '‚ãû',
  cuesc: '‚ãü',
  cularr: '‚Ü∂',
  cularrp: '‚§Ω',
  cup: '‚à™',
  cupbrcap: '‚©à',
  cupcap: '‚©Ü',
  cupcup: '‚©ä',
  cupdot: '‚äç',
  cupor: '‚©Ö',
  cups: '‚à™Ô∏Ä',
  curarr: '‚Ü∑',
  curarrm: '‚§º',
  curlyeqprec: '‚ãû',
  curlyeqsucc: '‚ãü',
  curlyvee: '‚ãé',
  curlywedge: '‚ãè',
  curren: '¬§',
  curvearrowleft: '‚Ü∂',
  curvearrowright: '‚Ü∑',
  cuvee: '‚ãé',
  cuwed: '‚ãè',
  cwconint: '‚à≤',
  cwint: '‚à±',
  cylcty: '‚å≠',
  dArr: '‚áì',
  dHar: '‚••',
  dagger: '‚Ä†',
  daleth: '‚Ñ∏',
  darr: '‚Üì',
  dash: '‚Äê',
  dashv: '‚ä£',
  dbkarow: '‚§è',
  dblac: 'Àù',
  dcaron: 'ƒè',
  dcy: '–¥',
  dd: '‚ÖÜ',
  ddagger: '‚Ä°',
  ddarr: '‚áä',
  ddotseq: '‚©∑',
  deg: '¬∞',
  delta: 'Œ¥',
  demptyv: '‚¶±',
  dfisht: '‚•ø',
  dfr: 'ùî°',
  dharl: '‚áÉ',
  dharr: '‚áÇ',
  diam: '‚ãÑ',
  diamond: '‚ãÑ',
  diamondsuit: '‚ô¶',
  diams: '‚ô¶',
  die: '¬®',
  digamma: 'œù',
  disin: '‚ã≤',
  div: '√∑',
  divide: '√∑',
  divideontimes: '‚ãá',
  divonx: '‚ãá',
  djcy: '—í',
  dlcorn: '‚åû',
  dlcrop: '‚åç',
  dollar: '$',
  dopf: 'ùïï',
  dot: 'Àô',
  doteq: '‚âê',
  doteqdot: '‚âë',
  dotminus: '‚à∏',
  dotplus: '‚àî',
  dotsquare: '‚ä°',
  doublebarwedge: '‚åÜ',
  downarrow: '‚Üì',
  downdownarrows: '‚áä',
  downharpoonleft: '‚áÉ',
  downharpoonright: '‚áÇ',
  drbkarow: '‚§ê',
  drcorn: '‚åü',
  drcrop: '‚åå',
  dscr: 'ùíπ',
  dscy: '—ï',
  dsol: '‚ß∂',
  dstrok: 'ƒë',
  dtdot: '‚ã±',
  dtri: '‚ñø',
  dtrif: '‚ñæ',
  duarr: '‚áµ',
  duhar: '‚•Ø',
  dwangle: '‚¶¶',
  dzcy: '—ü',
  dzigrarr: '‚üø',
  eDDot: '‚©∑',
  eDot: '‚âë',
  eacute: '√©',
  easter: '‚©Æ',
  ecaron: 'ƒõ',
  ecir: '‚âñ',
  ecirc: '√™',
  ecolon: '‚âï',
  ecy: '—ç',
  edot: 'ƒó',
  ee: '‚Öá',
  efDot: '‚âí',
  efr: 'ùî¢',
  eg: '‚™ö',
  egrave: '√®',
  egs: '‚™ñ',
  egsdot: '‚™ò',
  el: '‚™ô',
  elinters: '‚èß',
  ell: '‚Ñì',
  els: '‚™ï',
  elsdot: '‚™ó',
  emacr: 'ƒì',
  empty: '‚àÖ',
  emptyset: '‚àÖ',
  emptyv: '‚àÖ',
  emsp13: '‚ÄÑ',
  emsp14: '‚ÄÖ',
  emsp: '‚ÄÉ',
  eng: '≈ã',
  ensp: '‚ÄÇ',
  eogon: 'ƒô',
  eopf: 'ùïñ',
  epar: '‚ãï',
  eparsl: '‚ß£',
  eplus: '‚©±',
  epsi: 'Œµ',
  epsilon: 'Œµ',
  epsiv: 'œµ',
  eqcirc: '‚âñ',
  eqcolon: '‚âï',
  eqsim: '‚âÇ',
  eqslantgtr: '‚™ñ',
  eqslantless: '‚™ï',
  equals: '=',
  equest: '‚âü',
  equiv: '‚â°',
  equivDD: '‚©∏',
  eqvparsl: '‚ß•',
  erDot: '‚âì',
  erarr: '‚•±',
  escr: '‚ÑØ',
  esdot: '‚âê',
  esim: '‚âÇ',
  eta: 'Œ∑',
  eth: '√∞',
  euml: '√´',
  euro: '‚Ç¨',
  excl: '!',
  exist: '‚àÉ',
  expectation: '‚Ñ∞',
  exponentiale: '‚Öá',
  fallingdotseq: '‚âí',
  fcy: '—Ñ',
  female: '‚ôÄ',
  ffilig: 'Ô¨É',
  fflig: 'Ô¨Ä',
  ffllig: 'Ô¨Ñ',
  ffr: 'ùî£',
  filig: 'Ô¨Å',
  fjlig: 'fj',
  flat: '‚ô≠',
  fllig: 'Ô¨Ç',
  fltns: '‚ñ±',
  fnof: '∆í',
  fopf: 'ùïó',
  forall: '‚àÄ',
  fork: '‚ãî',
  forkv: '‚´ô',
  fpartint: '‚®ç',
  frac12: '¬Ω',
  frac13: '‚Öì',
  frac14: '¬º',
  frac15: '‚Öï',
  frac16: '‚Öô',
  frac18: '‚Öõ',
  frac23: '‚Öî',
  frac25: '‚Öñ',
  frac34: '¬æ',
  frac35: '‚Öó',
  frac38: '‚Öú',
  frac45: '‚Öò',
  frac56: '‚Öö',
  frac58: '‚Öù',
  frac78: '‚Öû',
  frasl: '‚ÅÑ',
  frown: '‚å¢',
  fscr: 'ùíª',
  gE: '‚âß',
  gEl: '‚™å',
  gacute: '«µ',
  gamma: 'Œ≥',
  gammad: 'œù',
  gap: '‚™Ü',
  gbreve: 'ƒü',
  gcirc: 'ƒù',
  gcy: '–≥',
  gdot: 'ƒ°',
  ge: '‚â•',
  gel: '‚ãõ',
  geq: '‚â•',
  geqq: '‚âß',
  geqslant: '‚©æ',
  ges: '‚©æ',
  gescc: '‚™©',
  gesdot: '‚™Ä',
  gesdoto: '‚™Ç',
  gesdotol: '‚™Ñ',
  gesl: '‚ãõÔ∏Ä',
  gesles: '‚™î',
  gfr: 'ùî§',
  gg: '‚â´',
  ggg: '‚ãô',
  gimel: '‚Ñ∑',
  gjcy: '—ì',
  gl: '‚â∑',
  glE: '‚™í',
  gla: '‚™•',
  glj: '‚™§',
  gnE: '‚â©',
  gnap: '‚™ä',
  gnapprox: '‚™ä',
  gne: '‚™à',
  gneq: '‚™à',
  gneqq: '‚â©',
  gnsim: '‚ãß',
  gopf: 'ùïò',
  grave: '`',
  gscr: '‚Ñä',
  gsim: '‚â≥',
  gsime: '‚™é',
  gsiml: '‚™ê',
  gt: '>',
  gtcc: '‚™ß',
  gtcir: '‚©∫',
  gtdot: '‚ãó',
  gtlPar: '‚¶ï',
  gtquest: '‚©º',
  gtrapprox: '‚™Ü',
  gtrarr: '‚•∏',
  gtrdot: '‚ãó',
  gtreqless: '‚ãõ',
  gtreqqless: '‚™å',
  gtrless: '‚â∑',
  gtrsim: '‚â≥',
  gvertneqq: '‚â©Ô∏Ä',
  gvnE: '‚â©Ô∏Ä',
  hArr: '‚áî',
  hairsp: '‚Ää',
  half: '¬Ω',
  hamilt: '‚Ñã',
  hardcy: '—ä',
  harr: '‚Üî',
  harrcir: '‚•à',
  harrw: '‚Ü≠',
  hbar: '‚Ñè',
  hcirc: 'ƒ•',
  hearts: '‚ô•',
  heartsuit: '‚ô•',
  hellip: '‚Ä¶',
  hercon: '‚äπ',
  hfr: 'ùî•',
  hksearow: '‚§•',
  hkswarow: '‚§¶',
  hoarr: '‚áø',
  homtht: '‚àª',
  hookleftarrow: '‚Ü©',
  hookrightarrow: '‚Ü™',
  hopf: 'ùïô',
  horbar: '‚Äï',
  hscr: 'ùíΩ',
  hslash: '‚Ñè',
  hstrok: 'ƒß',
  hybull: '‚ÅÉ',
  hyphen: '‚Äê',
  iacute: '√≠',
  ic: '‚Å£',
  icirc: '√Æ',
  icy: '–∏',
  iecy: '–µ',
  iexcl: '¬°',
  iff: '‚áî',
  ifr: 'ùî¶',
  igrave: '√¨',
  ii: '‚Öà',
  iiiint: '‚®å',
  iiint: '‚à≠',
  iinfin: '‚ßú',
  iiota: '‚Ñ©',
  ijlig: 'ƒ≥',
  imacr: 'ƒ´',
  image: '‚Ñë',
  imagline: '‚Ñê',
  imagpart: '‚Ñë',
  imath: 'ƒ±',
  imof: '‚ä∑',
  imped: '∆µ',
  in: '‚àà',
  incare: '‚ÑÖ',
  infin: '‚àû',
  infintie: '‚ßù',
  inodot: 'ƒ±',
  int: '‚à´',
  intcal: '‚ä∫',
  integers: '‚Ñ§',
  intercal: '‚ä∫',
  intlarhk: '‚®ó',
  intprod: '‚®º',
  iocy: '—ë',
  iogon: 'ƒØ',
  iopf: 'ùïö',
  iota: 'Œπ',
  iprod: '‚®º',
  iquest: '¬ø',
  iscr: 'ùíæ',
  isin: '‚àà',
  isinE: '‚ãπ',
  isindot: '‚ãµ',
  isins: '‚ã¥',
  isinsv: '‚ã≥',
  isinv: '‚àà',
  it: '‚Å¢',
  itilde: 'ƒ©',
  iukcy: '—ñ',
  iuml: '√Ø',
  jcirc: 'ƒµ',
  jcy: '–π',
  jfr: 'ùîß',
  jmath: '»∑',
  jopf: 'ùïõ',
  jscr: 'ùíø',
  jsercy: '—ò',
  jukcy: '—î',
  kappa: 'Œ∫',
  kappav: 'œ∞',
  kcedil: 'ƒ∑',
  kcy: '–∫',
  kfr: 'ùî®',
  kgreen: 'ƒ∏',
  khcy: '—Ö',
  kjcy: '—ú',
  kopf: 'ùïú',
  kscr: 'ùìÄ',
  lAarr: '‚áö',
  lArr: '‚áê',
  lAtail: '‚§õ',
  lBarr: '‚§é',
  lE: '‚â¶',
  lEg: '‚™ã',
  lHar: '‚•¢',
  lacute: 'ƒ∫',
  laemptyv: '‚¶¥',
  lagran: '‚Ñí',
  lambda: 'Œª',
  lang: '‚ü®',
  langd: '‚¶ë',
  langle: '‚ü®',
  lap: '‚™Ö',
  laquo: '¬´',
  larr: '‚Üê',
  larrb: '‚á§',
  larrbfs: '‚§ü',
  larrfs: '‚§ù',
  larrhk: '‚Ü©',
  larrlp: '‚Ü´',
  larrpl: '‚§π',
  larrsim: '‚•≥',
  larrtl: '‚Ü¢',
  lat: '‚™´',
  latail: '‚§ô',
  late: '‚™≠',
  lates: '‚™≠Ô∏Ä',
  lbarr: '‚§å',
  lbbrk: '‚ù≤',
  lbrace: '{',
  lbrack: '[',
  lbrke: '‚¶ã',
  lbrksld: '‚¶è',
  lbrkslu: '‚¶ç',
  lcaron: 'ƒæ',
  lcedil: 'ƒº',
  lceil: '‚åà',
  lcub: '{',
  lcy: '–ª',
  ldca: '‚§∂',
  ldquo: '‚Äú',
  ldquor: '‚Äû',
  ldrdhar: '‚•ß',
  ldrushar: '‚•ã',
  ldsh: '‚Ü≤',
  le: '‚â§',
  leftarrow: '‚Üê',
  leftarrowtail: '‚Ü¢',
  leftharpoondown: '‚ÜΩ',
  leftharpoonup: '‚Üº',
  leftleftarrows: '‚áá',
  leftrightarrow: '‚Üî',
  leftrightarrows: '‚áÜ',
  leftrightharpoons: '‚áã',
  leftrightsquigarrow: '‚Ü≠',
  leftthreetimes: '‚ãã',
  leg: '‚ãö',
  leq: '‚â§',
  leqq: '‚â¶',
  leqslant: '‚©Ω',
  les: '‚©Ω',
  lescc: '‚™®',
  lesdot: '‚©ø',
  lesdoto: '‚™Å',
  lesdotor: '‚™É',
  lesg: '‚ãöÔ∏Ä',
  lesges: '‚™ì',
  lessapprox: '‚™Ö',
  lessdot: '‚ãñ',
  lesseqgtr: '‚ãö',
  lesseqqgtr: '‚™ã',
  lessgtr: '‚â∂',
  lesssim: '‚â≤',
  lfisht: '‚•º',
  lfloor: '‚åä',
  lfr: 'ùî©',
  lg: '‚â∂',
  lgE: '‚™ë',
  lhard: '‚ÜΩ',
  lharu: '‚Üº',
  lharul: '‚•™',
  lhblk: '‚ñÑ',
  ljcy: '—ô',
  ll: '‚â™',
  llarr: '‚áá',
  llcorner: '‚åû',
  llhard: '‚•´',
  lltri: '‚ó∫',
  lmidot: '≈Ä',
  lmoust: '‚é∞',
  lmoustache: '‚é∞',
  lnE: '‚â®',
  lnap: '‚™â',
  lnapprox: '‚™â',
  lne: '‚™á',
  lneq: '‚™á',
  lneqq: '‚â®',
  lnsim: '‚ã¶',
  loang: '‚ü¨',
  loarr: '‚áΩ',
  lobrk: '‚ü¶',
  longleftarrow: '‚üµ',
  longleftrightarrow: '‚ü∑',
  longmapsto: '‚üº',
  longrightarrow: '‚ü∂',
  looparrowleft: '‚Ü´',
  looparrowright: '‚Ü¨',
  lopar: '‚¶Ö',
  lopf: 'ùïù',
  loplus: '‚®≠',
  lotimes: '‚®¥',
  lowast: '‚àó',
  lowbar: '_',
  loz: '‚óä',
  lozenge: '‚óä',
  lozf: '‚ß´',
  lpar: '(',
  lparlt: '‚¶ì',
  lrarr: '‚áÜ',
  lrcorner: '‚åü',
  lrhar: '‚áã',
  lrhard: '‚•≠',
  lrm: '‚Äé',
  lrtri: '‚äø',
  lsaquo: '‚Äπ',
  lscr: 'ùìÅ',
  lsh: '‚Ü∞',
  lsim: '‚â≤',
  lsime: '‚™ç',
  lsimg: '‚™è',
  lsqb: '[',
  lsquo: '‚Äò',
  lsquor: '‚Äö',
  lstrok: '≈Ç',
  lt: '<',
  ltcc: '‚™¶',
  ltcir: '‚©π',
  ltdot: '‚ãñ',
  lthree: '‚ãã',
  ltimes: '‚ãâ',
  ltlarr: '‚•∂',
  ltquest: '‚©ª',
  ltrPar: '‚¶ñ',
  ltri: '‚óÉ',
  ltrie: '‚ä¥',
  ltrif: '‚óÇ',
  lurdshar: '‚•ä',
  luruhar: '‚•¶',
  lvertneqq: '‚â®Ô∏Ä',
  lvnE: '‚â®Ô∏Ä',
  mDDot: '‚à∫',
  macr: '¬Ø',
  male: '‚ôÇ',
  malt: '‚ú†',
  maltese: '‚ú†',
  map: '‚Ü¶',
  mapsto: '‚Ü¶',
  mapstodown: '‚Üß',
  mapstoleft: '‚Ü§',
  mapstoup: '‚Ü•',
  marker: '‚ñÆ',
  mcomma: '‚®©',
  mcy: '–º',
  mdash: '‚Äî',
  measuredangle: '‚à°',
  mfr: 'ùî™',
  mho: '‚Ñß',
  micro: '¬µ',
  mid: '‚à£',
  midast: '*',
  midcir: '‚´∞',
  middot: '¬∑',
  minus: '‚àí',
  minusb: '‚äü',
  minusd: '‚à∏',
  minusdu: '‚®™',
  mlcp: '‚´õ',
  mldr: '‚Ä¶',
  mnplus: '‚àì',
  models: '‚äß',
  mopf: 'ùïû',
  mp: '‚àì',
  mscr: 'ùìÇ',
  mstpos: '‚àæ',
  mu: 'Œº',
  multimap: '‚ä∏',
  mumap: '‚ä∏',
  nGg: '‚ãôÃ∏',
  nGt: '‚â´‚Éí',
  nGtv: '‚â´Ã∏',
  nLeftarrow: '‚áç',
  nLeftrightarrow: '‚áé',
  nLl: '‚ãòÃ∏',
  nLt: '‚â™‚Éí',
  nLtv: '‚â™Ã∏',
  nRightarrow: '‚áè',
  nVDash: '‚äØ',
  nVdash: '‚äÆ',
  nabla: '‚àá',
  nacute: '≈Ñ',
  nang: '‚à†‚Éí',
  nap: '‚ââ',
  napE: '‚©∞Ã∏',
  napid: '‚âãÃ∏',
  napos: '≈â',
  napprox: '‚ââ',
  natur: '‚ôÆ',
  natural: '‚ôÆ',
  naturals: '‚Ñï',
  nbsp: '¬†',
  nbump: '‚âéÃ∏',
  nbumpe: '‚âèÃ∏',
  ncap: '‚©É',
  ncaron: '≈à',
  ncedil: '≈Ü',
  ncong: '‚âá',
  ncongdot: '‚©≠Ã∏',
  ncup: '‚©Ç',
  ncy: '–Ω',
  ndash: '‚Äì',
  ne: '‚â†',
  neArr: '‚áó',
  nearhk: '‚§§',
  nearr: '‚Üó',
  nearrow: '‚Üó',
  nedot: '‚âêÃ∏',
  nequiv: '‚â¢',
  nesear: '‚§®',
  nesim: '‚âÇÃ∏',
  nexist: '‚àÑ',
  nexists: '‚àÑ',
  nfr: 'ùî´',
  ngE: '‚âßÃ∏',
  nge: '‚â±',
  ngeq: '‚â±',
  ngeqq: '‚âßÃ∏',
  ngeqslant: '‚©æÃ∏',
  nges: '‚©æÃ∏',
  ngsim: '‚âµ',
  ngt: '‚âØ',
  ngtr: '‚âØ',
  nhArr: '‚áé',
  nharr: '‚ÜÆ',
  nhpar: '‚´≤',
  ni: '‚àã',
  nis: '‚ãº',
  nisd: '‚ã∫',
  niv: '‚àã',
  njcy: '—ö',
  nlArr: '‚áç',
  nlE: '‚â¶Ã∏',
  nlarr: '‚Üö',
  nldr: '‚Ä•',
  nle: '‚â∞',
  nleftarrow: '‚Üö',
  nleftrightarrow: '‚ÜÆ',
  nleq: '‚â∞',
  nleqq: '‚â¶Ã∏',
  nleqslant: '‚©ΩÃ∏',
  nles: '‚©ΩÃ∏',
  nless: '‚âÆ',
  nlsim: '‚â¥',
  nlt: '‚âÆ',
  nltri: '‚ã™',
  nltrie: '‚ã¨',
  nmid: '‚à§',
  nopf: 'ùïü',
  not: '¬¨',
  notin: '‚àâ',
  notinE: '‚ãπÃ∏',
  notindot: '‚ãµÃ∏',
  notinva: '‚àâ',
  notinvb: '‚ã∑',
  notinvc: '‚ã∂',
  notni: '‚àå',
  notniva: '‚àå',
  notnivb: '‚ãæ',
  notnivc: '‚ãΩ',
  npar: '‚à¶',
  nparallel: '‚à¶',
  nparsl: '‚´Ω‚É•',
  npart: '‚àÇÃ∏',
  npolint: '‚®î',
  npr: '‚äÄ',
  nprcue: '‚ã†',
  npre: '‚™ØÃ∏',
  nprec: '‚äÄ',
  npreceq: '‚™ØÃ∏',
  nrArr: '‚áè',
  nrarr: '‚Üõ',
  nrarrc: '‚§≥Ã∏',
  nrarrw: '‚ÜùÃ∏',
  nrightarrow: '‚Üõ',
  nrtri: '‚ã´',
  nrtrie: '‚ã≠',
  nsc: '‚äÅ',
  nsccue: '‚ã°',
  nsce: '‚™∞Ã∏',
  nscr: 'ùìÉ',
  nshortmid: '‚à§',
  nshortparallel: '‚à¶',
  nsim: '‚âÅ',
  nsime: '‚âÑ',
  nsimeq: '‚âÑ',
  nsmid: '‚à§',
  nspar: '‚à¶',
  nsqsube: '‚ã¢',
  nsqsupe: '‚ã£',
  nsub: '‚äÑ',
  nsubE: '‚´ÖÃ∏',
  nsube: '‚äà',
  nsubset: '‚äÇ‚Éí',
  nsubseteq: '‚äà',
  nsubseteqq: '‚´ÖÃ∏',
  nsucc: '‚äÅ',
  nsucceq: '‚™∞Ã∏',
  nsup: '‚äÖ',
  nsupE: '‚´ÜÃ∏',
  nsupe: '‚äâ',
  nsupset: '‚äÉ‚Éí',
  nsupseteq: '‚äâ',
  nsupseteqq: '‚´ÜÃ∏',
  ntgl: '‚âπ',
  ntilde: '√±',
  ntlg: '‚â∏',
  ntriangleleft: '‚ã™',
  ntrianglelefteq: '‚ã¨',
  ntriangleright: '‚ã´',
  ntrianglerighteq: '‚ã≠',
  nu: 'ŒΩ',
  num: '#',
  numero: '‚Ññ',
  numsp: '‚Äá',
  nvDash: '‚ä≠',
  nvHarr: '‚§Ñ',
  nvap: '‚âç‚Éí',
  nvdash: '‚ä¨',
  nvge: '‚â•‚Éí',
  nvgt: '>‚Éí',
  nvinfin: '‚ßû',
  nvlArr: '‚§Ç',
  nvle: '‚â§‚Éí',
  nvlt: '<‚Éí',
  nvltrie: '‚ä¥‚Éí',
  nvrArr: '‚§É',
  nvrtrie: '‚äµ‚Éí',
  nvsim: '‚àº‚Éí',
  nwArr: '‚áñ',
  nwarhk: '‚§£',
  nwarr: '‚Üñ',
  nwarrow: '‚Üñ',
  nwnear: '‚§ß',
  oS: '‚ìà',
  oacute: '√≥',
  oast: '‚äõ',
  ocir: '‚äö',
  ocirc: '√¥',
  ocy: '–æ',
  odash: '‚äù',
  odblac: '≈ë',
  odiv: '‚®∏',
  odot: '‚äô',
  odsold: '‚¶º',
  oelig: '≈ì',
  ofcir: '‚¶ø',
  ofr: 'ùî¨',
  ogon: 'Àõ',
  ograve: '√≤',
  ogt: '‚ßÅ',
  ohbar: '‚¶µ',
  ohm: 'Œ©',
  oint: '‚àÆ',
  olarr: '‚Ü∫',
  olcir: '‚¶æ',
  olcross: '‚¶ª',
  oline: '‚Äæ',
  olt: '‚ßÄ',
  omacr: '≈ç',
  omega: 'œâ',
  omicron: 'Œø',
  omid: '‚¶∂',
  ominus: '‚äñ',
  oopf: 'ùï†',
  opar: '‚¶∑',
  operp: '‚¶π',
  oplus: '‚äï',
  or: '‚à®',
  orarr: '‚Üª',
  ord: '‚©ù',
  order: '‚Ñ¥',
  orderof: '‚Ñ¥',
  ordf: '¬™',
  ordm: '¬∫',
  origof: '‚ä∂',
  oror: '‚©ñ',
  orslope: '‚©ó',
  orv: '‚©õ',
  oscr: '‚Ñ¥',
  oslash: '√∏',
  osol: '‚äò',
  otilde: '√µ',
  otimes: '‚äó',
  otimesas: '‚®∂',
  ouml: '√∂',
  ovbar: '‚åΩ',
  par: '‚à•',
  para: '¬∂',
  parallel: '‚à•',
  parsim: '‚´≥',
  parsl: '‚´Ω',
  part: '‚àÇ',
  pcy: '–ø',
  percnt: '%',
  period: '.',
  permil: '‚Ä∞',
  perp: '‚ä•',
  pertenk: '‚Ä±',
  pfr: 'ùî≠',
  phi: 'œÜ',
  phiv: 'œï',
  phmmat: '‚Ñ≥',
  phone: '‚òé',
  pi: 'œÄ',
  pitchfork: '‚ãî',
  piv: 'œñ',
  planck: '‚Ñè',
  planckh: '‚Ñé',
  plankv: '‚Ñè',
  plus: '+',
  plusacir: '‚®£',
  plusb: '‚äû',
  pluscir: '‚®¢',
  plusdo: '‚àî',
  plusdu: '‚®•',
  pluse: '‚©≤',
  plusmn: '¬±',
  plussim: '‚®¶',
  plustwo: '‚®ß',
  pm: '¬±',
  pointint: '‚®ï',
  popf: 'ùï°',
  pound: '¬£',
  pr: '‚â∫',
  prE: '‚™≥',
  prap: '‚™∑',
  prcue: '‚âº',
  pre: '‚™Ø',
  prec: '‚â∫',
  precapprox: '‚™∑',
  preccurlyeq: '‚âº',
  preceq: '‚™Ø',
  precnapprox: '‚™π',
  precneqq: '‚™µ',
  precnsim: '‚ã®',
  precsim: '‚âæ',
  prime: '‚Ä≤',
  primes: '‚Ñô',
  prnE: '‚™µ',
  prnap: '‚™π',
  prnsim: '‚ã®',
  prod: '‚àè',
  profalar: '‚åÆ',
  profline: '‚åí',
  profsurf: '‚åì',
  prop: '‚àù',
  propto: '‚àù',
  prsim: '‚âæ',
  prurel: '‚ä∞',
  pscr: 'ùìÖ',
  psi: 'œà',
  puncsp: '‚Äà',
  qfr: 'ùîÆ',
  qint: '‚®å',
  qopf: 'ùï¢',
  qprime: '‚Åó',
  qscr: 'ùìÜ',
  quaternions: '‚Ñç',
  quatint: '‚®ñ',
  quest: '?',
  questeq: '‚âü',
  quot: '"',
  rAarr: '‚áõ',
  rArr: '‚áí',
  rAtail: '‚§ú',
  rBarr: '‚§è',
  rHar: '‚•§',
  race: '‚àΩÃ±',
  racute: '≈ï',
  radic: '‚àö',
  raemptyv: '‚¶≥',
  rang: '‚ü©',
  rangd: '‚¶í',
  range: '‚¶•',
  rangle: '‚ü©',
  raquo: '¬ª',
  rarr: '‚Üí',
  rarrap: '‚•µ',
  rarrb: '‚á•',
  rarrbfs: '‚§†',
  rarrc: '‚§≥',
  rarrfs: '‚§û',
  rarrhk: '‚Ü™',
  rarrlp: '‚Ü¨',
  rarrpl: '‚•Ö',
  rarrsim: '‚•¥',
  rarrtl: '‚Ü£',
  rarrw: '‚Üù',
  ratail: '‚§ö',
  ratio: '‚à∂',
  rationals: '‚Ñö',
  rbarr: '‚§ç',
  rbbrk: '‚ù≥',
  rbrace: '}',
  rbrack: ']',
  rbrke: '‚¶å',
  rbrksld: '‚¶é',
  rbrkslu: '‚¶ê',
  rcaron: '≈ô',
  rcedil: '≈ó',
  rceil: '‚åâ',
  rcub: '}',
  rcy: '—Ä',
  rdca: '‚§∑',
  rdldhar: '‚•©',
  rdquo: '‚Äù',
  rdquor: '‚Äù',
  rdsh: '‚Ü≥',
  real: '‚Ñú',
  realine: '‚Ñõ',
  realpart: '‚Ñú',
  reals: '‚Ñù',
  rect: '‚ñ≠',
  reg: '¬Æ',
  rfisht: '‚•Ω',
  rfloor: '‚åã',
  rfr: 'ùîØ',
  rhard: '‚áÅ',
  rharu: '‚áÄ',
  rharul: '‚•¨',
  rho: 'œÅ',
  rhov: 'œ±',
  rightarrow: '‚Üí',
  rightarrowtail: '‚Ü£',
  rightharpoondown: '‚áÅ',
  rightharpoonup: '‚áÄ',
  rightleftarrows: '‚áÑ',
  rightleftharpoons: '‚áå',
  rightrightarrows: '‚áâ',
  rightsquigarrow: '‚Üù',
  rightthreetimes: '‚ãå',
  ring: 'Àö',
  risingdotseq: '‚âì',
  rlarr: '‚áÑ',
  rlhar: '‚áå',
  rlm: '‚Äè',
  rmoust: '‚é±',
  rmoustache: '‚é±',
  rnmid: '‚´Æ',
  roang: '‚ü≠',
  roarr: '‚áæ',
  robrk: '‚üß',
  ropar: '‚¶Ü',
  ropf: 'ùï£',
  roplus: '‚®Æ',
  rotimes: '‚®µ',
  rpar: ')',
  rpargt: '‚¶î',
  rppolint: '‚®í',
  rrarr: '‚áâ',
  rsaquo: '‚Ä∫',
  rscr: 'ùìá',
  rsh: '‚Ü±',
  rsqb: ']',
  rsquo: '‚Äô',
  rsquor: '‚Äô',
  rthree: '‚ãå',
  rtimes: '‚ãä',
  rtri: '‚ñπ',
  rtrie: '‚äµ',
  rtrif: '‚ñ∏',
  rtriltri: '‚ßé',
  ruluhar: '‚•®',
  rx: '‚Ñû',
  sacute: '≈õ',
  sbquo: '‚Äö',
  sc: '‚âª',
  scE: '‚™¥',
  scap: '‚™∏',
  scaron: '≈°',
  sccue: '‚âΩ',
  sce: '‚™∞',
  scedil: '≈ü',
  scirc: '≈ù',
  scnE: '‚™∂',
  scnap: '‚™∫',
  scnsim: '‚ã©',
  scpolint: '‚®ì',
  scsim: '‚âø',
  scy: '—Å',
  sdot: '‚ãÖ',
  sdotb: '‚ä°',
  sdote: '‚©¶',
  seArr: '‚áò',
  searhk: '‚§•',
  searr: '‚Üò',
  searrow: '‚Üò',
  sect: '¬ß',
  semi: ';',
  seswar: '‚§©',
  setminus: '‚àñ',
  setmn: '‚àñ',
  sext: '‚ú∂',
  sfr: 'ùî∞',
  sfrown: '‚å¢',
  sharp: '‚ôØ',
  shchcy: '—â',
  shcy: '—à',
  shortmid: '‚à£',
  shortparallel: '‚à•',
  shy: '¬≠',
  sigma: 'œÉ',
  sigmaf: 'œÇ',
  sigmav: 'œÇ',
  sim: '‚àº',
  simdot: '‚©™',
  sime: '‚âÉ',
  simeq: '‚âÉ',
  simg: '‚™û',
  simgE: '‚™†',
  siml: '‚™ù',
  simlE: '‚™ü',
  simne: '‚âÜ',
  simplus: '‚®§',
  simrarr: '‚•≤',
  slarr: '‚Üê',
  smallsetminus: '‚àñ',
  smashp: '‚®≥',
  smeparsl: '‚ß§',
  smid: '‚à£',
  smile: '‚å£',
  smt: '‚™™',
  smte: '‚™¨',
  smtes: '‚™¨Ô∏Ä',
  softcy: '—å',
  sol: '/',
  solb: '‚ßÑ',
  solbar: '‚åø',
  sopf: 'ùï§',
  spades: '‚ô†',
  spadesuit: '‚ô†',
  spar: '‚à•',
  sqcap: '‚äì',
  sqcaps: '‚äìÔ∏Ä',
  sqcup: '‚äî',
  sqcups: '‚äîÔ∏Ä',
  sqsub: '‚äè',
  sqsube: '‚äë',
  sqsubset: '‚äè',
  sqsubseteq: '‚äë',
  sqsup: '‚äê',
  sqsupe: '‚äí',
  sqsupset: '‚äê',
  sqsupseteq: '‚äí',
  squ: '‚ñ°',
  square: '‚ñ°',
  squarf: '‚ñ™',
  squf: '‚ñ™',
  srarr: '‚Üí',
  sscr: 'ùìà',
  ssetmn: '‚àñ',
  ssmile: '‚å£',
  sstarf: '‚ãÜ',
  star: '‚òÜ',
  starf: '‚òÖ',
  straightepsilon: 'œµ',
  straightphi: 'œï',
  strns: '¬Ø',
  sub: '‚äÇ',
  subE: '‚´Ö',
  subdot: '‚™Ω',
  sube: '‚äÜ',
  subedot: '‚´É',
  submult: '‚´Å',
  subnE: '‚´ã',
  subne: '‚ää',
  subplus: '‚™ø',
  subrarr: '‚•π',
  subset: '‚äÇ',
  subseteq: '‚äÜ',
  subseteqq: '‚´Ö',
  subsetneq: '‚ää',
  subsetneqq: '‚´ã',
  subsim: '‚´á',
  subsub: '‚´ï',
  subsup: '‚´ì',
  succ: '‚âª',
  succapprox: '‚™∏',
  succcurlyeq: '‚âΩ',
  succeq: '‚™∞',
  succnapprox: '‚™∫',
  succneqq: '‚™∂',
  succnsim: '‚ã©',
  succsim: '‚âø',
  sum: '‚àë',
  sung: '‚ô™',
  sup1: '¬π',
  sup2: '¬≤',
  sup3: '¬≥',
  sup: '‚äÉ',
  supE: '‚´Ü',
  supdot: '‚™æ',
  supdsub: '‚´ò',
  supe: '‚äá',
  supedot: '‚´Ñ',
  suphsol: '‚üâ',
  suphsub: '‚´ó',
  suplarr: '‚•ª',
  supmult: '‚´Ç',
  supnE: '‚´å',
  supne: '‚äã',
  supplus: '‚´Ä',
  supset: '‚äÉ',
  supseteq: '‚äá',
  supseteqq: '‚´Ü',
  supsetneq: '‚äã',
  supsetneqq: '‚´å',
  supsim: '‚´à',
  supsub: '‚´î',
  supsup: '‚´ñ',
  swArr: '‚áô',
  swarhk: '‚§¶',
  swarr: '‚Üô',
  swarrow: '‚Üô',
  swnwar: '‚§™',
  szlig: '√ü',
  target: '‚åñ',
  tau: 'œÑ',
  tbrk: '‚é¥',
  tcaron: '≈•',
  tcedil: '≈£',
  tcy: '—Ç',
  tdot: '‚Éõ',
  telrec: '‚åï',
  tfr: 'ùî±',
  there4: '‚à¥',
  therefore: '‚à¥',
  theta: 'Œ∏',
  thetasym: 'œë',
  thetav: 'œë',
  thickapprox: '‚âà',
  thicksim: '‚àº',
  thinsp: '‚Äâ',
  thkap: '‚âà',
  thksim: '‚àº',
  thorn: '√æ',
  tilde: 'Àú',
  times: '√ó',
  timesb: '‚ä†',
  timesbar: '‚®±',
  timesd: '‚®∞',
  tint: '‚à≠',
  toea: '‚§®',
  top: '‚ä§',
  topbot: '‚å∂',
  topcir: '‚´±',
  topf: 'ùï•',
  topfork: '‚´ö',
  tosa: '‚§©',
  tprime: '‚Ä¥',
  trade: '‚Ñ¢',
  triangle: '‚ñµ',
  triangledown: '‚ñø',
  triangleleft: '‚óÉ',
  trianglelefteq: '‚ä¥',
  triangleq: '‚âú',
  triangleright: '‚ñπ',
  trianglerighteq: '‚äµ',
  tridot: '‚ó¨',
  trie: '‚âú',
  triminus: '‚®∫',
  triplus: '‚®π',
  trisb: '‚ßç',
  tritime: '‚®ª',
  trpezium: '‚è¢',
  tscr: 'ùìâ',
  tscy: '—Ü',
  tshcy: '—õ',
  tstrok: '≈ß',
  twixt: '‚â¨',
  twoheadleftarrow: '‚Üû',
  twoheadrightarrow: '‚Ü†',
  uArr: '‚áë',
  uHar: '‚•£',
  uacute: '√∫',
  uarr: '‚Üë',
  ubrcy: '—û',
  ubreve: '≈≠',
  ucirc: '√ª',
  ucy: '—É',
  udarr: '‚áÖ',
  udblac: '≈±',
  udhar: '‚•Æ',
  ufisht: '‚•æ',
  ufr: 'ùî≤',
  ugrave: '√π',
  uharl: '‚Üø',
  uharr: '‚Üæ',
  uhblk: '‚ñÄ',
  ulcorn: '‚åú',
  ulcorner: '‚åú',
  ulcrop: '‚åè',
  ultri: '‚ó∏',
  umacr: '≈´',
  uml: '¬®',
  uogon: '≈≥',
  uopf: 'ùï¶',
  uparrow: '‚Üë',
  updownarrow: '‚Üï',
  upharpoonleft: '‚Üø',
  upharpoonright: '‚Üæ',
  uplus: '‚äé',
  upsi: 'œÖ',
  upsih: 'œí',
  upsilon: 'œÖ',
  upuparrows: '‚áà',
  urcorn: '‚åù',
  urcorner: '‚åù',
  urcrop: '‚åé',
  uring: '≈Ø',
  urtri: '‚óπ',
  uscr: 'ùìä',
  utdot: '‚ã∞',
  utilde: '≈©',
  utri: '‚ñµ',
  utrif: '‚ñ¥',
  uuarr: '‚áà',
  uuml: '√º',
  uwangle: '‚¶ß',
  vArr: '‚áï',
  vBar: '‚´®',
  vBarv: '‚´©',
  vDash: '‚ä®',
  vangrt: '‚¶ú',
  varepsilon: 'œµ',
  varkappa: 'œ∞',
  varnothing: '‚àÖ',
  varphi: 'œï',
  varpi: 'œñ',
  varpropto: '‚àù',
  varr: '‚Üï',
  varrho: 'œ±',
  varsigma: 'œÇ',
  varsubsetneq: '‚ääÔ∏Ä',
  varsubsetneqq: '‚´ãÔ∏Ä',
  varsupsetneq: '‚äãÔ∏Ä',
  varsupsetneqq: '‚´åÔ∏Ä',
  vartheta: 'œë',
  vartriangleleft: '‚ä≤',
  vartriangleright: '‚ä≥',
  vcy: '–≤',
  vdash: '‚ä¢',
  vee: '‚à®',
  veebar: '‚äª',
  veeeq: '‚âö',
  vellip: '‚ãÆ',
  verbar: '|',
  vert: '|',
  vfr: 'ùî≥',
  vltri: '‚ä≤',
  vnsub: '‚äÇ‚Éí',
  vnsup: '‚äÉ‚Éí',
  vopf: 'ùïß',
  vprop: '‚àù',
  vrtri: '‚ä≥',
  vscr: 'ùìã',
  vsubnE: '‚´ãÔ∏Ä',
  vsubne: '‚ääÔ∏Ä',
  vsupnE: '‚´åÔ∏Ä',
  vsupne: '‚äãÔ∏Ä',
  vzigzag: '‚¶ö',
  wcirc: '≈µ',
  wedbar: '‚©ü',
  wedge: '‚àß',
  wedgeq: '‚âô',
  weierp: '‚Ñò',
  wfr: 'ùî¥',
  wopf: 'ùï®',
  wp: '‚Ñò',
  wr: '‚âÄ',
  wreath: '‚âÄ',
  wscr: 'ùìå',
  xcap: '‚ãÇ',
  xcirc: '‚óØ',
  xcup: '‚ãÉ',
  xdtri: '‚ñΩ',
  xfr: 'ùîµ',
  xhArr: '‚ü∫',
  xharr: '‚ü∑',
  xi: 'Œæ',
  xlArr: '‚ü∏',
  xlarr: '‚üµ',
  xmap: '‚üº',
  xnis: '‚ãª',
  xodot: '‚®Ä',
  xopf: 'ùï©',
  xoplus: '‚®Å',
  xotime: '‚®Ç',
  xrArr: '‚üπ',
  xrarr: '‚ü∂',
  xscr: 'ùìç',
  xsqcup: '‚®Ü',
  xuplus: '‚®Ñ',
  xutri: '‚ñ≥',
  xvee: '‚ãÅ',
  xwedge: '‚ãÄ',
  yacute: '√Ω',
  yacy: '—è',
  ycirc: '≈∑',
  ycy: '—ã',
  yen: '¬•',
  yfr: 'ùî∂',
  yicy: '—ó',
  yopf: 'ùï™',
  yscr: 'ùìé',
  yucy: '—é',
  yuml: '√ø',
  zacute: '≈∫',
  zcaron: '≈æ',
  zcy: '–∑',
  zdot: '≈º',
  zeetrf: '‚Ñ®',
  zeta: 'Œ∂',
  zfr: 'ùî∑',
  zhcy: '–∂',
  zigrarr: '‚áù',
  zopf: 'ùï´',
  zscr: 'ùìè',
  zwj: '‚Äç',
  zwnj: '‚Äå'
};

const own$6 = {}.hasOwnProperty;

/**
 * Decode a single character reference (without the `&` or `;`).
 * You probably only need this when you‚Äôre building parsers yourself that follow
 * different rules compared to HTML.
 * This is optimized to be tiny in browsers.
 *
 * @param {string} value
 *   `notin` (named), `#123` (deci), `#x123` (hexa).
 * @returns {string|false}
 *   Decoded reference.
 */
function decodeNamedCharacterReference(value) {
  return own$6.call(characterEntities, value) ? characterEntities[value] : false
}

/**
 * @typedef {import('micromark-util-types').Construct} Construct
 * @typedef {import('micromark-util-types').Tokenizer} Tokenizer
 * @typedef {import('micromark-util-types').Token} Token
 * @typedef {import('micromark-util-types').State} State
 * @typedef {import('micromark-util-types').Code} Code
 */

/** @type {Construct} */
const characterReference = {
  name: 'characterReference',
  tokenize: tokenizeCharacterReference
};
/** @type {Tokenizer} */

function tokenizeCharacterReference(effects, ok, nok) {
  const self = this;
  let size = 0;
  /** @type {number} */

  let max;
  /** @type {(code: Code) => code is number} */

  let test;
  return start
  /** @type {State} */

  function start(code) {
    effects.enter('characterReference');
    effects.enter('characterReferenceMarker');
    effects.consume(code);
    effects.exit('characterReferenceMarker');
    return open
  }
  /** @type {State} */

  function open(code) {
    if (code === 35) {
      effects.enter('characterReferenceMarkerNumeric');
      effects.consume(code);
      effects.exit('characterReferenceMarkerNumeric');
      return numeric
    }

    effects.enter('characterReferenceValue');
    max = 31;
    test = asciiAlphanumeric;
    return value(code)
  }
  /** @type {State} */

  function numeric(code) {
    if (code === 88 || code === 120) {
      effects.enter('characterReferenceMarkerHexadecimal');
      effects.consume(code);
      effects.exit('characterReferenceMarkerHexadecimal');
      effects.enter('characterReferenceValue');
      max = 6;
      test = asciiHexDigit;
      return value
    }

    effects.enter('characterReferenceValue');
    max = 7;
    test = asciiDigit;
    return value(code)
  }
  /** @type {State} */

  function value(code) {
    /** @type {Token} */
    let token;

    if (code === 59 && size) {
      token = effects.exit('characterReferenceValue');

      if (
        test === asciiAlphanumeric &&
        !decodeNamedCharacterReference(self.sliceSerialize(token))
      ) {
        return nok(code)
      }

      effects.enter('characterReferenceMarker');
      effects.consume(code);
      effects.exit('characterReferenceMarker');
      effects.exit('characterReference');
      return ok
    }

    if (test(code) && size++ < max) {
      effects.consume(code);
      return value
    }

    return nok(code)
  }
}

/**
 * @typedef {import('micromark-util-types').Construct} Construct
 * @typedef {import('micromark-util-types').Tokenizer} Tokenizer
 * @typedef {import('micromark-util-types').State} State
 * @typedef {import('micromark-util-types').Code} Code
 */

/** @type {Construct} */
const codeFenced = {
  name: 'codeFenced',
  tokenize: tokenizeCodeFenced,
  concrete: true
};
/** @type {Tokenizer} */

function tokenizeCodeFenced(effects, ok, nok) {
  const self = this;
  /** @type {Construct} */

  const closingFenceConstruct = {
    tokenize: tokenizeClosingFence,
    partial: true
  };
  /** @type {Construct} */

  const nonLazyLine = {
    tokenize: tokenizeNonLazyLine,
    partial: true
  };
  const tail = this.events[this.events.length - 1];
  const initialPrefix =
    tail && tail[1].type === 'linePrefix'
      ? tail[2].sliceSerialize(tail[1], true).length
      : 0;
  let sizeOpen = 0;
  /** @type {NonNullable<Code>} */

  let marker;
  return start
  /** @type {State} */

  function start(code) {
    effects.enter('codeFenced');
    effects.enter('codeFencedFence');
    effects.enter('codeFencedFenceSequence');
    marker = code;
    return sequenceOpen(code)
  }
  /** @type {State} */

  function sequenceOpen(code) {
    if (code === marker) {
      effects.consume(code);
      sizeOpen++;
      return sequenceOpen
    }

    effects.exit('codeFencedFenceSequence');
    return sizeOpen < 3
      ? nok(code)
      : factorySpace(effects, infoOpen, 'whitespace')(code)
  }
  /** @type {State} */

  function infoOpen(code) {
    if (code === null || markdownLineEnding(code)) {
      return openAfter(code)
    }

    effects.enter('codeFencedFenceInfo');
    effects.enter('chunkString', {
      contentType: 'string'
    });
    return info(code)
  }
  /** @type {State} */

  function info(code) {
    if (code === null || markdownLineEndingOrSpace(code)) {
      effects.exit('chunkString');
      effects.exit('codeFencedFenceInfo');
      return factorySpace(effects, infoAfter, 'whitespace')(code)
    }

    if (code === 96 && code === marker) return nok(code)
    effects.consume(code);
    return info
  }
  /** @type {State} */

  function infoAfter(code) {
    if (code === null || markdownLineEnding(code)) {
      return openAfter(code)
    }

    effects.enter('codeFencedFenceMeta');
    effects.enter('chunkString', {
      contentType: 'string'
    });
    return meta(code)
  }
  /** @type {State} */

  function meta(code) {
    if (code === null || markdownLineEnding(code)) {
      effects.exit('chunkString');
      effects.exit('codeFencedFenceMeta');
      return openAfter(code)
    }

    if (code === 96 && code === marker) return nok(code)
    effects.consume(code);
    return meta
  }
  /** @type {State} */

  function openAfter(code) {
    effects.exit('codeFencedFence');
    return self.interrupt ? ok(code) : contentStart(code)
  }
  /** @type {State} */

  function contentStart(code) {
    if (code === null) {
      return after(code)
    }

    if (markdownLineEnding(code)) {
      return effects.attempt(
        nonLazyLine,
        effects.attempt(
          closingFenceConstruct,
          after,
          initialPrefix
            ? factorySpace(
                effects,
                contentStart,
                'linePrefix',
                initialPrefix + 1
              )
            : contentStart
        ),
        after
      )(code)
    }

    effects.enter('codeFlowValue');
    return contentContinue(code)
  }
  /** @type {State} */

  function contentContinue(code) {
    if (code === null || markdownLineEnding(code)) {
      effects.exit('codeFlowValue');
      return contentStart(code)
    }

    effects.consume(code);
    return contentContinue
  }
  /** @type {State} */

  function after(code) {
    effects.exit('codeFenced');
    return ok(code)
  }
  /** @type {Tokenizer} */

  function tokenizeNonLazyLine(effects, ok, nok) {
    const self = this;
    return start
    /** @type {State} */

    function start(code) {
      effects.enter('lineEnding');
      effects.consume(code);
      effects.exit('lineEnding');
      return lineStart
    }
    /** @type {State} */

    function lineStart(code) {
      return self.parser.lazy[self.now().line] ? nok(code) : ok(code)
    }
  }
  /** @type {Tokenizer} */

  function tokenizeClosingFence(effects, ok, nok) {
    let size = 0;
    return factorySpace(
      effects,
      closingSequenceStart,
      'linePrefix',
      this.parser.constructs.disable.null.includes('codeIndented')
        ? undefined
        : 4
    )
    /** @type {State} */

    function closingSequenceStart(code) {
      effects.enter('codeFencedFence');
      effects.enter('codeFencedFenceSequence');
      return closingSequence(code)
    }
    /** @type {State} */

    function closingSequence(code) {
      if (code === marker) {
        effects.consume(code);
        size++;
        return closingSequence
      }

      if (size < sizeOpen) return nok(code)
      effects.exit('codeFencedFenceSequence');
      return factorySpace(effects, closingSequenceEnd, 'whitespace')(code)
    }
    /** @type {State} */

    function closingSequenceEnd(code) {
      if (code === null || markdownLineEnding(code)) {
        effects.exit('codeFencedFence');
        return ok(code)
      }

      return nok(code)
    }
  }
}

/**
 * @typedef {import('micromark-util-types').Construct} Construct
 * @typedef {import('micromark-util-types').Tokenizer} Tokenizer
 * @typedef {import('micromark-util-types').Resolver} Resolver
 * @typedef {import('micromark-util-types').Token} Token
 * @typedef {import('micromark-util-types').State} State
 */

/** @type {Construct} */
const codeIndented = {
  name: 'codeIndented',
  tokenize: tokenizeCodeIndented
};
/** @type {Construct} */

const indentedContent = {
  tokenize: tokenizeIndentedContent,
  partial: true
};
/** @type {Tokenizer} */

function tokenizeCodeIndented(effects, ok, nok) {
  const self = this;
  return start
  /** @type {State} */

  function start(code) {
    effects.enter('codeIndented');
    return factorySpace(effects, afterStartPrefix, 'linePrefix', 4 + 1)(code)
  }
  /** @type {State} */

  function afterStartPrefix(code) {
    const tail = self.events[self.events.length - 1];
    return tail &&
      tail[1].type === 'linePrefix' &&
      tail[2].sliceSerialize(tail[1], true).length >= 4
      ? afterPrefix(code)
      : nok(code)
  }
  /** @type {State} */

  function afterPrefix(code) {
    if (code === null) {
      return after(code)
    }

    if (markdownLineEnding(code)) {
      return effects.attempt(indentedContent, afterPrefix, after)(code)
    }

    effects.enter('codeFlowValue');
    return content(code)
  }
  /** @type {State} */

  function content(code) {
    if (code === null || markdownLineEnding(code)) {
      effects.exit('codeFlowValue');
      return afterPrefix(code)
    }

    effects.consume(code);
    return content
  }
  /** @type {State} */

  function after(code) {
    effects.exit('codeIndented');
    return ok(code)
  }
}
/** @type {Tokenizer} */

function tokenizeIndentedContent(effects, ok, nok) {
  const self = this;
  return start
  /** @type {State} */

  function start(code) {
    // If this is a lazy line, it can‚Äôt be code.
    if (self.parser.lazy[self.now().line]) {
      return nok(code)
    }

    if (markdownLineEnding(code)) {
      effects.enter('lineEnding');
      effects.consume(code);
      effects.exit('lineEnding');
      return start
    }

    return factorySpace(effects, afterPrefix, 'linePrefix', 4 + 1)(code)
  }
  /** @type {State} */

  function afterPrefix(code) {
    const tail = self.events[self.events.length - 1];
    return tail &&
      tail[1].type === 'linePrefix' &&
      tail[2].sliceSerialize(tail[1], true).length >= 4
      ? ok(code)
      : markdownLineEnding(code)
      ? start(code)
      : nok(code)
  }
}

/**
 * @typedef {import('micromark-util-types').Construct} Construct
 * @typedef {import('micromark-util-types').Resolver} Resolver
 * @typedef {import('micromark-util-types').Tokenizer} Tokenizer
 * @typedef {import('micromark-util-types').Previous} Previous
 * @typedef {import('micromark-util-types').Token} Token
 * @typedef {import('micromark-util-types').State} State
 */

/** @type {Construct} */
const codeText = {
  name: 'codeText',
  tokenize: tokenizeCodeText,
  resolve: resolveCodeText,
  previous: previous$2
};
/** @type {Resolver} */

function resolveCodeText(events) {
  let tailExitIndex = events.length - 4;
  let headEnterIndex = 3;
  /** @type {number} */

  let index;
  /** @type {number|undefined} */

  let enter; // If we start and end with an EOL or a space.

  if (
    (events[headEnterIndex][1].type === 'lineEnding' ||
      events[headEnterIndex][1].type === 'space') &&
    (events[tailExitIndex][1].type === 'lineEnding' ||
      events[tailExitIndex][1].type === 'space')
  ) {
    index = headEnterIndex; // And we have data.

    while (++index < tailExitIndex) {
      if (events[index][1].type === 'codeTextData') {
        // Then we have padding.
        events[headEnterIndex][1].type = 'codeTextPadding';
        events[tailExitIndex][1].type = 'codeTextPadding';
        headEnterIndex += 2;
        tailExitIndex -= 2;
        break
      }
    }
  } // Merge adjacent spaces and data.

  index = headEnterIndex - 1;
  tailExitIndex++;

  while (++index <= tailExitIndex) {
    if (enter === undefined) {
      if (index !== tailExitIndex && events[index][1].type !== 'lineEnding') {
        enter = index;
      }
    } else if (
      index === tailExitIndex ||
      events[index][1].type === 'lineEnding'
    ) {
      events[enter][1].type = 'codeTextData';

      if (index !== enter + 2) {
        events[enter][1].end = events[index - 1][1].end;
        events.splice(enter + 2, index - enter - 2);
        tailExitIndex -= index - enter - 2;
        index = enter + 2;
      }

      enter = undefined;
    }
  }

  return events
}
/** @type {Previous} */

function previous$2(code) {
  // If there is a previous code, there will always be a tail.
  return (
    code !== 96 ||
    this.events[this.events.length - 1][1].type === 'characterEscape'
  )
}
/** @type {Tokenizer} */

function tokenizeCodeText(effects, ok, nok) {
  let sizeOpen = 0;
  /** @type {number} */

  let size;
  /** @type {Token} */

  let token;
  return start
  /** @type {State} */

  function start(code) {
    effects.enter('codeText');
    effects.enter('codeTextSequence');
    return openingSequence(code)
  }
  /** @type {State} */

  function openingSequence(code) {
    if (code === 96) {
      effects.consume(code);
      sizeOpen++;
      return openingSequence
    }

    effects.exit('codeTextSequence');
    return gap(code)
  }
  /** @type {State} */

  function gap(code) {
    // EOF.
    if (code === null) {
      return nok(code)
    } // Closing fence?
    // Could also be data.

    if (code === 96) {
      token = effects.enter('codeTextSequence');
      size = 0;
      return closingSequence(code)
    } // Tabs don‚Äôt work, and virtual spaces don‚Äôt make sense.

    if (code === 32) {
      effects.enter('space');
      effects.consume(code);
      effects.exit('space');
      return gap
    }

    if (markdownLineEnding(code)) {
      effects.enter('lineEnding');
      effects.consume(code);
      effects.exit('lineEnding');
      return gap
    } // Data.

    effects.enter('codeTextData');
    return data(code)
  } // In code.

  /** @type {State} */

  function data(code) {
    if (
      code === null ||
      code === 32 ||
      code === 96 ||
      markdownLineEnding(code)
    ) {
      effects.exit('codeTextData');
      return gap(code)
    }

    effects.consume(code);
    return data
  } // Closing fence.

  /** @type {State} */

  function closingSequence(code) {
    // More.
    if (code === 96) {
      effects.consume(code);
      size++;
      return closingSequence
    } // Done!

    if (size === sizeOpen) {
      effects.exit('codeTextSequence');
      effects.exit('codeText');
      return ok(code)
    } // More or less accents: mark as data.

    token.type = 'codeTextData';
    return data(code)
  }
}

/**
 * @typedef {import('micromark-util-types').Token} Token
 * @typedef {import('micromark-util-types').Chunk} Chunk
 * @typedef {import('micromark-util-types').Event} Event
 */

/**
 * Tokenize subcontent.
 *
 * @param {Event[]} events
 * @returns {boolean}
 */
function subtokenize(events) {
  /** @type {Record<string, number>} */
  const jumps = {};
  let index = -1;
  /** @type {Event} */

  let event;
  /** @type {number|undefined} */

  let lineIndex;
  /** @type {number} */

  let otherIndex;
  /** @type {Event} */

  let otherEvent;
  /** @type {Event[]} */

  let parameters;
  /** @type {Event[]} */

  let subevents;
  /** @type {boolean|undefined} */

  let more;

  while (++index < events.length) {
    while (index in jumps) {
      index = jumps[index];
    }

    event = events[index]; // Add a hook for the GFM tasklist extension, which needs to know if text
    // is in the first content of a list item.

    if (
      index &&
      event[1].type === 'chunkFlow' &&
      events[index - 1][1].type === 'listItemPrefix'
    ) {
      subevents = event[1]._tokenizer.events;
      otherIndex = 0;

      if (
        otherIndex < subevents.length &&
        subevents[otherIndex][1].type === 'lineEndingBlank'
      ) {
        otherIndex += 2;
      }

      if (
        otherIndex < subevents.length &&
        subevents[otherIndex][1].type === 'content'
      ) {
        while (++otherIndex < subevents.length) {
          if (subevents[otherIndex][1].type === 'content') {
            break
          }

          if (subevents[otherIndex][1].type === 'chunkText') {
            subevents[otherIndex][1]._isInFirstContentOfListItem = true;
            otherIndex++;
          }
        }
      }
    } // Enter.

    if (event[0] === 'enter') {
      if (event[1].contentType) {
        Object.assign(jumps, subcontent(events, index));
        index = jumps[index];
        more = true;
      }
    } // Exit.
    else if (event[1]._container) {
      otherIndex = index;
      lineIndex = undefined;

      while (otherIndex--) {
        otherEvent = events[otherIndex];

        if (
          otherEvent[1].type === 'lineEnding' ||
          otherEvent[1].type === 'lineEndingBlank'
        ) {
          if (otherEvent[0] === 'enter') {
            if (lineIndex) {
              events[lineIndex][1].type = 'lineEndingBlank';
            }

            otherEvent[1].type = 'lineEnding';
            lineIndex = otherIndex;
          }
        } else {
          break
        }
      }

      if (lineIndex) {
        // Fix position.
        event[1].end = Object.assign({}, events[lineIndex][1].start); // Switch container exit w/ line endings.

        parameters = events.slice(lineIndex, index);
        parameters.unshift(event);
        splice(events, lineIndex, index - lineIndex + 1, parameters);
      }
    }
  }

  return !more
}
/**
 * Tokenize embedded tokens.
 *
 * @param {Event[]} events
 * @param {number} eventIndex
 * @returns {Record<string, number>}
 */

function subcontent(events, eventIndex) {
  const token = events[eventIndex][1];
  const context = events[eventIndex][2];
  let startPosition = eventIndex - 1;
  /** @type {number[]} */

  const startPositions = [];
  const tokenizer =
    token._tokenizer || context.parser[token.contentType](token.start);
  const childEvents = tokenizer.events;
  /** @type {[number, number][]} */

  const jumps = [];
  /** @type {Record<string, number>} */

  const gaps = {};
  /** @type {Chunk[]} */

  let stream;
  /** @type {Token|undefined} */

  let previous;
  let index = -1;
  /** @type {Token|undefined} */

  let current = token;
  let adjust = 0;
  let start = 0;
  const breaks = [start]; // Loop forward through the linked tokens to pass them in order to the
  // subtokenizer.

  while (current) {
    // Find the position of the event for this token.
    while (events[++startPosition][1] !== current) {
      // Empty.
    }

    startPositions.push(startPosition);

    if (!current._tokenizer) {
      stream = context.sliceStream(current);

      if (!current.next) {
        stream.push(null);
      }

      if (previous) {
        tokenizer.defineSkip(current.start);
      }

      if (current._isInFirstContentOfListItem) {
        tokenizer._gfmTasklistFirstContentOfListItem = true;
      }

      tokenizer.write(stream);

      if (current._isInFirstContentOfListItem) {
        tokenizer._gfmTasklistFirstContentOfListItem = undefined;
      }
    } // Unravel the next token.

    previous = current;
    current = current.next;
  } // Now, loop back through all events (and linked tokens), to figure out which
  // parts belong where.

  current = token;

  while (++index < childEvents.length) {
    if (
      // Find a void token that includes a break.
      childEvents[index][0] === 'exit' &&
      childEvents[index - 1][0] === 'enter' &&
      childEvents[index][1].type === childEvents[index - 1][1].type &&
      childEvents[index][1].start.line !== childEvents[index][1].end.line
    ) {
      start = index + 1;
      breaks.push(start); // Help GC.

      current._tokenizer = undefined;
      current.previous = undefined;
      current = current.next;
    }
  } // Help GC.

  tokenizer.events = []; // If there‚Äôs one more token (which is the cases for lines that end in an
  // EOF), that‚Äôs perfect: the last point we found starts it.
  // If there isn‚Äôt then make sure any remaining content is added to it.

  if (current) {
    // Help GC.
    current._tokenizer = undefined;
    current.previous = undefined;
  } else {
    breaks.pop();
  } // Now splice the events from the subtokenizer into the current events,
  // moving back to front so that splice indices aren‚Äôt affected.

  index = breaks.length;

  while (index--) {
    const slice = childEvents.slice(breaks[index], breaks[index + 1]);
    const start = startPositions.pop();
    jumps.unshift([start, start + slice.length - 1]);
    splice(events, start, 2, slice);
  }

  index = -1;

  while (++index < jumps.length) {
    gaps[adjust + jumps[index][0]] = adjust + jumps[index][1];
    adjust += jumps[index][1] - jumps[index][0] - 1;
  }

  return gaps
}

/**
 * @typedef {import('micromark-util-types').Construct} Construct
 * @typedef {import('micromark-util-types').Resolver} Resolver
 * @typedef {import('micromark-util-types').Tokenizer} Tokenizer
 * @typedef {import('micromark-util-types').Token} Token
 * @typedef {import('micromark-util-types').State} State
 */

/**
 * No name because it must not be turned off.
 * @type {Construct}
 */
const content = {
  tokenize: tokenizeContent,
  resolve: resolveContent
};
/** @type {Construct} */

const continuationConstruct = {
  tokenize: tokenizeContinuation,
  partial: true
};
/**
 * Content is transparent: it‚Äôs parsed right now. That way, definitions are also
 * parsed right now: before text in paragraphs (specifically, media) are parsed.
 *
 * @type {Resolver}
 */

function resolveContent(events) {
  subtokenize(events);
  return events
}
/** @type {Tokenizer} */

function tokenizeContent(effects, ok) {
  /** @type {Token} */
  let previous;
  return start
  /** @type {State} */

  function start(code) {
    effects.enter('content');
    previous = effects.enter('chunkContent', {
      contentType: 'content'
    });
    return data(code)
  }
  /** @type {State} */

  function data(code) {
    if (code === null) {
      return contentEnd(code)
    }

    if (markdownLineEnding(code)) {
      return effects.check(
        continuationConstruct,
        contentContinue,
        contentEnd
      )(code)
    } // Data.

    effects.consume(code);
    return data
  }
  /** @type {State} */

  function contentEnd(code) {
    effects.exit('chunkContent');
    effects.exit('content');
    return ok(code)
  }
  /** @type {State} */

  function contentContinue(code) {
    effects.consume(code);
    effects.exit('chunkContent');
    previous.next = effects.enter('chunkContent', {
      contentType: 'content',
      previous
    });
    previous = previous.next;
    return data
  }
}
/** @type {Tokenizer} */

function tokenizeContinuation(effects, ok, nok) {
  const self = this;
  return startLookahead
  /** @type {State} */

  function startLookahead(code) {
    effects.exit('chunkContent');
    effects.enter('lineEnding');
    effects.consume(code);
    effects.exit('lineEnding');
    return factorySpace(effects, prefixed, 'linePrefix')
  }
  /** @type {State} */

  function prefixed(code) {
    if (code === null || markdownLineEnding(code)) {
      return nok(code)
    }

    const tail = self.events[self.events.length - 1];

    if (
      !self.parser.constructs.disable.null.includes('codeIndented') &&
      tail &&
      tail[1].type === 'linePrefix' &&
      tail[2].sliceSerialize(tail[1], true).length >= 4
    ) {
      return ok(code)
    }

    return effects.interrupt(self.parser.constructs.flow, nok, ok)(code)
  }
}

/**
 * @typedef {import('micromark-util-types').Effects} Effects
 * @typedef {import('micromark-util-types').State} State
 */

/**
 * @param {Effects} effects
 * @param {State} ok
 * @param {State} nok
 * @param {string} type
 * @param {string} literalType
 * @param {string} literalMarkerType
 * @param {string} rawType
 * @param {string} stringType
 * @param {number} [max=Infinity]
 * @returns {State}
 */
// eslint-disable-next-line max-params
function factoryDestination(
  effects,
  ok,
  nok,
  type,
  literalType,
  literalMarkerType,
  rawType,
  stringType,
  max
) {
  const limit = max || Number.POSITIVE_INFINITY;
  let balance = 0;
  return start
  /** @type {State} */

  function start(code) {
    if (code === 60) {
      effects.enter(type);
      effects.enter(literalType);
      effects.enter(literalMarkerType);
      effects.consume(code);
      effects.exit(literalMarkerType);
      return destinationEnclosedBefore
    }

    if (code === null || code === 41 || asciiControl(code)) {
      return nok(code)
    }

    effects.enter(type);
    effects.enter(rawType);
    effects.enter(stringType);
    effects.enter('chunkString', {
      contentType: 'string'
    });
    return destinationRaw(code)
  }
  /** @type {State} */

  function destinationEnclosedBefore(code) {
    if (code === 62) {
      effects.enter(literalMarkerType);
      effects.consume(code);
      effects.exit(literalMarkerType);
      effects.exit(literalType);
      effects.exit(type);
      return ok
    }

    effects.enter(stringType);
    effects.enter('chunkString', {
      contentType: 'string'
    });
    return destinationEnclosed(code)
  }
  /** @type {State} */

  function destinationEnclosed(code) {
    if (code === 62) {
      effects.exit('chunkString');
      effects.exit(stringType);
      return destinationEnclosedBefore(code)
    }

    if (code === null || code === 60 || markdownLineEnding(code)) {
      return nok(code)
    }

    effects.consume(code);
    return code === 92 ? destinationEnclosedEscape : destinationEnclosed
  }
  /** @type {State} */

  function destinationEnclosedEscape(code) {
    if (code === 60 || code === 62 || code === 92) {
      effects.consume(code);
      return destinationEnclosed
    }

    return destinationEnclosed(code)
  }
  /** @type {State} */

  function destinationRaw(code) {
    if (code === 40) {
      if (++balance > limit) return nok(code)
      effects.consume(code);
      return destinationRaw
    }

    if (code === 41) {
      if (!balance--) {
        effects.exit('chunkString');
        effects.exit(stringType);
        effects.exit(rawType);
        effects.exit(type);
        return ok(code)
      }

      effects.consume(code);
      return destinationRaw
    }

    if (code === null || markdownLineEndingOrSpace(code)) {
      if (balance) return nok(code)
      effects.exit('chunkString');
      effects.exit(stringType);
      effects.exit(rawType);
      effects.exit(type);
      return ok(code)
    }

    if (asciiControl(code)) return nok(code)
    effects.consume(code);
    return code === 92 ? destinationRawEscape : destinationRaw
  }
  /** @type {State} */

  function destinationRawEscape(code) {
    if (code === 40 || code === 41 || code === 92) {
      effects.consume(code);
      return destinationRaw
    }

    return destinationRaw(code)
  }
}

/**
 * @typedef {import('micromark-util-types').Effects} Effects
 * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext
 * @typedef {import('micromark-util-types').State} State
 */

/**
 * @this {TokenizeContext}
 * @param {Effects} effects
 * @param {State} ok
 * @param {State} nok
 * @param {string} type
 * @param {string} markerType
 * @param {string} stringType
 * @returns {State}
 */
// eslint-disable-next-line max-params
function factoryLabel(effects, ok, nok, type, markerType, stringType) {
  const self = this;
  let size = 0;
  /** @type {boolean} */

  let data;
  return start
  /** @type {State} */

  function start(code) {
    effects.enter(type);
    effects.enter(markerType);
    effects.consume(code);
    effects.exit(markerType);
    effects.enter(stringType);
    return atBreak
  }
  /** @type {State} */

  function atBreak(code) {
    if (
      code === null ||
      code === 91 ||
      (code === 93 && !data) ||
      /* To do: remove in the future once we‚Äôve switched from
       * `micromark-extension-footnote` to `micromark-extension-gfm-footnote`,
       * which doesn‚Äôt need this */

      /* Hidden footnotes hook */

      /* c8 ignore next 3 */
      (code === 94 &&
        !size &&
        '_hiddenFootnoteSupport' in self.parser.constructs) ||
      size > 999
    ) {
      return nok(code)
    }

    if (code === 93) {
      effects.exit(stringType);
      effects.enter(markerType);
      effects.consume(code);
      effects.exit(markerType);
      effects.exit(type);
      return ok
    }

    if (markdownLineEnding(code)) {
      effects.enter('lineEnding');
      effects.consume(code);
      effects.exit('lineEnding');
      return atBreak
    }

    effects.enter('chunkString', {
      contentType: 'string'
    });
    return label(code)
  }
  /** @type {State} */

  function label(code) {
    if (
      code === null ||
      code === 91 ||
      code === 93 ||
      markdownLineEnding(code) ||
      size++ > 999
    ) {
      effects.exit('chunkString');
      return atBreak(code)
    }

    effects.consume(code);
    data = data || !markdownSpace(code);
    return code === 92 ? labelEscape : label
  }
  /** @type {State} */

  function labelEscape(code) {
    if (code === 91 || code === 92 || code === 93) {
      effects.consume(code);
      size++;
      return label
    }

    return label(code)
  }
}

/**
 * @typedef {import('micromark-util-types').Effects} Effects
 * @typedef {import('micromark-util-types').State} State
 * @typedef {import('micromark-util-types').Code} Code
 */

/**
 * @param {Effects} effects
 * @param {State} ok
 * @param {State} nok
 * @param {string} type
 * @param {string} markerType
 * @param {string} stringType
 * @returns {State}
 */
// eslint-disable-next-line max-params
function factoryTitle(effects, ok, nok, type, markerType, stringType) {
  /** @type {NonNullable<Code>} */
  let marker;
  return start
  /** @type {State} */

  function start(code) {
    effects.enter(type);
    effects.enter(markerType);
    effects.consume(code);
    effects.exit(markerType);
    marker = code === 40 ? 41 : code;
    return atFirstTitleBreak
  }
  /** @type {State} */

  function atFirstTitleBreak(code) {
    if (code === marker) {
      effects.enter(markerType);
      effects.consume(code);
      effects.exit(markerType);
      effects.exit(type);
      return ok
    }

    effects.enter(stringType);
    return atTitleBreak(code)
  }
  /** @type {State} */

  function atTitleBreak(code) {
    if (code === marker) {
      effects.exit(stringType);
      return atFirstTitleBreak(marker)
    }

    if (code === null) {
      return nok(code)
    } // Note: blank lines can‚Äôt exist in content.

    if (markdownLineEnding(code)) {
      effects.enter('lineEnding');
      effects.consume(code);
      effects.exit('lineEnding');
      return factorySpace(effects, atTitleBreak, 'linePrefix')
    }

    effects.enter('chunkString', {
      contentType: 'string'
    });
    return title(code)
  }
  /** @type {State} */

  function title(code) {
    if (code === marker || code === null || markdownLineEnding(code)) {
      effects.exit('chunkString');
      return atTitleBreak(code)
    }

    effects.consume(code);
    return code === 92 ? titleEscape : title
  }
  /** @type {State} */

  function titleEscape(code) {
    if (code === marker || code === 92) {
      effects.consume(code);
      return title
    }

    return title(code)
  }
}

/**
 * @typedef {import('micromark-util-types').Effects} Effects
 * @typedef {import('micromark-util-types').State} State
 */

/**
 * @param {Effects} effects
 * @param {State} ok
 */
function factoryWhitespace(effects, ok) {
  /** @type {boolean} */
  let seen;
  return start
  /** @type {State} */

  function start(code) {
    if (markdownLineEnding(code)) {
      effects.enter('lineEnding');
      effects.consume(code);
      effects.exit('lineEnding');
      seen = true;
      return start
    }

    if (markdownSpace(code)) {
      return factorySpace(
        effects,
        start,
        seen ? 'linePrefix' : 'lineSuffix'
      )(code)
    }

    return ok(code)
  }
}

/**
 * Normalize an identifier (such as used in definitions).
 *
 * @param {string} value
 * @returns {string}
 */
function normalizeIdentifier(value) {
  return (
    value // Collapse Markdown whitespace.
      .replace(/[\t\n\r ]+/g, ' ') // Trim.
      .replace(/^ | $/g, '') // Some characters are considered ‚Äúuppercase‚Äù, but if their lowercase
      // counterpart is uppercased will result in a different uppercase
      // character.
      // Hence, to get that form, we perform both lower- and uppercase.
      // Upper case makes sure keys will not interact with default prototypal
      // methods: no method is uppercase.
      .toLowerCase()
      .toUpperCase()
  )
}

/**
 * @typedef {import('micromark-util-types').Construct} Construct
 * @typedef {import('micromark-util-types').Tokenizer} Tokenizer
 * @typedef {import('micromark-util-types').State} State
 */

/** @type {Construct} */
const definition = {
  name: 'definition',
  tokenize: tokenizeDefinition
};
/** @type {Construct} */

const titleConstruct = {
  tokenize: tokenizeTitle,
  partial: true
};
/** @type {Tokenizer} */

function tokenizeDefinition(effects, ok, nok) {
  const self = this;
  /** @type {string} */

  let identifier;
  return start
  /** @type {State} */

  function start(code) {
    effects.enter('definition');
    return factoryLabel.call(
      self,
      effects,
      labelAfter,
      nok,
      'definitionLabel',
      'definitionLabelMarker',
      'definitionLabelString'
    )(code)
  }
  /** @type {State} */

  function labelAfter(code) {
    identifier = normalizeIdentifier(
      self.sliceSerialize(self.events[self.events.length - 1][1]).slice(1, -1)
    );

    if (code === 58) {
      effects.enter('definitionMarker');
      effects.consume(code);
      effects.exit('definitionMarker'); // Note: blank lines can‚Äôt exist in content.

      return factoryWhitespace(
        effects,
        factoryDestination(
          effects,
          effects.attempt(
            titleConstruct,
            factorySpace(effects, after, 'whitespace'),
            factorySpace(effects, after, 'whitespace')
          ),
          nok,
          'definitionDestination',
          'definitionDestinationLiteral',
          'definitionDestinationLiteralMarker',
          'definitionDestinationRaw',
          'definitionDestinationString'
        )
      )
    }

    return nok(code)
  }
  /** @type {State} */

  function after(code) {
    if (code === null || markdownLineEnding(code)) {
      effects.exit('definition');

      if (!self.parser.defined.includes(identifier)) {
        self.parser.defined.push(identifier);
      }

      return ok(code)
    }

    return nok(code)
  }
}
/** @type {Tokenizer} */

function tokenizeTitle(effects, ok, nok) {
  return start
  /** @type {State} */

  function start(code) {
    return markdownLineEndingOrSpace(code)
      ? factoryWhitespace(effects, before)(code)
      : nok(code)
  }
  /** @type {State} */

  function before(code) {
    if (code === 34 || code === 39 || code === 40) {
      return factoryTitle(
        effects,
        factorySpace(effects, after, 'whitespace'),
        nok,
        'definitionTitle',
        'definitionTitleMarker',
        'definitionTitleString'
      )(code)
    }

    return nok(code)
  }
  /** @type {State} */

  function after(code) {
    return code === null || markdownLineEnding(code) ? ok(code) : nok(code)
  }
}

/**
 * @typedef {import('micromark-util-types').Construct} Construct
 * @typedef {import('micromark-util-types').Tokenizer} Tokenizer
 * @typedef {import('micromark-util-types').State} State
 */

/** @type {Construct} */
const hardBreakEscape = {
  name: 'hardBreakEscape',
  tokenize: tokenizeHardBreakEscape
};
/** @type {Tokenizer} */

function tokenizeHardBreakEscape(effects, ok, nok) {
  return start
  /** @type {State} */

  function start(code) {
    effects.enter('hardBreakEscape');
    effects.enter('escapeMarker');
    effects.consume(code);
    return open
  }
  /** @type {State} */

  function open(code) {
    if (markdownLineEnding(code)) {
      effects.exit('escapeMarker');
      effects.exit('hardBreakEscape');
      return ok(code)
    }

    return nok(code)
  }
}

/**
 * @typedef {import('micromark-util-types').Construct} Construct
 * @typedef {import('micromark-util-types').Resolver} Resolver
 * @typedef {import('micromark-util-types').Tokenizer} Tokenizer
 * @typedef {import('micromark-util-types').Token} Token
 * @typedef {import('micromark-util-types').State} State
 */

/** @type {Construct} */
const headingAtx = {
  name: 'headingAtx',
  tokenize: tokenizeHeadingAtx,
  resolve: resolveHeadingAtx
};
/** @type {Resolver} */

function resolveHeadingAtx(events, context) {
  let contentEnd = events.length - 2;
  let contentStart = 3;
  /** @type {Token} */

  let content;
  /** @type {Token} */

  let text; // Prefix whitespace, part of the opening.

  if (events[contentStart][1].type === 'whitespace') {
    contentStart += 2;
  } // Suffix whitespace, part of the closing.

  if (
    contentEnd - 2 > contentStart &&
    events[contentEnd][1].type === 'whitespace'
  ) {
    contentEnd -= 2;
  }

  if (
    events[contentEnd][1].type === 'atxHeadingSequence' &&
    (contentStart === contentEnd - 1 ||
      (contentEnd - 4 > contentStart &&
        events[contentEnd - 2][1].type === 'whitespace'))
  ) {
    contentEnd -= contentStart + 1 === contentEnd ? 2 : 4;
  }

  if (contentEnd > contentStart) {
    content = {
      type: 'atxHeadingText',
      start: events[contentStart][1].start,
      end: events[contentEnd][1].end
    };
    text = {
      type: 'chunkText',
      start: events[contentStart][1].start,
      end: events[contentEnd][1].end,
      // @ts-expect-error Constants are fine to assign.
      contentType: 'text'
    };
    splice(events, contentStart, contentEnd - contentStart + 1, [
      ['enter', content, context],
      ['enter', text, context],
      ['exit', text, context],
      ['exit', content, context]
    ]);
  }

  return events
}
/** @type {Tokenizer} */

function tokenizeHeadingAtx(effects, ok, nok) {
  const self = this;
  let size = 0;
  return start
  /** @type {State} */

  function start(code) {
    effects.enter('atxHeading');
    effects.enter('atxHeadingSequence');
    return fenceOpenInside(code)
  }
  /** @type {State} */

  function fenceOpenInside(code) {
    if (code === 35 && size++ < 6) {
      effects.consume(code);
      return fenceOpenInside
    }

    if (code === null || markdownLineEndingOrSpace(code)) {
      effects.exit('atxHeadingSequence');
      return self.interrupt ? ok(code) : headingBreak(code)
    }

    return nok(code)
  }
  /** @type {State} */

  function headingBreak(code) {
    if (code === 35) {
      effects.enter('atxHeadingSequence');
      return sequence(code)
    }

    if (code === null || markdownLineEnding(code)) {
      effects.exit('atxHeading');
      return ok(code)
    }

    if (markdownSpace(code)) {
      return factorySpace(effects, headingBreak, 'whitespace')(code)
    }

    effects.enter('atxHeadingText');
    return data(code)
  }
  /** @type {State} */

  function sequence(code) {
    if (code === 35) {
      effects.consume(code);
      return sequence
    }

    effects.exit('atxHeadingSequence');
    return headingBreak(code)
  }
  /** @type {State} */

  function data(code) {
    if (code === null || code === 35 || markdownLineEndingOrSpace(code)) {
      effects.exit('atxHeadingText');
      return headingBreak(code)
    }

    effects.consume(code);
    return data
  }
}

/**
 * List of lowercase HTML tag names which when parsing HTML (flow), result
 * in more relaxed rules (condition 6): because they are known blocks, the
 * HTML-like syntax doesn‚Äôt have to be strictly parsed.
 * For tag names not in this list, a more strict algorithm (condition 7) is used
 * to detect whether the HTML-like syntax is seen as HTML (flow) or not.
 *
 * This is copied from:
 * <https://spec.commonmark.org/0.30/#html-blocks>.
 */
const htmlBlockNames = [
  'address',
  'article',
  'aside',
  'base',
  'basefont',
  'blockquote',
  'body',
  'caption',
  'center',
  'col',
  'colgroup',
  'dd',
  'details',
  'dialog',
  'dir',
  'div',
  'dl',
  'dt',
  'fieldset',
  'figcaption',
  'figure',
  'footer',
  'form',
  'frame',
  'frameset',
  'h1',
  'h2',
  'h3',
  'h4',
  'h5',
  'h6',
  'head',
  'header',
  'hr',
  'html',
  'iframe',
  'legend',
  'li',
  'link',
  'main',
  'menu',
  'menuitem',
  'nav',
  'noframes',
  'ol',
  'optgroup',
  'option',
  'p',
  'param',
  'section',
  'summary',
  'table',
  'tbody',
  'td',
  'tfoot',
  'th',
  'thead',
  'title',
  'tr',
  'track',
  'ul'
];

/**
 * List of lowercase HTML tag names which when parsing HTML (flow), result in
 * HTML that can include lines w/o exiting, until a closing tag also in this
 * list is found (condition 1).
 *
 * This module is copied from:
 * <https://spec.commonmark.org/0.30/#html-blocks>.
 *
 * Note that `textarea` was added in `CommonMark@0.30`.
 */
const htmlRawNames = ['pre', 'script', 'style', 'textarea'];

/**
 * @typedef {import('micromark-util-types').Construct} Construct
 * @typedef {import('micromark-util-types').Resolver} Resolver
 * @typedef {import('micromark-util-types').Tokenizer} Tokenizer
 * @typedef {import('micromark-util-types').State} State
 * @typedef {import('micromark-util-types').Code} Code
 */
/** @type {Construct} */

const htmlFlow = {
  name: 'htmlFlow',
  tokenize: tokenizeHtmlFlow,
  resolveTo: resolveToHtmlFlow,
  concrete: true
};
/** @type {Construct} */

const nextBlankConstruct = {
  tokenize: tokenizeNextBlank,
  partial: true
};
/** @type {Resolver} */

function resolveToHtmlFlow(events) {
  let index = events.length;

  while (index--) {
    if (events[index][0] === 'enter' && events[index][1].type === 'htmlFlow') {
      break
    }
  }

  if (index > 1 && events[index - 2][1].type === 'linePrefix') {
    // Add the prefix start to the HTML token.
    events[index][1].start = events[index - 2][1].start; // Add the prefix start to the HTML line token.

    events[index + 1][1].start = events[index - 2][1].start; // Remove the line prefix.

    events.splice(index - 2, 2);
  }

  return events
}
/** @type {Tokenizer} */

function tokenizeHtmlFlow(effects, ok, nok) {
  const self = this;
  /** @type {number} */

  let kind;
  /** @type {boolean} */

  let startTag;
  /** @type {string} */

  let buffer;
  /** @type {number} */

  let index;
  /** @type {Code} */

  let marker;
  return start
  /** @type {State} */

  function start(code) {
    effects.enter('htmlFlow');
    effects.enter('htmlFlowData');
    effects.consume(code);
    return open
  }
  /** @type {State} */

  function open(code) {
    if (code === 33) {
      effects.consume(code);
      return declarationStart
    }

    if (code === 47) {
      effects.consume(code);
      return tagCloseStart
    }

    if (code === 63) {
      effects.consume(code);
      kind = 3; // While we‚Äôre in an instruction instead of a declaration, we‚Äôre on a `?`
      // right now, so we do need to search for `>`, similar to declarations.

      return self.interrupt ? ok : continuationDeclarationInside
    }

    if (asciiAlpha(code)) {
      effects.consume(code);
      buffer = String.fromCharCode(code);
      startTag = true;
      return tagName
    }

    return nok(code)
  }
  /** @type {State} */

  function declarationStart(code) {
    if (code === 45) {
      effects.consume(code);
      kind = 2;
      return commentOpenInside
    }

    if (code === 91) {
      effects.consume(code);
      kind = 5;
      buffer = 'CDATA[';
      index = 0;
      return cdataOpenInside
    }

    if (asciiAlpha(code)) {
      effects.consume(code);
      kind = 4;
      return self.interrupt ? ok : continuationDeclarationInside
    }

    return nok(code)
  }
  /** @type {State} */

  function commentOpenInside(code) {
    if (code === 45) {
      effects.consume(code);
      return self.interrupt ? ok : continuationDeclarationInside
    }

    return nok(code)
  }
  /** @type {State} */

  function cdataOpenInside(code) {
    if (code === buffer.charCodeAt(index++)) {
      effects.consume(code);
      return index === buffer.length
        ? self.interrupt
          ? ok
          : continuation
        : cdataOpenInside
    }

    return nok(code)
  }
  /** @type {State} */

  function tagCloseStart(code) {
    if (asciiAlpha(code)) {
      effects.consume(code);
      buffer = String.fromCharCode(code);
      return tagName
    }

    return nok(code)
  }
  /** @type {State} */

  function tagName(code) {
    if (
      code === null ||
      code === 47 ||
      code === 62 ||
      markdownLineEndingOrSpace(code)
    ) {
      if (
        code !== 47 &&
        startTag &&
        htmlRawNames.includes(buffer.toLowerCase())
      ) {
        kind = 1;
        return self.interrupt ? ok(code) : continuation(code)
      }

      if (htmlBlockNames.includes(buffer.toLowerCase())) {
        kind = 6;

        if (code === 47) {
          effects.consume(code);
          return basicSelfClosing
        }

        return self.interrupt ? ok(code) : continuation(code)
      }

      kind = 7; // Do not support complete HTML when interrupting

      return self.interrupt && !self.parser.lazy[self.now().line]
        ? nok(code)
        : startTag
        ? completeAttributeNameBefore(code)
        : completeClosingTagAfter(code)
    }

    if (code === 45 || asciiAlphanumeric(code)) {
      effects.consume(code);
      buffer += String.fromCharCode(code);
      return tagName
    }

    return nok(code)
  }
  /** @type {State} */

  function basicSelfClosing(code) {
    if (code === 62) {
      effects.consume(code);
      return self.interrupt ? ok : continuation
    }

    return nok(code)
  }
  /** @type {State} */

  function completeClosingTagAfter(code) {
    if (markdownSpace(code)) {
      effects.consume(code);
      return completeClosingTagAfter
    }

    return completeEnd(code)
  }
  /** @type {State} */

  function completeAttributeNameBefore(code) {
    if (code === 47) {
      effects.consume(code);
      return completeEnd
    }

    if (code === 58 || code === 95 || asciiAlpha(code)) {
      effects.consume(code);
      return completeAttributeName
    }

    if (markdownSpace(code)) {
      effects.consume(code);
      return completeAttributeNameBefore
    }

    return completeEnd(code)
  }
  /** @type {State} */

  function completeAttributeName(code) {
    if (
      code === 45 ||
      code === 46 ||
      code === 58 ||
      code === 95 ||
      asciiAlphanumeric(code)
    ) {
      effects.consume(code);
      return completeAttributeName
    }

    return completeAttributeNameAfter(code)
  }
  /** @type {State} */

  function completeAttributeNameAfter(code) {
    if (code === 61) {
      effects.consume(code);
      return completeAttributeValueBefore
    }

    if (markdownSpace(code)) {
      effects.consume(code);
      return completeAttributeNameAfter
    }

    return completeAttributeNameBefore(code)
  }
  /** @type {State} */

  function completeAttributeValueBefore(code) {
    if (
      code === null ||
      code === 60 ||
      code === 61 ||
      code === 62 ||
      code === 96
    ) {
      return nok(code)
    }

    if (code === 34 || code === 39) {
      effects.consume(code);
      marker = code;
      return completeAttributeValueQuoted
    }

    if (markdownSpace(code)) {
      effects.consume(code);
      return completeAttributeValueBefore
    }

    marker = null;
    return completeAttributeValueUnquoted(code)
  }
  /** @type {State} */

  function completeAttributeValueQuoted(code) {
    if (code === null || markdownLineEnding(code)) {
      return nok(code)
    }

    if (code === marker) {
      effects.consume(code);
      return completeAttributeValueQuotedAfter
    }

    effects.consume(code);
    return completeAttributeValueQuoted
  }
  /** @type {State} */

  function completeAttributeValueUnquoted(code) {
    if (
      code === null ||
      code === 34 ||
      code === 39 ||
      code === 60 ||
      code === 61 ||
      code === 62 ||
      code === 96 ||
      markdownLineEndingOrSpace(code)
    ) {
      return completeAttributeNameAfter(code)
    }

    effects.consume(code);
    return completeAttributeValueUnquoted
  }
  /** @type {State} */

  function completeAttributeValueQuotedAfter(code) {
    if (code === 47 || code === 62 || markdownSpace(code)) {
      return completeAttributeNameBefore(code)
    }

    return nok(code)
  }
  /** @type {State} */

  function completeEnd(code) {
    if (code === 62) {
      effects.consume(code);
      return completeAfter
    }

    return nok(code)
  }
  /** @type {State} */

  function completeAfter(code) {
    if (markdownSpace(code)) {
      effects.consume(code);
      return completeAfter
    }

    return code === null || markdownLineEnding(code)
      ? continuation(code)
      : nok(code)
  }
  /** @type {State} */

  function continuation(code) {
    if (code === 45 && kind === 2) {
      effects.consume(code);
      return continuationCommentInside
    }

    if (code === 60 && kind === 1) {
      effects.consume(code);
      return continuationRawTagOpen
    }

    if (code === 62 && kind === 4) {
      effects.consume(code);
      return continuationClose
    }

    if (code === 63 && kind === 3) {
      effects.consume(code);
      return continuationDeclarationInside
    }

    if (code === 93 && kind === 5) {
      effects.consume(code);
      return continuationCharacterDataInside
    }

    if (markdownLineEnding(code) && (kind === 6 || kind === 7)) {
      return effects.check(
        nextBlankConstruct,
        continuationClose,
        continuationAtLineEnding
      )(code)
    }

    if (code === null || markdownLineEnding(code)) {
      return continuationAtLineEnding(code)
    }

    effects.consume(code);
    return continuation
  }
  /** @type {State} */

  function continuationAtLineEnding(code) {
    effects.exit('htmlFlowData');
    return htmlContinueStart(code)
  }
  /** @type {State} */

  function htmlContinueStart(code) {
    if (code === null) {
      return done(code)
    }

    if (markdownLineEnding(code)) {
      return effects.attempt(
        {
          tokenize: htmlLineEnd,
          partial: true
        },
        htmlContinueStart,
        done
      )(code)
    }

    effects.enter('htmlFlowData');
    return continuation(code)
  }
  /** @type {Tokenizer} */

  function htmlLineEnd(effects, ok, nok) {
    return start
    /** @type {State} */

    function start(code) {
      effects.enter('lineEnding');
      effects.consume(code);
      effects.exit('lineEnding');
      return lineStart
    }
    /** @type {State} */

    function lineStart(code) {
      return self.parser.lazy[self.now().line] ? nok(code) : ok(code)
    }
  }
  /** @type {State} */

  function continuationCommentInside(code) {
    if (code === 45) {
      effects.consume(code);
      return continuationDeclarationInside
    }

    return continuation(code)
  }
  /** @type {State} */

  function continuationRawTagOpen(code) {
    if (code === 47) {
      effects.consume(code);
      buffer = '';
      return continuationRawEndTag
    }

    return continuation(code)
  }
  /** @type {State} */

  function continuationRawEndTag(code) {
    if (code === 62 && htmlRawNames.includes(buffer.toLowerCase())) {
      effects.consume(code);
      return continuationClose
    }

    if (asciiAlpha(code) && buffer.length < 8) {
      effects.consume(code);
      buffer += String.fromCharCode(code);
      return continuationRawEndTag
    }

    return continuation(code)
  }
  /** @type {State} */

  function continuationCharacterDataInside(code) {
    if (code === 93) {
      effects.consume(code);
      return continuationDeclarationInside
    }

    return continuation(code)
  }
  /** @type {State} */

  function continuationDeclarationInside(code) {
    if (code === 62) {
      effects.consume(code);
      return continuationClose
    } // More dashes.

    if (code === 45 && kind === 2) {
      effects.consume(code);
      return continuationDeclarationInside
    }

    return continuation(code)
  }
  /** @type {State} */

  function continuationClose(code) {
    if (code === null || markdownLineEnding(code)) {
      effects.exit('htmlFlowData');
      return done(code)
    }

    effects.consume(code);
    return continuationClose
  }
  /** @type {State} */

  function done(code) {
    effects.exit('htmlFlow');
    return ok(code)
  }
}
/** @type {Tokenizer} */

function tokenizeNextBlank(effects, ok, nok) {
  return start
  /** @type {State} */

  function start(code) {
    effects.exit('htmlFlowData');
    effects.enter('lineEndingBlank');
    effects.consume(code);
    effects.exit('lineEndingBlank');
    return effects.attempt(blankLine, ok, nok)
  }
}

/**
 * @typedef {import('micromark-util-types').Construct} Construct
 * @typedef {import('micromark-util-types').Tokenizer} Tokenizer
 * @typedef {import('micromark-util-types').State} State
 * @typedef {import('micromark-util-types').Code} Code
 */

/** @type {Construct} */
const htmlText = {
  name: 'htmlText',
  tokenize: tokenizeHtmlText
};
/** @type {Tokenizer} */

function tokenizeHtmlText(effects, ok, nok) {
  const self = this;
  /** @type {NonNullable<Code>|undefined} */

  let marker;
  /** @type {string} */

  let buffer;
  /** @type {number} */

  let index;
  /** @type {State} */

  let returnState;
  return start
  /** @type {State} */

  function start(code) {
    effects.enter('htmlText');
    effects.enter('htmlTextData');
    effects.consume(code);
    return open
  }
  /** @type {State} */

  function open(code) {
    if (code === 33) {
      effects.consume(code);
      return declarationOpen
    }

    if (code === 47) {
      effects.consume(code);
      return tagCloseStart
    }

    if (code === 63) {
      effects.consume(code);
      return instruction
    }

    if (asciiAlpha(code)) {
      effects.consume(code);
      return tagOpen
    }

    return nok(code)
  }
  /** @type {State} */

  function declarationOpen(code) {
    if (code === 45) {
      effects.consume(code);
      return commentOpen
    }

    if (code === 91) {
      effects.consume(code);
      buffer = 'CDATA[';
      index = 0;
      return cdataOpen
    }

    if (asciiAlpha(code)) {
      effects.consume(code);
      return declaration
    }

    return nok(code)
  }
  /** @type {State} */

  function commentOpen(code) {
    if (code === 45) {
      effects.consume(code);
      return commentStart
    }

    return nok(code)
  }
  /** @type {State} */

  function commentStart(code) {
    if (code === null || code === 62) {
      return nok(code)
    }

    if (code === 45) {
      effects.consume(code);
      return commentStartDash
    }

    return comment(code)
  }
  /** @type {State} */

  function commentStartDash(code) {
    if (code === null || code === 62) {
      return nok(code)
    }

    return comment(code)
  }
  /** @type {State} */

  function comment(code) {
    if (code === null) {
      return nok(code)
    }

    if (code === 45) {
      effects.consume(code);
      return commentClose
    }

    if (markdownLineEnding(code)) {
      returnState = comment;
      return atLineEnding(code)
    }

    effects.consume(code);
    return comment
  }
  /** @type {State} */

  function commentClose(code) {
    if (code === 45) {
      effects.consume(code);
      return end
    }

    return comment(code)
  }
  /** @type {State} */

  function cdataOpen(code) {
    if (code === buffer.charCodeAt(index++)) {
      effects.consume(code);
      return index === buffer.length ? cdata : cdataOpen
    }

    return nok(code)
  }
  /** @type {State} */

  function cdata(code) {
    if (code === null) {
      return nok(code)
    }

    if (code === 93) {
      effects.consume(code);
      return cdataClose
    }

    if (markdownLineEnding(code)) {
      returnState = cdata;
      return atLineEnding(code)
    }

    effects.consume(code);
    return cdata
  }
  /** @type {State} */

  function cdataClose(code) {
    if (code === 93) {
      effects.consume(code);
      return cdataEnd
    }

    return cdata(code)
  }
  /** @type {State} */

  function cdataEnd(code) {
    if (code === 62) {
      return end(code)
    }

    if (code === 93) {
      effects.consume(code);
      return cdataEnd
    }

    return cdata(code)
  }
  /** @type {State} */

  function declaration(code) {
    if (code === null || code === 62) {
      return end(code)
    }

    if (markdownLineEnding(code)) {
      returnState = declaration;
      return atLineEnding(code)
    }

    effects.consume(code);
    return declaration
  }
  /** @type {State} */

  function instruction(code) {
    if (code === null) {
      return nok(code)
    }

    if (code === 63) {
      effects.consume(code);
      return instructionClose
    }

    if (markdownLineEnding(code)) {
      returnState = instruction;
      return atLineEnding(code)
    }

    effects.consume(code);
    return instruction
  }
  /** @type {State} */

  function instructionClose(code) {
    return code === 62 ? end(code) : instruction(code)
  }
  /** @type {State} */

  function tagCloseStart(code) {
    if (asciiAlpha(code)) {
      effects.consume(code);
      return tagClose
    }

    return nok(code)
  }
  /** @type {State} */

  function tagClose(code) {
    if (code === 45 || asciiAlphanumeric(code)) {
      effects.consume(code);
      return tagClose
    }

    return tagCloseBetween(code)
  }
  /** @type {State} */

  function tagCloseBetween(code) {
    if (markdownLineEnding(code)) {
      returnState = tagCloseBetween;
      return atLineEnding(code)
    }

    if (markdownSpace(code)) {
      effects.consume(code);
      return tagCloseBetween
    }

    return end(code)
  }
  /** @type {State} */

  function tagOpen(code) {
    if (code === 45 || asciiAlphanumeric(code)) {
      effects.consume(code);
      return tagOpen
    }

    if (code === 47 || code === 62 || markdownLineEndingOrSpace(code)) {
      return tagOpenBetween(code)
    }

    return nok(code)
  }
  /** @type {State} */

  function tagOpenBetween(code) {
    if (code === 47) {
      effects.consume(code);
      return end
    }

    if (code === 58 || code === 95 || asciiAlpha(code)) {
      effects.consume(code);
      return tagOpenAttributeName
    }

    if (markdownLineEnding(code)) {
      returnState = tagOpenBetween;
      return atLineEnding(code)
    }

    if (markdownSpace(code)) {
      effects.consume(code);
      return tagOpenBetween
    }

    return end(code)
  }
  /** @type {State} */

  function tagOpenAttributeName(code) {
    if (
      code === 45 ||
      code === 46 ||
      code === 58 ||
      code === 95 ||
      asciiAlphanumeric(code)
    ) {
      effects.consume(code);
      return tagOpenAttributeName
    }

    return tagOpenAttributeNameAfter(code)
  }
  /** @type {State} */

  function tagOpenAttributeNameAfter(code) {
    if (code === 61) {
      effects.consume(code);
      return tagOpenAttributeValueBefore
    }

    if (markdownLineEnding(code)) {
      returnState = tagOpenAttributeNameAfter;
      return atLineEnding(code)
    }

    if (markdownSpace(code)) {
      effects.consume(code);
      return tagOpenAttributeNameAfter
    }

    return tagOpenBetween(code)
  }
  /** @type {State} */

  function tagOpenAttributeValueBefore(code) {
    if (
      code === null ||
      code === 60 ||
      code === 61 ||
      code === 62 ||
      code === 96
    ) {
      return nok(code)
    }

    if (code === 34 || code === 39) {
      effects.consume(code);
      marker = code;
      return tagOpenAttributeValueQuoted
    }

    if (markdownLineEnding(code)) {
      returnState = tagOpenAttributeValueBefore;
      return atLineEnding(code)
    }

    if (markdownSpace(code)) {
      effects.consume(code);
      return tagOpenAttributeValueBefore
    }

    effects.consume(code);
    marker = undefined;
    return tagOpenAttributeValueUnquoted
  }
  /** @type {State} */

  function tagOpenAttributeValueQuoted(code) {
    if (code === marker) {
      effects.consume(code);
      return tagOpenAttributeValueQuotedAfter
    }

    if (code === null) {
      return nok(code)
    }

    if (markdownLineEnding(code)) {
      returnState = tagOpenAttributeValueQuoted;
      return atLineEnding(code)
    }

    effects.consume(code);
    return tagOpenAttributeValueQuoted
  }
  /** @type {State} */

  function tagOpenAttributeValueQuotedAfter(code) {
    if (code === 62 || code === 47 || markdownLineEndingOrSpace(code)) {
      return tagOpenBetween(code)
    }

    return nok(code)
  }
  /** @type {State} */

  function tagOpenAttributeValueUnquoted(code) {
    if (
      code === null ||
      code === 34 ||
      code === 39 ||
      code === 60 ||
      code === 61 ||
      code === 96
    ) {
      return nok(code)
    }

    if (code === 62 || markdownLineEndingOrSpace(code)) {
      return tagOpenBetween(code)
    }

    effects.consume(code);
    return tagOpenAttributeValueUnquoted
  } // We can‚Äôt have blank lines in content, so no need to worry about empty
  // tokens.

  /** @type {State} */

  function atLineEnding(code) {
    effects.exit('htmlTextData');
    effects.enter('lineEnding');
    effects.consume(code);
    effects.exit('lineEnding');
    return factorySpace(
      effects,
      afterPrefix,
      'linePrefix',
      self.parser.constructs.disable.null.includes('codeIndented')
        ? undefined
        : 4
    )
  }
  /** @type {State} */

  function afterPrefix(code) {
    effects.enter('htmlTextData');
    return returnState(code)
  }
  /** @type {State} */

  function end(code) {
    if (code === 62) {
      effects.consume(code);
      effects.exit('htmlTextData');
      effects.exit('htmlText');
      return ok
    }

    return nok(code)
  }
}

/**
 * @typedef {import('micromark-util-types').Construct} Construct
 * @typedef {import('micromark-util-types').Resolver} Resolver
 * @typedef {import('micromark-util-types').Tokenizer} Tokenizer
 * @typedef {import('micromark-util-types').Event} Event
 * @typedef {import('micromark-util-types').Token} Token
 * @typedef {import('micromark-util-types').State} State
 * @typedef {import('micromark-util-types').Code} Code
 */

/** @type {Construct} */
const labelEnd = {
  name: 'labelEnd',
  tokenize: tokenizeLabelEnd,
  resolveTo: resolveToLabelEnd,
  resolveAll: resolveAllLabelEnd
};
/** @type {Construct} */

const resourceConstruct = {
  tokenize: tokenizeResource
};
/** @type {Construct} */

const fullReferenceConstruct = {
  tokenize: tokenizeFullReference
};
/** @type {Construct} */

const collapsedReferenceConstruct = {
  tokenize: tokenizeCollapsedReference
};
/** @type {Resolver} */

function resolveAllLabelEnd(events) {
  let index = -1;
  /** @type {Token} */

  let token;

  while (++index < events.length) {
    token = events[index][1];

    if (
      token.type === 'labelImage' ||
      token.type === 'labelLink' ||
      token.type === 'labelEnd'
    ) {
      // Remove the marker.
      events.splice(index + 1, token.type === 'labelImage' ? 4 : 2);
      token.type = 'data';
      index++;
    }
  }

  return events
}
/** @type {Resolver} */

function resolveToLabelEnd(events, context) {
  let index = events.length;
  let offset = 0;
  /** @type {Token} */

  let token;
  /** @type {number|undefined} */

  let open;
  /** @type {number|undefined} */

  let close;
  /** @type {Event[]} */

  let media; // Find an opening.

  while (index--) {
    token = events[index][1];

    if (open) {
      // If we see another link, or inactive link label, we‚Äôve been here before.
      if (
        token.type === 'link' ||
        (token.type === 'labelLink' && token._inactive)
      ) {
        break
      } // Mark other link openings as inactive, as we can‚Äôt have links in
      // links.

      if (events[index][0] === 'enter' && token.type === 'labelLink') {
        token._inactive = true;
      }
    } else if (close) {
      if (
        events[index][0] === 'enter' &&
        (token.type === 'labelImage' || token.type === 'labelLink') &&
        !token._balanced
      ) {
        open = index;

        if (token.type !== 'labelLink') {
          offset = 2;
          break
        }
      }
    } else if (token.type === 'labelEnd') {
      close = index;
    }
  }

  const group = {
    type: events[open][1].type === 'labelLink' ? 'link' : 'image',
    start: Object.assign({}, events[open][1].start),
    end: Object.assign({}, events[events.length - 1][1].end)
  };
  const label = {
    type: 'label',
    start: Object.assign({}, events[open][1].start),
    end: Object.assign({}, events[close][1].end)
  };
  const text = {
    type: 'labelText',
    start: Object.assign({}, events[open + offset + 2][1].end),
    end: Object.assign({}, events[close - 2][1].start)
  };
  media = [
    ['enter', group, context],
    ['enter', label, context]
  ]; // Opening marker.

  media = push(media, events.slice(open + 1, open + offset + 3)); // Text open.

  media = push(media, [['enter', text, context]]); // Between.

  media = push(
    media,
    resolveAll(
      context.parser.constructs.insideSpan.null,
      events.slice(open + offset + 4, close - 3),
      context
    )
  ); // Text close, marker close, label close.

  media = push(media, [
    ['exit', text, context],
    events[close - 2],
    events[close - 1],
    ['exit', label, context]
  ]); // Reference, resource, or so.

  media = push(media, events.slice(close + 1)); // Media close.

  media = push(media, [['exit', group, context]]);
  splice(events, open, events.length, media);
  return events
}
/** @type {Tokenizer} */

function tokenizeLabelEnd(effects, ok, nok) {
  const self = this;
  let index = self.events.length;
  /** @type {Token} */

  let labelStart;
  /** @type {boolean} */

  let defined; // Find an opening.

  while (index--) {
    if (
      (self.events[index][1].type === 'labelImage' ||
        self.events[index][1].type === 'labelLink') &&
      !self.events[index][1]._balanced
    ) {
      labelStart = self.events[index][1];
      break
    }
  }

  return start
  /** @type {State} */

  function start(code) {
    if (!labelStart) {
      return nok(code)
    } // It‚Äôs a balanced bracket, but contains a link.

    if (labelStart._inactive) return balanced(code)
    defined = self.parser.defined.includes(
      normalizeIdentifier(
        self.sliceSerialize({
          start: labelStart.end,
          end: self.now()
        })
      )
    );
    effects.enter('labelEnd');
    effects.enter('labelMarker');
    effects.consume(code);
    effects.exit('labelMarker');
    effects.exit('labelEnd');
    return afterLabelEnd
  }
  /** @type {State} */

  function afterLabelEnd(code) {
    // Resource: `[asd](fgh)`.
    if (code === 40) {
      return effects.attempt(
        resourceConstruct,
        ok,
        defined ? ok : balanced
      )(code)
    } // Collapsed (`[asd][]`) or full (`[asd][fgh]`) reference?

    if (code === 91) {
      return effects.attempt(
        fullReferenceConstruct,
        ok,
        defined
          ? effects.attempt(collapsedReferenceConstruct, ok, balanced)
          : balanced
      )(code)
    } // Shortcut reference: `[asd]`?

    return defined ? ok(code) : balanced(code)
  }
  /** @type {State} */

  function balanced(code) {
    labelStart._balanced = true;
    return nok(code)
  }
}
/** @type {Tokenizer} */

function tokenizeResource(effects, ok, nok) {
  return start
  /** @type {State} */

  function start(code) {
    effects.enter('resource');
    effects.enter('resourceMarker');
    effects.consume(code);
    effects.exit('resourceMarker');
    return factoryWhitespace(effects, open)
  }
  /** @type {State} */

  function open(code) {
    if (code === 41) {
      return end(code)
    }

    return factoryDestination(
      effects,
      destinationAfter,
      nok,
      'resourceDestination',
      'resourceDestinationLiteral',
      'resourceDestinationLiteralMarker',
      'resourceDestinationRaw',
      'resourceDestinationString',
      32
    )(code)
  }
  /** @type {State} */

  function destinationAfter(code) {
    return markdownLineEndingOrSpace(code)
      ? factoryWhitespace(effects, between)(code)
      : end(code)
  }
  /** @type {State} */

  function between(code) {
    if (code === 34 || code === 39 || code === 40) {
      return factoryTitle(
        effects,
        factoryWhitespace(effects, end),
        nok,
        'resourceTitle',
        'resourceTitleMarker',
        'resourceTitleString'
      )(code)
    }

    return end(code)
  }
  /** @type {State} */

  function end(code) {
    if (code === 41) {
      effects.enter('resourceMarker');
      effects.consume(code);
      effects.exit('resourceMarker');
      effects.exit('resource');
      return ok
    }

    return nok(code)
  }
}
/** @type {Tokenizer} */

function tokenizeFullReference(effects, ok, nok) {
  const self = this;
  return start
  /** @type {State} */

  function start(code) {
    return factoryLabel.call(
      self,
      effects,
      afterLabel,
      nok,
      'reference',
      'referenceMarker',
      'referenceString'
    )(code)
  }
  /** @type {State} */

  function afterLabel(code) {
    return self.parser.defined.includes(
      normalizeIdentifier(
        self.sliceSerialize(self.events[self.events.length - 1][1]).slice(1, -1)
      )
    )
      ? ok(code)
      : nok(code)
  }
}
/** @type {Tokenizer} */

function tokenizeCollapsedReference(effects, ok, nok) {
  return start
  /** @type {State} */

  function start(code) {
    effects.enter('reference');
    effects.enter('referenceMarker');
    effects.consume(code);
    effects.exit('referenceMarker');
    return open
  }
  /** @type {State} */

  function open(code) {
    if (code === 93) {
      effects.enter('referenceMarker');
      effects.consume(code);
      effects.exit('referenceMarker');
      effects.exit('reference');
      return ok
    }

    return nok(code)
  }
}

/**
 * @typedef {import('micromark-util-types').Construct} Construct
 * @typedef {import('micromark-util-types').Tokenizer} Tokenizer
 * @typedef {import('micromark-util-types').State} State
 */
/** @type {Construct} */

const labelStartImage = {
  name: 'labelStartImage',
  tokenize: tokenizeLabelStartImage,
  resolveAll: labelEnd.resolveAll
};
/** @type {Tokenizer} */

function tokenizeLabelStartImage(effects, ok, nok) {
  const self = this;
  return start
  /** @type {State} */

  function start(code) {
    effects.enter('labelImage');
    effects.enter('labelImageMarker');
    effects.consume(code);
    effects.exit('labelImageMarker');
    return open
  }
  /** @type {State} */

  function open(code) {
    if (code === 91) {
      effects.enter('labelMarker');
      effects.consume(code);
      effects.exit('labelMarker');
      effects.exit('labelImage');
      return after
    }

    return nok(code)
  }
  /** @type {State} */

  function after(code) {
    /* To do: remove in the future once we‚Äôve switched from
     * `micromark-extension-footnote` to `micromark-extension-gfm-footnote`,
     * which doesn‚Äôt need this */

    /* Hidden footnotes hook */

    /* c8 ignore next 3 */
    return code === 94 && '_hiddenFootnoteSupport' in self.parser.constructs
      ? nok(code)
      : ok(code)
  }
}

/**
 * @typedef {import('micromark-util-types').Construct} Construct
 * @typedef {import('micromark-util-types').Tokenizer} Tokenizer
 * @typedef {import('micromark-util-types').State} State
 */
/** @type {Construct} */

const labelStartLink = {
  name: 'labelStartLink',
  tokenize: tokenizeLabelStartLink,
  resolveAll: labelEnd.resolveAll
};
/** @type {Tokenizer} */

function tokenizeLabelStartLink(effects, ok, nok) {
  const self = this;
  return start
  /** @type {State} */

  function start(code) {
    effects.enter('labelLink');
    effects.enter('labelMarker');
    effects.consume(code);
    effects.exit('labelMarker');
    effects.exit('labelLink');
    return after
  }
  /** @type {State} */

  function after(code) {
    /* To do: remove in the future once we‚Äôve switched from
     * `micromark-extension-footnote` to `micromark-extension-gfm-footnote`,
     * which doesn‚Äôt need this */

    /* Hidden footnotes hook. */

    /* c8 ignore next 3 */
    return code === 94 && '_hiddenFootnoteSupport' in self.parser.constructs
      ? nok(code)
      : ok(code)
  }
}

/**
 * @typedef {import('micromark-util-types').Construct} Construct
 * @typedef {import('micromark-util-types').Tokenizer} Tokenizer
 * @typedef {import('micromark-util-types').State} State
 */

/** @type {Construct} */
const lineEnding = {
  name: 'lineEnding',
  tokenize: tokenizeLineEnding
};
/** @type {Tokenizer} */

function tokenizeLineEnding(effects, ok) {
  return start
  /** @type {State} */

  function start(code) {
    effects.enter('lineEnding');
    effects.consume(code);
    effects.exit('lineEnding');
    return factorySpace(effects, ok, 'linePrefix')
  }
}

/**
 * @typedef {import('micromark-util-types').Construct} Construct
 * @typedef {import('micromark-util-types').Tokenizer} Tokenizer
 * @typedef {import('micromark-util-types').State} State
 * @typedef {import('micromark-util-types').Code} Code
 */

/** @type {Construct} */
const thematicBreak$1 = {
  name: 'thematicBreak',
  tokenize: tokenizeThematicBreak
};
/** @type {Tokenizer} */

function tokenizeThematicBreak(effects, ok, nok) {
  let size = 0;
  /** @type {NonNullable<Code>} */

  let marker;
  return start
  /** @type {State} */

  function start(code) {
    effects.enter('thematicBreak');
    marker = code;
    return atBreak(code)
  }
  /** @type {State} */

  function atBreak(code) {
    if (code === marker) {
      effects.enter('thematicBreakSequence');
      return sequence(code)
    }

    if (markdownSpace(code)) {
      return factorySpace(effects, atBreak, 'whitespace')(code)
    }

    if (size < 3 || (code !== null && !markdownLineEnding(code))) {
      return nok(code)
    }

    effects.exit('thematicBreak');
    return ok(code)
  }
  /** @type {State} */

  function sequence(code) {
    if (code === marker) {
      effects.consume(code);
      size++;
      return sequence
    }

    effects.exit('thematicBreakSequence');
    return atBreak(code)
  }
}

/**
 * @typedef {import('micromark-util-types').Construct} Construct
 * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext
 * @typedef {import('micromark-util-types').Exiter} Exiter
 * @typedef {import('micromark-util-types').Tokenizer} Tokenizer
 * @typedef {import('micromark-util-types').State} State
 * @typedef {import('micromark-util-types').Code} Code
 */
/** @type {Construct} */

const list$1 = {
  name: 'list',
  tokenize: tokenizeListStart,
  continuation: {
    tokenize: tokenizeListContinuation
  },
  exit: tokenizeListEnd
};
/** @type {Construct} */

const listItemPrefixWhitespaceConstruct = {
  tokenize: tokenizeListItemPrefixWhitespace,
  partial: true
};
/** @type {Construct} */

const indentConstruct = {
  tokenize: tokenizeIndent$1,
  partial: true
};
/**
 * @type {Tokenizer}
 * @this {TokenizeContextWithState}
 */

function tokenizeListStart(effects, ok, nok) {
  const self = this;
  const tail = self.events[self.events.length - 1];
  let initialSize =
    tail && tail[1].type === 'linePrefix'
      ? tail[2].sliceSerialize(tail[1], true).length
      : 0;
  let size = 0;
  return start
  /** @type {State} */

  function start(code) {
    const kind =
      self.containerState.type ||
      (code === 42 || code === 43 || code === 45
        ? 'listUnordered'
        : 'listOrdered');

    if (
      kind === 'listUnordered'
        ? !self.containerState.marker || code === self.containerState.marker
        : asciiDigit(code)
    ) {
      if (!self.containerState.type) {
        self.containerState.type = kind;
        effects.enter(kind, {
          _container: true
        });
      }

      if (kind === 'listUnordered') {
        effects.enter('listItemPrefix');
        return code === 42 || code === 45
          ? effects.check(thematicBreak$1, nok, atMarker)(code)
          : atMarker(code)
      }

      if (!self.interrupt || code === 49) {
        effects.enter('listItemPrefix');
        effects.enter('listItemValue');
        return inside(code)
      }
    }

    return nok(code)
  }
  /** @type {State} */

  function inside(code) {
    if (asciiDigit(code) && ++size < 10) {
      effects.consume(code);
      return inside
    }

    if (
      (!self.interrupt || size < 2) &&
      (self.containerState.marker
        ? code === self.containerState.marker
        : code === 41 || code === 46)
    ) {
      effects.exit('listItemValue');
      return atMarker(code)
    }

    return nok(code)
  }
  /**
   * @type {State}
   **/

  function atMarker(code) {
    effects.enter('listItemMarker');
    effects.consume(code);
    effects.exit('listItemMarker');
    self.containerState.marker = self.containerState.marker || code;
    return effects.check(
      blankLine, // Can‚Äôt be empty when interrupting.
      self.interrupt ? nok : onBlank,
      effects.attempt(
        listItemPrefixWhitespaceConstruct,
        endOfPrefix,
        otherPrefix
      )
    )
  }
  /** @type {State} */

  function onBlank(code) {
    self.containerState.initialBlankLine = true;
    initialSize++;
    return endOfPrefix(code)
  }
  /** @type {State} */

  function otherPrefix(code) {
    if (markdownSpace(code)) {
      effects.enter('listItemPrefixWhitespace');
      effects.consume(code);
      effects.exit('listItemPrefixWhitespace');
      return endOfPrefix
    }

    return nok(code)
  }
  /** @type {State} */

  function endOfPrefix(code) {
    self.containerState.size =
      initialSize +
      self.sliceSerialize(effects.exit('listItemPrefix'), true).length;
    return ok(code)
  }
}
/**
 * @type {Tokenizer}
 * @this {TokenizeContextWithState}
 */

function tokenizeListContinuation(effects, ok, nok) {
  const self = this;
  self.containerState._closeFlow = undefined;
  return effects.check(blankLine, onBlank, notBlank)
  /** @type {State} */

  function onBlank(code) {
    self.containerState.furtherBlankLines =
      self.containerState.furtherBlankLines ||
      self.containerState.initialBlankLine; // We have a blank line.
    // Still, try to consume at most the items size.

    return factorySpace(
      effects,
      ok,
      'listItemIndent',
      self.containerState.size + 1
    )(code)
  }
  /** @type {State} */

  function notBlank(code) {
    if (self.containerState.furtherBlankLines || !markdownSpace(code)) {
      self.containerState.furtherBlankLines = undefined;
      self.containerState.initialBlankLine = undefined;
      return notInCurrentItem(code)
    }

    self.containerState.furtherBlankLines = undefined;
    self.containerState.initialBlankLine = undefined;
    return effects.attempt(indentConstruct, ok, notInCurrentItem)(code)
  }
  /** @type {State} */

  function notInCurrentItem(code) {
    // While we do continue, we signal that the flow should be closed.
    self.containerState._closeFlow = true; // As we‚Äôre closing flow, we‚Äôre no longer interrupting.

    self.interrupt = undefined;
    return factorySpace(
      effects,
      effects.attempt(list$1, ok, nok),
      'linePrefix',
      self.parser.constructs.disable.null.includes('codeIndented')
        ? undefined
        : 4
    )(code)
  }
}
/**
 * @type {Tokenizer}
 * @this {TokenizeContextWithState}
 */

function tokenizeIndent$1(effects, ok, nok) {
  const self = this;
  return factorySpace(
    effects,
    afterPrefix,
    'listItemIndent',
    self.containerState.size + 1
  )
  /** @type {State} */

  function afterPrefix(code) {
    const tail = self.events[self.events.length - 1];
    return tail &&
      tail[1].type === 'listItemIndent' &&
      tail[2].sliceSerialize(tail[1], true).length === self.containerState.size
      ? ok(code)
      : nok(code)
  }
}
/**
 * @type {Exiter}
 * @this {TokenizeContextWithState}
 */

function tokenizeListEnd(effects) {
  effects.exit(this.containerState.type);
}
/**
 * @type {Tokenizer}
 * @this {TokenizeContextWithState}
 */

function tokenizeListItemPrefixWhitespace(effects, ok, nok) {
  const self = this;
  return factorySpace(
    effects,
    afterPrefix,
    'listItemPrefixWhitespace',
    self.parser.constructs.disable.null.includes('codeIndented')
      ? undefined
      : 4 + 1
  )
  /** @type {State} */

  function afterPrefix(code) {
    const tail = self.events[self.events.length - 1];
    return !markdownSpace(code) &&
      tail &&
      tail[1].type === 'listItemPrefixWhitespace'
      ? ok(code)
      : nok(code)
  }
}

/**
 * @typedef {import('micromark-util-types').Construct} Construct
 * @typedef {import('micromark-util-types').Resolver} Resolver
 * @typedef {import('micromark-util-types').Tokenizer} Tokenizer
 * @typedef {import('micromark-util-types').State} State
 * @typedef {import('micromark-util-types').Code} Code
 */

/** @type {Construct} */
const setextUnderline = {
  name: 'setextUnderline',
  tokenize: tokenizeSetextUnderline,
  resolveTo: resolveToSetextUnderline
};
/** @type {Resolver} */

function resolveToSetextUnderline(events, context) {
  let index = events.length;
  /** @type {number|undefined} */

  let content;
  /** @type {number|undefined} */

  let text;
  /** @type {number|undefined} */

  let definition; // Find the opening of the content.
  // It‚Äôll always exist: we don‚Äôt tokenize if it isn‚Äôt there.

  while (index--) {
    if (events[index][0] === 'enter') {
      if (events[index][1].type === 'content') {
        content = index;
        break
      }

      if (events[index][1].type === 'paragraph') {
        text = index;
      }
    } // Exit
    else {
      if (events[index][1].type === 'content') {
        // Remove the content end (if needed we‚Äôll add it later)
        events.splice(index, 1);
      }

      if (!definition && events[index][1].type === 'definition') {
        definition = index;
      }
    }
  }

  const heading = {
    type: 'setextHeading',
    start: Object.assign({}, events[text][1].start),
    end: Object.assign({}, events[events.length - 1][1].end)
  }; // Change the paragraph to setext heading text.

  events[text][1].type = 'setextHeadingText'; // If we have definitions in the content, we‚Äôll keep on having content,
  // but we need move it.

  if (definition) {
    events.splice(text, 0, ['enter', heading, context]);
    events.splice(definition + 1, 0, ['exit', events[content][1], context]);
    events[content][1].end = Object.assign({}, events[definition][1].end);
  } else {
    events[content][1] = heading;
  } // Add the heading exit at the end.

  events.push(['exit', heading, context]);
  return events
}
/** @type {Tokenizer} */

function tokenizeSetextUnderline(effects, ok, nok) {
  const self = this;
  let index = self.events.length;
  /** @type {NonNullable<Code>} */

  let marker;
  /** @type {boolean} */

  let paragraph; // Find an opening.

  while (index--) {
    // Skip enter/exit of line ending, line prefix, and content.
    // We can now either have a definition or a paragraph.
    if (
      self.events[index][1].type !== 'lineEnding' &&
      self.events[index][1].type !== 'linePrefix' &&
      self.events[index][1].type !== 'content'
    ) {
      paragraph = self.events[index][1].type === 'paragraph';
      break
    }
  }

  return start
  /** @type {State} */

  function start(code) {
    if (!self.parser.lazy[self.now().line] && (self.interrupt || paragraph)) {
      effects.enter('setextHeadingLine');
      effects.enter('setextHeadingLineSequence');
      marker = code;
      return closingSequence(code)
    }

    return nok(code)
  }
  /** @type {State} */

  function closingSequence(code) {
    if (code === marker) {
      effects.consume(code);
      return closingSequence
    }

    effects.exit('setextHeadingLineSequence');
    return factorySpace(effects, closingSequenceEnd, 'lineSuffix')(code)
  }
  /** @type {State} */

  function closingSequenceEnd(code) {
    if (code === null || markdownLineEnding(code)) {
      effects.exit('setextHeadingLine');
      return ok(code)
    }

    return nok(code)
  }
}

/**
 * @typedef {import('micromark-util-types').InitialConstruct} InitialConstruct
 * @typedef {import('micromark-util-types').Initializer} Initializer
 * @typedef {import('micromark-util-types').State} State
 */

/** @type {InitialConstruct} */
const flow$1 = {
  tokenize: initializeFlow
};
/** @type {Initializer} */

function initializeFlow(effects) {
  const self = this;
  const initial = effects.attempt(
    // Try to parse a blank line.
    blankLine,
    atBlankEnding, // Try to parse initial flow (essentially, only code).
    effects.attempt(
      this.parser.constructs.flowInitial,
      afterConstruct,
      factorySpace(
        effects,
        effects.attempt(
          this.parser.constructs.flow,
          afterConstruct,
          effects.attempt(content, afterConstruct)
        ),
        'linePrefix'
      )
    )
  );
  return initial
  /** @type {State} */

  function atBlankEnding(code) {
    if (code === null) {
      effects.consume(code);
      return
    }

    effects.enter('lineEndingBlank');
    effects.consume(code);
    effects.exit('lineEndingBlank');
    self.currentConstruct = undefined;
    return initial
  }
  /** @type {State} */

  function afterConstruct(code) {
    if (code === null) {
      effects.consume(code);
      return
    }

    effects.enter('lineEnding');
    effects.consume(code);
    effects.exit('lineEnding');
    self.currentConstruct = undefined;
    return initial
  }
}

/**
 * @typedef {import('micromark-util-types').Resolver} Resolver
 * @typedef {import('micromark-util-types').Initializer} Initializer
 * @typedef {import('micromark-util-types').Construct} Construct
 * @typedef {import('micromark-util-types').InitialConstruct} InitialConstruct
 * @typedef {import('micromark-util-types').State} State
 * @typedef {import('micromark-util-types').Code} Code
 */
const resolver = {
  resolveAll: createResolver()
};
const string$1 = initializeFactory('string');
const text$3 = initializeFactory('text');
/**
 * @param {'string'|'text'} field
 * @returns {InitialConstruct}
 */

function initializeFactory(field) {
  return {
    tokenize: initializeText,
    resolveAll: createResolver(
      field === 'text' ? resolveAllLineSuffixes : undefined
    )
  }
  /** @type {Initializer} */

  function initializeText(effects) {
    const self = this;
    const constructs = this.parser.constructs[field];
    const text = effects.attempt(constructs, start, notText);
    return start
    /** @type {State} */

    function start(code) {
      return atBreak(code) ? text(code) : notText(code)
    }
    /** @type {State} */

    function notText(code) {
      if (code === null) {
        effects.consume(code);
        return
      }

      effects.enter('data');
      effects.consume(code);
      return data
    }
    /** @type {State} */

    function data(code) {
      if (atBreak(code)) {
        effects.exit('data');
        return text(code)
      } // Data.

      effects.consume(code);
      return data
    }
    /**
     * @param {Code} code
     * @returns {boolean}
     */

    function atBreak(code) {
      if (code === null) {
        return true
      }

      const list = constructs[code];
      let index = -1;

      if (list) {
        while (++index < list.length) {
          const item = list[index];

          if (!item.previous || item.previous.call(self, self.previous)) {
            return true
          }
        }
      }

      return false
    }
  }
}
/**
 * @param {Resolver} [extraResolver]
 * @returns {Resolver}
 */

function createResolver(extraResolver) {
  return resolveAllText
  /** @type {Resolver} */

  function resolveAllText(events, context) {
    let index = -1;
    /** @type {number|undefined} */

    let enter; // A rather boring computation (to merge adjacent `data` events) which
    // improves mm performance by 29%.

    while (++index <= events.length) {
      if (enter === undefined) {
        if (events[index] && events[index][1].type === 'data') {
          enter = index;
          index++;
        }
      } else if (!events[index] || events[index][1].type !== 'data') {
        // Don‚Äôt do anything if there is one data token.
        if (index !== enter + 2) {
          events[enter][1].end = events[index - 1][1].end;
          events.splice(enter + 2, index - enter - 2);
          index = enter + 2;
        }

        enter = undefined;
      }
    }

    return extraResolver ? extraResolver(events, context) : events
  }
}
/**
 * A rather ugly set of instructions which again looks at chunks in the input
 * stream.
 * The reason to do this here is that it is *much* faster to parse in reverse.
 * And that we can‚Äôt hook into `null` to split the line suffix before an EOF.
 * To do: figure out if we can make this into a clean utility, or even in core.
 * As it will be useful for GFMs literal autolink extension (and maybe even
 * tables?)
 *
 * @type {Resolver}
 */

function resolveAllLineSuffixes(events, context) {
  let eventIndex = 0; // Skip first.

  while (++eventIndex <= events.length) {
    if (
      (eventIndex === events.length ||
        events[eventIndex][1].type === 'lineEnding') &&
      events[eventIndex - 1][1].type === 'data'
    ) {
      const data = events[eventIndex - 1][1];
      const chunks = context.sliceStream(data);
      let index = chunks.length;
      let bufferIndex = -1;
      let size = 0;
      /** @type {boolean|undefined} */

      let tabs;

      while (index--) {
        const chunk = chunks[index];

        if (typeof chunk === 'string') {
          bufferIndex = chunk.length;

          while (chunk.charCodeAt(bufferIndex - 1) === 32) {
            size++;
            bufferIndex--;
          }

          if (bufferIndex) break
          bufferIndex = -1;
        } // Number
        else if (chunk === -2) {
          tabs = true;
          size++;
        } else if (chunk === -1) ; else {
          // Replacement character, exit.
          index++;
          break
        }
      }

      if (size) {
        const token = {
          type:
            eventIndex === events.length || tabs || size < 2
              ? 'lineSuffix'
              : 'hardBreakTrailing',
          start: {
            line: data.end.line,
            column: data.end.column - size,
            offset: data.end.offset - size,
            _index: data.start._index + index,
            _bufferIndex: index
              ? bufferIndex
              : data.start._bufferIndex + bufferIndex
          },
          end: Object.assign({}, data.end)
        };
        data.end = Object.assign({}, token.start);

        if (data.start.offset === data.end.offset) {
          Object.assign(data, token);
        } else {
          events.splice(
            eventIndex,
            0,
            ['enter', token, context],
            ['exit', token, context]
          );
          eventIndex += 2;
        }
      }

      eventIndex++;
    }
  }

  return events
}

/**
 * @typedef {import('micromark-util-types').Code} Code
 * @typedef {import('micromark-util-types').Chunk} Chunk
 * @typedef {import('micromark-util-types').Point} Point
 * @typedef {import('micromark-util-types').Token} Token
 * @typedef {import('micromark-util-types').Effects} Effects
 * @typedef {import('micromark-util-types').State} State
 * @typedef {import('micromark-util-types').Construct} Construct
 * @typedef {import('micromark-util-types').InitialConstruct} InitialConstruct
 * @typedef {import('micromark-util-types').ConstructRecord} ConstructRecord
 * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext
 * @typedef {import('micromark-util-types').ParseContext} ParseContext
 */

/**
 * Create a tokenizer.
 * Tokenizers deal with one type of data (e.g., containers, flow, text).
 * The parser is the object dealing with it all.
 * `initialize` works like other constructs, except that only its `tokenize`
 * function is used, in which case it doesn‚Äôt receive an `ok` or `nok`.
 * `from` can be given to set the point before the first character, although
 * when further lines are indented, they must be set with `defineSkip`.
 *
 * @param {ParseContext} parser
 * @param {InitialConstruct} initialize
 * @param {Omit<Point, '_index'|'_bufferIndex'>} [from]
 * @returns {TokenizeContext}
 */
function createTokenizer(parser, initialize, from) {
  /** @type {Point} */
  let point = Object.assign(
    from
      ? Object.assign({}, from)
      : {
          line: 1,
          column: 1,
          offset: 0
        },
    {
      _index: 0,
      _bufferIndex: -1
    }
  );
  /** @type {Record<string, number>} */

  const columnStart = {};
  /** @type {Array<Construct>} */

  const resolveAllConstructs = [];
  /** @type {Array<Chunk>} */

  let chunks = [];
  /** @type {Array<Token>} */

  let stack = [];
  /**
   * Tools used for tokenizing.
   *
   * @type {Effects}
   */

  const effects = {
    consume,
    enter,
    exit,
    attempt: constructFactory(onsuccessfulconstruct),
    check: constructFactory(onsuccessfulcheck),
    interrupt: constructFactory(onsuccessfulcheck, {
      interrupt: true
    })
  };
  /**
   * State and tools for resolving and serializing.
   *
   * @type {TokenizeContext}
   */

  const context = {
    previous: null,
    code: null,
    containerState: {},
    events: [],
    parser,
    sliceStream,
    sliceSerialize,
    now,
    defineSkip,
    write
  };
  /**
   * The state function.
   *
   * @type {State|void}
   */

  let state = initialize.tokenize.call(context, effects);

  if (initialize.resolveAll) {
    resolveAllConstructs.push(initialize);
  }

  return context
  /** @type {TokenizeContext['write']} */

  function write(slice) {
    chunks = push(chunks, slice);
    main(); // Exit if we‚Äôre not done, resolve might change stuff.

    if (chunks[chunks.length - 1] !== null) {
      return []
    }

    addResult(initialize, 0); // Otherwise, resolve, and exit.

    context.events = resolveAll(resolveAllConstructs, context.events, context);
    return context.events
  } //
  // Tools.
  //

  /** @type {TokenizeContext['sliceSerialize']} */

  function sliceSerialize(token, expandTabs) {
    return serializeChunks(sliceStream(token), expandTabs)
  }
  /** @type {TokenizeContext['sliceStream']} */

  function sliceStream(token) {
    return sliceChunks(chunks, token)
  }
  /** @type {TokenizeContext['now']} */

  function now() {
    return Object.assign({}, point)
  }
  /** @type {TokenizeContext['defineSkip']} */

  function defineSkip(value) {
    columnStart[value.line] = value.column;
    accountForPotentialSkip();
  } //
  // State management.
  //

  /**
   * Main loop (note that `_index` and `_bufferIndex` in `point` are modified by
   * `consume`).
   * Here is where we walk through the chunks, which either include strings of
   * several characters, or numerical character codes.
   * The reason to do this in a loop instead of a call is so the stack can
   * drain.
   *
   * @returns {void}
   */

  function main() {
    /** @type {number} */
    let chunkIndex;

    while (point._index < chunks.length) {
      const chunk = chunks[point._index]; // If we‚Äôre in a buffer chunk, loop through it.

      if (typeof chunk === 'string') {
        chunkIndex = point._index;

        if (point._bufferIndex < 0) {
          point._bufferIndex = 0;
        }

        while (
          point._index === chunkIndex &&
          point._bufferIndex < chunk.length
        ) {
          go(chunk.charCodeAt(point._bufferIndex));
        }
      } else {
        go(chunk);
      }
    }
  }
  /**
   * Deal with one code.
   *
   * @param {Code} code
   * @returns {void}
   */

  function go(code) {
    state = state(code);
  }
  /** @type {Effects['consume']} */

  function consume(code) {
    if (markdownLineEnding(code)) {
      point.line++;
      point.column = 1;
      point.offset += code === -3 ? 2 : 1;
      accountForPotentialSkip();
    } else if (code !== -1) {
      point.column++;
      point.offset++;
    } // Not in a string chunk.

    if (point._bufferIndex < 0) {
      point._index++;
    } else {
      point._bufferIndex++; // At end of string chunk.
      // @ts-expect-error Points w/ non-negative `_bufferIndex` reference
      // strings.

      if (point._bufferIndex === chunks[point._index].length) {
        point._bufferIndex = -1;
        point._index++;
      }
    } // Expose the previous character.

    context.previous = code; // Mark as consumed.
  }
  /** @type {Effects['enter']} */

  function enter(type, fields) {
    /** @type {Token} */
    // @ts-expect-error Patch instead of assign required fields to help GC.
    const token = fields || {};
    token.type = type;
    token.start = now();
    context.events.push(['enter', token, context]);
    stack.push(token);
    return token
  }
  /** @type {Effects['exit']} */

  function exit(type) {
    const token = stack.pop();
    token.end = now();
    context.events.push(['exit', token, context]);
    return token
  }
  /**
   * Use results.
   *
   * @type {ReturnHandle}
   */

  function onsuccessfulconstruct(construct, info) {
    addResult(construct, info.from);
  }
  /**
   * Discard results.
   *
   * @type {ReturnHandle}
   */

  function onsuccessfulcheck(_, info) {
    info.restore();
  }
  /**
   * Factory to attempt/check/interrupt.
   *
   * @param {ReturnHandle} onreturn
   * @param {Record<string, unknown>} [fields]
   */

  function constructFactory(onreturn, fields) {
    return hook
    /**
     * Handle either an object mapping codes to constructs, a list of
     * constructs, or a single construct.
     *
     * @param {Construct|Array<Construct>|ConstructRecord} constructs
     * @param {State} returnState
     * @param {State} [bogusState]
     * @returns {State}
     */

    function hook(constructs, returnState, bogusState) {
      /** @type {Array<Construct>} */
      let listOfConstructs;
      /** @type {number} */

      let constructIndex;
      /** @type {Construct} */

      let currentConstruct;
      /** @type {Info} */

      let info;
      return Array.isArray(constructs)
        ? /* c8 ignore next 1 */
          handleListOfConstructs(constructs)
        : 'tokenize' in constructs // @ts-expect-error Looks like a construct.
        ? handleListOfConstructs([constructs])
        : handleMapOfConstructs(constructs)
      /**
       * Handle a list of construct.
       *
       * @param {ConstructRecord} map
       * @returns {State}
       */

      function handleMapOfConstructs(map) {
        return start
        /** @type {State} */

        function start(code) {
          const def = code !== null && map[code];
          const all = code !== null && map.null;
          const list = [
            // To do: add more extension tests.

            /* c8 ignore next 2 */
            ...(Array.isArray(def) ? def : def ? [def] : []),
            ...(Array.isArray(all) ? all : all ? [all] : [])
          ];
          return handleListOfConstructs(list)(code)
        }
      }
      /**
       * Handle a list of construct.
       *
       * @param {Array<Construct>} list
       * @returns {State}
       */

      function handleListOfConstructs(list) {
        listOfConstructs = list;
        constructIndex = 0;

        if (list.length === 0) {
          return bogusState
        }

        return handleConstruct(list[constructIndex])
      }
      /**
       * Handle a single construct.
       *
       * @param {Construct} construct
       * @returns {State}
       */

      function handleConstruct(construct) {
        return start
        /** @type {State} */

        function start(code) {
          // To do: not needed to store if there is no bogus state, probably?
          // Currently doesn‚Äôt work because `inspect` in document does a check
          // w/o a bogus, which doesn‚Äôt make sense. But it does seem to help perf
          // by not storing.
          info = store();
          currentConstruct = construct;

          if (!construct.partial) {
            context.currentConstruct = construct;
          }

          if (
            construct.name &&
            context.parser.constructs.disable.null.includes(construct.name)
          ) {
            return nok()
          }

          return construct.tokenize.call(
            // If we do have fields, create an object w/ `context` as its
            // prototype.
            // This allows a ‚Äúlive binding‚Äù, which is needed for `interrupt`.
            fields ? Object.assign(Object.create(context), fields) : context,
            effects,
            ok,
            nok
          )(code)
        }
      }
      /** @type {State} */

      function ok(code) {
        onreturn(currentConstruct, info);
        return returnState
      }
      /** @type {State} */

      function nok(code) {
        info.restore();

        if (++constructIndex < listOfConstructs.length) {
          return handleConstruct(listOfConstructs[constructIndex])
        }

        return bogusState
      }
    }
  }
  /**
   * @param {Construct} construct
   * @param {number} from
   * @returns {void}
   */

  function addResult(construct, from) {
    if (construct.resolveAll && !resolveAllConstructs.includes(construct)) {
      resolveAllConstructs.push(construct);
    }

    if (construct.resolve) {
      splice(
        context.events,
        from,
        context.events.length - from,
        construct.resolve(context.events.slice(from), context)
      );
    }

    if (construct.resolveTo) {
      context.events = construct.resolveTo(context.events, context);
    }
  }
  /**
   * Store state.
   *
   * @returns {Info}
   */

  function store() {
    const startPoint = now();
    const startPrevious = context.previous;
    const startCurrentConstruct = context.currentConstruct;
    const startEventsIndex = context.events.length;
    const startStack = Array.from(stack);
    return {
      restore,
      from: startEventsIndex
    }
    /**
     * Restore state.
     *
     * @returns {void}
     */

    function restore() {
      point = startPoint;
      context.previous = startPrevious;
      context.currentConstruct = startCurrentConstruct;
      context.events.length = startEventsIndex;
      stack = startStack;
      accountForPotentialSkip();
    }
  }
  /**
   * Move the current point a bit forward in the line when it‚Äôs on a column
   * skip.
   *
   * @returns {void}
   */

  function accountForPotentialSkip() {
    if (point.line in columnStart && point.column < 2) {
      point.column = columnStart[point.line];
      point.offset += columnStart[point.line] - 1;
    }
  }
}
/**
 * Get the chunks from a slice of chunks in the range of a token.
 *
 * @param {Array<Chunk>} chunks
 * @param {Pick<Token, 'start'|'end'>} token
 * @returns {Array<Chunk>}
 */

function sliceChunks(chunks, token) {
  const startIndex = token.start._index;
  const startBufferIndex = token.start._bufferIndex;
  const endIndex = token.end._index;
  const endBufferIndex = token.end._bufferIndex;
  /** @type {Array<Chunk>} */

  let view;

  if (startIndex === endIndex) {
    // @ts-expect-error `_bufferIndex` is used on string chunks.
    view = [chunks[startIndex].slice(startBufferIndex, endBufferIndex)];
  } else {
    view = chunks.slice(startIndex, endIndex);

    if (startBufferIndex > -1) {
      // @ts-expect-error `_bufferIndex` is used on string chunks.
      view[0] = view[0].slice(startBufferIndex);
    }

    if (endBufferIndex > 0) {
      // @ts-expect-error `_bufferIndex` is used on string chunks.
      view.push(chunks[endIndex].slice(0, endBufferIndex));
    }
  }

  return view
}
/**
 * Get the string value of a slice of chunks.
 *
 * @param {Array<Chunk>} chunks
 * @param {boolean} [expandTabs=false]
 * @returns {string}
 */

function serializeChunks(chunks, expandTabs) {
  let index = -1;
  /** @type {Array<string>} */

  const result = [];
  /** @type {boolean|undefined} */

  let atTab;

  while (++index < chunks.length) {
    const chunk = chunks[index];
    /** @type {string} */

    let value;

    if (typeof chunk === 'string') {
      value = chunk;
    } else
      switch (chunk) {
        case -5: {
          value = '\r';
          break
        }

        case -4: {
          value = '\n';
          break
        }

        case -3: {
          value = '\r' + '\n';
          break
        }

        case -2: {
          value = expandTabs ? ' ' : '\t';
          break
        }

        case -1: {
          if (!expandTabs && atTab) continue
          value = ' ';
          break
        }

        default: {
          // Currently only replacement character.
          value = String.fromCharCode(chunk);
        }
      }

    atTab = chunk === -2;
    result.push(value);
  }

  return result.join('')
}

/**
 * @typedef {import('micromark-util-types').Extension} Extension
 */
/** @type {Extension['document']} */

const document = {
  [42]: list$1,
  [43]: list$1,
  [45]: list$1,
  [48]: list$1,
  [49]: list$1,
  [50]: list$1,
  [51]: list$1,
  [52]: list$1,
  [53]: list$1,
  [54]: list$1,
  [55]: list$1,
  [56]: list$1,
  [57]: list$1,
  [62]: blockQuote
};
/** @type {Extension['contentInitial']} */

const contentInitial = {
  [91]: definition
};
/** @type {Extension['flowInitial']} */

const flowInitial = {
  [-2]: codeIndented,
  [-1]: codeIndented,
  [32]: codeIndented
};
/** @type {Extension['flow']} */

const flow = {
  [35]: headingAtx,
  [42]: thematicBreak$1,
  [45]: [setextUnderline, thematicBreak$1],
  [60]: htmlFlow,
  [61]: setextUnderline,
  [95]: thematicBreak$1,
  [96]: codeFenced,
  [126]: codeFenced
};
/** @type {Extension['string']} */

const string = {
  [38]: characterReference,
  [92]: characterEscape
};
/** @type {Extension['text']} */

const text$2 = {
  [-5]: lineEnding,
  [-4]: lineEnding,
  [-3]: lineEnding,
  [33]: labelStartImage,
  [38]: characterReference,
  [42]: attention,
  [60]: [autolink, htmlText],
  [91]: labelStartLink,
  [92]: [hardBreakEscape, characterEscape],
  [93]: labelEnd,
  [95]: attention,
  [96]: codeText
};
/** @type {Extension['insideSpan']} */

const insideSpan = {
  null: [attention, resolver]
};
/** @type {Extension['attentionMarkers']} */

const attentionMarkers = {
  null: [42, 95]
};
/** @type {Extension['disable']} */

const disable = {
  null: []
};

var defaultConstructs = /*#__PURE__*/Object.freeze({
  __proto__: null,
  attentionMarkers: attentionMarkers,
  contentInitial: contentInitial,
  disable: disable,
  document: document,
  flow: flow,
  flowInitial: flowInitial,
  insideSpan: insideSpan,
  string: string,
  text: text$2
});

/**
 * @typedef {import('micromark-util-types').InitialConstruct} InitialConstruct
 * @typedef {import('micromark-util-types').FullNormalizedExtension} FullNormalizedExtension
 * @typedef {import('micromark-util-types').ParseOptions} ParseOptions
 * @typedef {import('micromark-util-types').ParseContext} ParseContext
 * @typedef {import('micromark-util-types').Create} Create
 */
/**
 * @param {ParseOptions} [options]
 * @returns {ParseContext}
 */

function parse$1(options = {}) {
  /** @type {FullNormalizedExtension} */
  // @ts-expect-error `defaultConstructs` is full, so the result will be too.
  const constructs = combineExtensions(
    // @ts-expect-error Same as above.
    [defaultConstructs].concat(options.extensions || [])
  );
  /** @type {ParseContext} */

  const parser = {
    defined: [],
    lazy: {},
    constructs,
    content: create(content$1),
    document: create(document$1),
    flow: create(flow$1),
    string: create(string$1),
    text: create(text$3)
  };
  return parser
  /**
   * @param {InitialConstruct} initial
   */

  function create(initial) {
    return creator
    /** @type {Create} */

    function creator(from) {
      return createTokenizer(parser, initial, from)
    }
  }
}

/**
 * @typedef {import('micromark-util-types').Encoding} Encoding
 * @typedef {import('micromark-util-types').Value} Value
 * @typedef {import('micromark-util-types').Chunk} Chunk
 * @typedef {import('micromark-util-types').Code} Code
 */

/**
 * @callback Preprocessor
 * @param {Value} value
 * @param {Encoding} [encoding]
 * @param {boolean} [end=false]
 * @returns {Array<Chunk>}
 */
const search = /[\0\t\n\r]/g;
/**
 * @returns {Preprocessor}
 */

function preprocess() {
  let column = 1;
  let buffer = '';
  /** @type {boolean|undefined} */

  let start = true;
  /** @type {boolean|undefined} */

  let atCarriageReturn;
  return preprocessor
  /** @type {Preprocessor} */

  function preprocessor(value, encoding, end) {
    /** @type {Array<Chunk>} */
    const chunks = [];
    /** @type {RegExpMatchArray|null} */

    let match;
    /** @type {number} */

    let next;
    /** @type {number} */

    let startPosition;
    /** @type {number} */

    let endPosition;
    /** @type {Code} */

    let code; // @ts-expect-error `Buffer` does allow an encoding.

    value = buffer + value.toString(encoding);
    startPosition = 0;
    buffer = '';

    if (start) {
      if (value.charCodeAt(0) === 65279) {
        startPosition++;
      }

      start = undefined;
    }

    while (startPosition < value.length) {
      search.lastIndex = startPosition;
      match = search.exec(value);
      endPosition =
        match && match.index !== undefined ? match.index : value.length;
      code = value.charCodeAt(endPosition);

      if (!match) {
        buffer = value.slice(startPosition);
        break
      }

      if (code === 10 && startPosition === endPosition && atCarriageReturn) {
        chunks.push(-3);
        atCarriageReturn = undefined;
      } else {
        if (atCarriageReturn) {
          chunks.push(-5);
          atCarriageReturn = undefined;
        }

        if (startPosition < endPosition) {
          chunks.push(value.slice(startPosition, endPosition));
          column += endPosition - startPosition;
        }

        switch (code) {
          case 0: {
            chunks.push(65533);
            column++;
            break
          }

          case 9: {
            next = Math.ceil(column / 4) * 4;
            chunks.push(-2);

            while (column++ < next) chunks.push(-1);

            break
          }

          case 10: {
            chunks.push(-4);
            column = 1;
            break
          }

          default: {
            atCarriageReturn = true;
            column = 1;
          }
        }
      }

      startPosition = endPosition + 1;
    }

    if (end) {
      if (atCarriageReturn) chunks.push(-5);
      if (buffer) chunks.push(buffer);
      chunks.push(null);
    }

    return chunks
  }
}

/**
 * @typedef {import('micromark-util-types').Event} Event
 */
/**
 * @param {Array<Event>} events
 * @returns {Array<Event>}
 */

function postprocess(events) {
  while (!subtokenize(events)) {
    // Empty
  }

  return events
}

/**
 * Turn the number (in string form as either hexa- or plain decimal) coming from
 * a numeric character reference into a character.
 *
 * @param {string} value
 *   Value to decode.
 * @param {number} base
 *   Numeric base.
 * @returns {string}
 */
function decodeNumericCharacterReference(value, base) {
  const code = Number.parseInt(value, base);

  if (
    // C0 except for HT, LF, FF, CR, space
    code < 9 ||
    code === 11 ||
    (code > 13 && code < 32) || // Control character (DEL) of the basic block and C1 controls.
    (code > 126 && code < 160) || // Lone high surrogates and low surrogates.
    (code > 55295 && code < 57344) || // Noncharacters.
    (code > 64975 && code < 65008) ||
    (code & 65535) === 65535 ||
    (code & 65535) === 65534 || // Out of range
    code > 1114111
  ) {
    return '\uFFFD'
  }

  return String.fromCharCode(code)
}

const characterEscapeOrReference =
  /\\([!-/:-@[-`{-~])|&(#(?:\d{1,7}|x[\da-f]{1,6})|[\da-z]{1,31});/gi;
/**
 * Utility to decode markdown strings (which occur in places such as fenced
 * code info strings, destinations, labels, and titles).
 * The ‚Äústring‚Äù content type allows character escapes and -references.
 * This decodes those.
 *
 * @param {string} value
 * @returns {string}
 */

function decodeString(value) {
  return value.replace(characterEscapeOrReference, decode)
}
/**
 * @param {string} $0
 * @param {string} $1
 * @param {string} $2
 * @returns {string}
 */

function decode($0, $1, $2) {
  if ($1) {
    // Escape.
    return $1
  } // Reference.

  const head = $2.charCodeAt(0);

  if (head === 35) {
    const head = $2.charCodeAt(1);
    const hex = head === 120 || head === 88;
    return decodeNumericCharacterReference($2.slice(hex ? 2 : 1), hex ? 16 : 10)
  }

  return decodeNamedCharacterReference($2) || $0
}

/**
 * @typedef {import('micromark-util-types').Encoding} Encoding
 * @typedef {import('micromark-util-types').Event} Event
 * @typedef {import('micromark-util-types').ParseOptions} ParseOptions
 * @typedef {import('micromark-util-types').Token} Token
 * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext
 * @typedef {import('micromark-util-types').Value} Value
 *
 * @typedef {import('unist').Parent} UnistParent
 * @typedef {import('unist').Point} Point
 *
 * @typedef {import('mdast').PhrasingContent} PhrasingContent
 * @typedef {import('mdast').StaticPhrasingContent} StaticPhrasingContent
 * @typedef {import('mdast').Content} Content
 * @typedef {import('mdast').Break} Break
 * @typedef {import('mdast').Blockquote} Blockquote
 * @typedef {import('mdast').Code} Code
 * @typedef {import('mdast').Definition} Definition
 * @typedef {import('mdast').Emphasis} Emphasis
 * @typedef {import('mdast').Heading} Heading
 * @typedef {import('mdast').HTML} HTML
 * @typedef {import('mdast').Image} Image
 * @typedef {import('mdast').ImageReference} ImageReference
 * @typedef {import('mdast').InlineCode} InlineCode
 * @typedef {import('mdast').Link} Link
 * @typedef {import('mdast').LinkReference} LinkReference
 * @typedef {import('mdast').List} List
 * @typedef {import('mdast').ListItem} ListItem
 * @typedef {import('mdast').Paragraph} Paragraph
 * @typedef {import('mdast').Root} Root
 * @typedef {import('mdast').Strong} Strong
 * @typedef {import('mdast').Text} Text
 * @typedef {import('mdast').ThematicBreak} ThematicBreak
 * @typedef {import('mdast').ReferenceType} ReferenceType
 * @typedef {import('../index.js').CompileData} CompileData
 */
const own$5 = {}.hasOwnProperty;

/**
 * @param value
 *   Markdown to parse.
 * @param encoding
 *   Character encoding for when `value` is `Buffer`.
 * @param options
 *   Configuration.
 * @returns
 *   mdast tree.
 */
const fromMarkdown =
  /**
   * @type {(
   *   ((value: Value, encoding: Encoding, options?: Options | null | undefined) => Root) &
   *   ((value: Value, options?: Options | null | undefined) => Root)
   * )}
   */

  /**
   * @param {Value} value
   * @param {Encoding | Options | null | undefined} [encoding]
   * @param {Options | null | undefined} [options]
   * @returns {Root}
   */
  function (value, encoding, options) {
    if (typeof encoding !== 'string') {
      options = encoding;
      encoding = undefined;
    }
    return compiler(options)(
      postprocess(
        // @ts-expect-error: micromark types need to accept `null`.
        parse$1(options).document().write(preprocess()(value, encoding, true))
      )
    )
  };

/**
 * Note this compiler only understand complete buffering, not streaming.
 *
 * @param {Options | null | undefined} [options]
 */
function compiler(options) {
  /** @type {Config} */
  const config = {
    transforms: [],
    canContainEols: ['emphasis', 'fragment', 'heading', 'paragraph', 'strong'],
    enter: {
      autolink: opener(link),
      autolinkProtocol: onenterdata,
      autolinkEmail: onenterdata,
      atxHeading: opener(heading),
      blockQuote: opener(blockQuote),
      characterEscape: onenterdata,
      characterReference: onenterdata,
      codeFenced: opener(codeFlow),
      codeFencedFenceInfo: buffer,
      codeFencedFenceMeta: buffer,
      codeIndented: opener(codeFlow, buffer),
      codeText: opener(codeText, buffer),
      codeTextData: onenterdata,
      data: onenterdata,
      codeFlowValue: onenterdata,
      definition: opener(definition),
      definitionDestinationString: buffer,
      definitionLabelString: buffer,
      definitionTitleString: buffer,
      emphasis: opener(emphasis),
      hardBreakEscape: opener(hardBreak),
      hardBreakTrailing: opener(hardBreak),
      htmlFlow: opener(html, buffer),
      htmlFlowData: onenterdata,
      htmlText: opener(html, buffer),
      htmlTextData: onenterdata,
      image: opener(image),
      label: buffer,
      link: opener(link),
      listItem: opener(listItem),
      listItemValue: onenterlistitemvalue,
      listOrdered: opener(list, onenterlistordered),
      listUnordered: opener(list),
      paragraph: opener(paragraph),
      reference: onenterreference,
      referenceString: buffer,
      resourceDestinationString: buffer,
      resourceTitleString: buffer,
      setextHeading: opener(heading),
      strong: opener(strong),
      thematicBreak: opener(thematicBreak)
    },
    exit: {
      atxHeading: closer(),
      atxHeadingSequence: onexitatxheadingsequence,
      autolink: closer(),
      autolinkEmail: onexitautolinkemail,
      autolinkProtocol: onexitautolinkprotocol,
      blockQuote: closer(),
      characterEscapeValue: onexitdata,
      characterReferenceMarkerHexadecimal: onexitcharacterreferencemarker,
      characterReferenceMarkerNumeric: onexitcharacterreferencemarker,
      characterReferenceValue: onexitcharacterreferencevalue,
      codeFenced: closer(onexitcodefenced),
      codeFencedFence: onexitcodefencedfence,
      codeFencedFenceInfo: onexitcodefencedfenceinfo,
      codeFencedFenceMeta: onexitcodefencedfencemeta,
      codeFlowValue: onexitdata,
      codeIndented: closer(onexitcodeindented),
      codeText: closer(onexitcodetext),
      codeTextData: onexitdata,
      data: onexitdata,
      definition: closer(),
      definitionDestinationString: onexitdefinitiondestinationstring,
      definitionLabelString: onexitdefinitionlabelstring,
      definitionTitleString: onexitdefinitiontitlestring,
      emphasis: closer(),
      hardBreakEscape: closer(onexithardbreak),
      hardBreakTrailing: closer(onexithardbreak),
      htmlFlow: closer(onexithtmlflow),
      htmlFlowData: onexitdata,
      htmlText: closer(onexithtmltext),
      htmlTextData: onexitdata,
      image: closer(onexitimage),
      label: onexitlabel,
      labelText: onexitlabeltext,
      lineEnding: onexitlineending,
      link: closer(onexitlink),
      listItem: closer(),
      listOrdered: closer(),
      listUnordered: closer(),
      paragraph: closer(),
      referenceString: onexitreferencestring,
      resourceDestinationString: onexitresourcedestinationstring,
      resourceTitleString: onexitresourcetitlestring,
      resource: onexitresource,
      setextHeading: closer(onexitsetextheading),
      setextHeadingLineSequence: onexitsetextheadinglinesequence,
      setextHeadingText: onexitsetextheadingtext,
      strong: closer(),
      thematicBreak: closer()
    }
  };
  configure(config, (options || {}).mdastExtensions || []);

  /** @type {CompileData} */
  const data = {};
  return compile

  /**
   * Turn micromark events into an mdast tree.
   *
   * @param {Array<Event>} events
   *   Events.
   * @returns {Root}
   *   mdast tree.
   */
  function compile(events) {
    /** @type {Root} */
    let tree = {
      type: 'root',
      children: []
    };
    /** @type {Omit<CompileContext, 'sliceSerialize'>} */
    const context = {
      stack: [tree],
      tokenStack: [],
      config,
      enter,
      exit,
      buffer,
      resume,
      setData,
      getData
    };
    /** @type {Array<number>} */
    const listStack = [];
    let index = -1;
    while (++index < events.length) {
      // We preprocess lists to add `listItem` tokens, and to infer whether
      // items the list itself are spread out.
      if (
        events[index][1].type === 'listOrdered' ||
        events[index][1].type === 'listUnordered'
      ) {
        if (events[index][0] === 'enter') {
          listStack.push(index);
        } else {
          const tail = listStack.pop();
          index = prepareList(events, tail, index);
        }
      }
    }
    index = -1;
    while (++index < events.length) {
      const handler = config[events[index][0]];
      if (own$5.call(handler, events[index][1].type)) {
        handler[events[index][1].type].call(
          Object.assign(
            {
              sliceSerialize: events[index][2].sliceSerialize
            },
            context
          ),
          events[index][1]
        );
      }
    }

    // Handle tokens still being open.
    if (context.tokenStack.length > 0) {
      const tail = context.tokenStack[context.tokenStack.length - 1];
      const handler = tail[1] || defaultOnError;
      handler.call(context, undefined, tail[0]);
    }

    // Figure out `root` position.
    tree.position = {
      start: point$1(
        events.length > 0
          ? events[0][1].start
          : {
              line: 1,
              column: 1,
              offset: 0
            }
      ),
      end: point$1(
        events.length > 0
          ? events[events.length - 2][1].end
          : {
              line: 1,
              column: 1,
              offset: 0
            }
      )
    };

    // Call transforms.
    index = -1;
    while (++index < config.transforms.length) {
      tree = config.transforms[index](tree) || tree;
    }
    return tree
  }

  /**
   * @param {Array<Event>} events
   * @param {number} start
   * @param {number} length
   * @returns {number}
   */
  function prepareList(events, start, length) {
    let index = start - 1;
    let containerBalance = -1;
    let listSpread = false;
    /** @type {Token | undefined} */
    let listItem;
    /** @type {number | undefined} */
    let lineIndex;
    /** @type {number | undefined} */
    let firstBlankLineIndex;
    /** @type {boolean | undefined} */
    let atMarker;
    while (++index <= length) {
      const event = events[index];
      if (
        event[1].type === 'listUnordered' ||
        event[1].type === 'listOrdered' ||
        event[1].type === 'blockQuote'
      ) {
        if (event[0] === 'enter') {
          containerBalance++;
        } else {
          containerBalance--;
        }
        atMarker = undefined;
      } else if (event[1].type === 'lineEndingBlank') {
        if (event[0] === 'enter') {
          if (
            listItem &&
            !atMarker &&
            !containerBalance &&
            !firstBlankLineIndex
          ) {
            firstBlankLineIndex = index;
          }
          atMarker = undefined;
        }
      } else if (
        event[1].type === 'linePrefix' ||
        event[1].type === 'listItemValue' ||
        event[1].type === 'listItemMarker' ||
        event[1].type === 'listItemPrefix' ||
        event[1].type === 'listItemPrefixWhitespace'
      ) ; else {
        atMarker = undefined;
      }
      if (
        (!containerBalance &&
          event[0] === 'enter' &&
          event[1].type === 'listItemPrefix') ||
        (containerBalance === -1 &&
          event[0] === 'exit' &&
          (event[1].type === 'listUnordered' ||
            event[1].type === 'listOrdered'))
      ) {
        if (listItem) {
          let tailIndex = index;
          lineIndex = undefined;
          while (tailIndex--) {
            const tailEvent = events[tailIndex];
            if (
              tailEvent[1].type === 'lineEnding' ||
              tailEvent[1].type === 'lineEndingBlank'
            ) {
              if (tailEvent[0] === 'exit') continue
              if (lineIndex) {
                events[lineIndex][1].type = 'lineEndingBlank';
                listSpread = true;
              }
              tailEvent[1].type = 'lineEnding';
              lineIndex = tailIndex;
            } else if (
              tailEvent[1].type === 'linePrefix' ||
              tailEvent[1].type === 'blockQuotePrefix' ||
              tailEvent[1].type === 'blockQuotePrefixWhitespace' ||
              tailEvent[1].type === 'blockQuoteMarker' ||
              tailEvent[1].type === 'listItemIndent'
            ) ; else {
              break
            }
          }
          if (
            firstBlankLineIndex &&
            (!lineIndex || firstBlankLineIndex < lineIndex)
          ) {
            // @ts-expect-error Patched.
            listItem._spread = true;
          }

          // Fix position.
          listItem.end = Object.assign(
            {},
            lineIndex ? events[lineIndex][1].start : event[1].end
          );
          events.splice(lineIndex || index, 0, ['exit', listItem, event[2]]);
          index++;
          length++;
        }

        // Create a new list item.
        if (event[1].type === 'listItemPrefix') {
          listItem = {
            type: 'listItem',
            // @ts-expect-error Patched
            _spread: false,
            start: Object.assign({}, event[1].start)
          };
          // @ts-expect-error: `listItem` is most definitely defined, TS...
          events.splice(index, 0, ['enter', listItem, event[2]]);
          index++;
          length++;
          firstBlankLineIndex = undefined;
          atMarker = true;
        }
      }
    }

    // @ts-expect-error Patched.
    events[start][1]._spread = listSpread;
    return length
  }

  /**
   * Set data.
   *
   * @template {keyof CompileData} Key
   *   Field type.
   * @param {Key} key
   *   Key of field.
   * @param {CompileData[Key]} [value]
   *   New value.
   * @returns {void}
   *   Nothing.
   */
  function setData(key, value) {
    data[key] = value;
  }

  /**
   * Get data.
   *
   * @template {keyof CompileData} Key
   *   Field type.
   * @param {Key} key
   *   Key of field.
   * @returns {CompileData[Key]}
   *   Value.
   */
  function getData(key) {
    return data[key]
  }

  /**
   * Create an opener handle.
   *
   * @param {(token: Token) => Node} create
   *   Create a node.
   * @param {Handle} [and]
   *   Optional function to also run.
   * @returns {Handle}
   *   Handle.
   */
  function opener(create, and) {
    return open

    /**
     * @this {CompileContext}
     * @param {Token} token
     * @returns {void}
     */
    function open(token) {
      enter.call(this, create(token), token);
      if (and) and.call(this, token);
    }
  }

  /**
   * @this {CompileContext}
   * @returns {void}
   */
  function buffer() {
    this.stack.push({
      type: 'fragment',
      children: []
    });
  }

  /**
   * @template {Node} Kind
   *   Node type.
   * @this {CompileContext}
   *   Context.
   * @param {Kind} node
   *   Node to enter.
   * @param {Token} token
   *   Corresponding token.
   * @param {OnEnterError | undefined} [errorHandler]
   *   Handle the case where this token is open, but it is closed by something else.
   * @returns {Kind}
   *   The given node.
   */
  function enter(node, token, errorHandler) {
    const parent = this.stack[this.stack.length - 1];
    // @ts-expect-error: Assume `Node` can exist as a child of `parent`.
    parent.children.push(node);
    this.stack.push(node);
    this.tokenStack.push([token, errorHandler]);
    // @ts-expect-error: `end` will be patched later.
    node.position = {
      start: point$1(token.start)
    };
    return node
  }

  /**
   * Create a closer handle.
   *
   * @param {Handle} [and]
   *   Optional function to also run.
   * @returns {Handle}
   *   Handle.
   */
  function closer(and) {
    return close

    /**
     * @this {CompileContext}
     * @param {Token} token
     * @returns {void}
     */
    function close(token) {
      if (and) and.call(this, token);
      exit.call(this, token);
    }
  }

  /**
   * @this {CompileContext}
   *   Context.
   * @param {Token} token
   *   Corresponding token.
   * @param {OnExitError | undefined} [onExitError]
   *   Handle the case where another token is open.
   * @returns {Node}
   *   The closed node.
   */
  function exit(token, onExitError) {
    const node = this.stack.pop();
    const open = this.tokenStack.pop();
    if (!open) {
      throw new Error(
        'Cannot close `' +
          token.type +
          '` (' +
          stringifyPosition({
            start: token.start,
            end: token.end
          }) +
          '): it‚Äôs not open'
      )
    } else if (open[0].type !== token.type) {
      if (onExitError) {
        onExitError.call(this, token, open[0]);
      } else {
        const handler = open[1] || defaultOnError;
        handler.call(this, token, open[0]);
      }
    }
    node.position.end = point$1(token.end);
    return node
  }

  /**
   * @this {CompileContext}
   * @returns {string}
   */
  function resume() {
    return toString(this.stack.pop())
  }

  //
  // Handlers.
  //

  /**
   * @this {CompileContext}
   * @type {Handle}
   */
  function onenterlistordered() {
    setData('expectingFirstListItemValue', true);
  }

  /**
   * @this {CompileContext}
   * @type {Handle}
   */
  function onenterlistitemvalue(token) {
    if (getData('expectingFirstListItemValue')) {
      const ancestor = this.stack[this.stack.length - 2];
      ancestor.start = Number.parseInt(this.sliceSerialize(token), 10);
      setData('expectingFirstListItemValue');
    }
  }

  /**
   * @this {CompileContext}
   * @type {Handle}
   */
  function onexitcodefencedfenceinfo() {
    const data = this.resume();
    const node = this.stack[this.stack.length - 1];
    node.lang = data;
  }

  /**
   * @this {CompileContext}
   * @type {Handle}
   */
  function onexitcodefencedfencemeta() {
    const data = this.resume();
    const node = this.stack[this.stack.length - 1];
    node.meta = data;
  }

  /**
   * @this {CompileContext}
   * @type {Handle}
   */
  function onexitcodefencedfence() {
    // Exit if this is the closing fence.
    if (getData('flowCodeInside')) return
    this.buffer();
    setData('flowCodeInside', true);
  }

  /**
   * @this {CompileContext}
   * @type {Handle}
   */
  function onexitcodefenced() {
    const data = this.resume();
    const node = this.stack[this.stack.length - 1];
    node.value = data.replace(/^(\r?\n|\r)|(\r?\n|\r)$/g, '');
    setData('flowCodeInside');
  }

  /**
   * @this {CompileContext}
   * @type {Handle}
   */
  function onexitcodeindented() {
    const data = this.resume();
    const node = this.stack[this.stack.length - 1];
    node.value = data.replace(/(\r?\n|\r)$/g, '');
  }

  /**
   * @this {CompileContext}
   * @type {Handle}
   */
  function onexitdefinitionlabelstring(token) {
    const label = this.resume();
    const node = this.stack[this.stack.length - 1];
    node.label = label;
    node.identifier = normalizeIdentifier(
      this.sliceSerialize(token)
    ).toLowerCase();
  }

  /**
   * @this {CompileContext}
   * @type {Handle}
   */
  function onexitdefinitiontitlestring() {
    const data = this.resume();
    const node = this.stack[this.stack.length - 1];
    node.title = data;
  }

  /**
   * @this {CompileContext}
   * @type {Handle}
   */
  function onexitdefinitiondestinationstring() {
    const data = this.resume();
    const node = this.stack[this.stack.length - 1];
    node.url = data;
  }

  /**
   * @this {CompileContext}
   * @type {Handle}
   */
  function onexitatxheadingsequence(token) {
    const node = this.stack[this.stack.length - 1];
    if (!node.depth) {
      const depth = this.sliceSerialize(token).length;
      node.depth = depth;
    }
  }

  /**
   * @this {CompileContext}
   * @type {Handle}
   */
  function onexitsetextheadingtext() {
    setData('setextHeadingSlurpLineEnding', true);
  }

  /**
   * @this {CompileContext}
   * @type {Handle}
   */
  function onexitsetextheadinglinesequence(token) {
    const node = this.stack[this.stack.length - 1];
    node.depth = this.sliceSerialize(token).charCodeAt(0) === 61 ? 1 : 2;
  }

  /**
   * @this {CompileContext}
   * @type {Handle}
   */
  function onexitsetextheading() {
    setData('setextHeadingSlurpLineEnding');
  }

  /**
   * @this {CompileContext}
   * @type {Handle}
   */

  function onenterdata(token) {
    const node = this.stack[this.stack.length - 1];
    let tail = node.children[node.children.length - 1];
    if (!tail || tail.type !== 'text') {
      // Add a new text node.
      tail = text();
      // @ts-expect-error: we‚Äôll add `end` later.
      tail.position = {
        start: point$1(token.start)
      };
      // @ts-expect-error: Assume `parent` accepts `text`.
      node.children.push(tail);
    }
    this.stack.push(tail);
  }

  /**
   * @this {CompileContext}
   * @type {Handle}
   */

  function onexitdata(token) {
    const tail = this.stack.pop();
    tail.value += this.sliceSerialize(token);
    tail.position.end = point$1(token.end);
  }

  /**
   * @this {CompileContext}
   * @type {Handle}
   */

  function onexitlineending(token) {
    const context = this.stack[this.stack.length - 1];
    // If we‚Äôre at a hard break, include the line ending in there.
    if (getData('atHardBreak')) {
      const tail = context.children[context.children.length - 1];
      tail.position.end = point$1(token.end);
      setData('atHardBreak');
      return
    }
    if (
      !getData('setextHeadingSlurpLineEnding') &&
      config.canContainEols.includes(context.type)
    ) {
      onenterdata.call(this, token);
      onexitdata.call(this, token);
    }
  }

  /**
   * @this {CompileContext}
   * @type {Handle}
   */

  function onexithardbreak() {
    setData('atHardBreak', true);
  }

  /**
   * @this {CompileContext}
   * @type {Handle}
   */

  function onexithtmlflow() {
    const data = this.resume();
    const node = this.stack[this.stack.length - 1];
    node.value = data;
  }

  /**
   * @this {CompileContext}
   * @type {Handle}
   */

  function onexithtmltext() {
    const data = this.resume();
    const node = this.stack[this.stack.length - 1];
    node.value = data;
  }

  /**
   * @this {CompileContext}
   * @type {Handle}
   */

  function onexitcodetext() {
    const data = this.resume();
    const node = this.stack[this.stack.length - 1];
    node.value = data;
  }

  /**
   * @this {CompileContext}
   * @type {Handle}
   */

  function onexitlink() {
    const node = this.stack[this.stack.length - 1];
    // Note: there are also `identifier` and `label` fields on this link node!
    // These are used / cleaned here.

    // To do: clean.
    if (getData('inReference')) {
      /** @type {ReferenceType} */
      const referenceType = getData('referenceType') || 'shortcut';
      node.type += 'Reference';
      // @ts-expect-error: mutate.
      node.referenceType = referenceType;
      // @ts-expect-error: mutate.
      delete node.url;
      delete node.title;
    } else {
      // @ts-expect-error: mutate.
      delete node.identifier;
      // @ts-expect-error: mutate.
      delete node.label;
    }
    setData('referenceType');
  }

  /**
   * @this {CompileContext}
   * @type {Handle}
   */

  function onexitimage() {
    const node = this.stack[this.stack.length - 1];
    // Note: there are also `identifier` and `label` fields on this link node!
    // These are used / cleaned here.

    // To do: clean.
    if (getData('inReference')) {
      /** @type {ReferenceType} */
      const referenceType = getData('referenceType') || 'shortcut';
      node.type += 'Reference';
      // @ts-expect-error: mutate.
      node.referenceType = referenceType;
      // @ts-expect-error: mutate.
      delete node.url;
      delete node.title;
    } else {
      // @ts-expect-error: mutate.
      delete node.identifier;
      // @ts-expect-error: mutate.
      delete node.label;
    }
    setData('referenceType');
  }

  /**
   * @this {CompileContext}
   * @type {Handle}
   */

  function onexitlabeltext(token) {
    const string = this.sliceSerialize(token);
    const ancestor = this.stack[this.stack.length - 2];
    // @ts-expect-error: stash this on the node, as it might become a reference
    // later.
    ancestor.label = decodeString(string);
    // @ts-expect-error: same as above.
    ancestor.identifier = normalizeIdentifier(string).toLowerCase();
  }

  /**
   * @this {CompileContext}
   * @type {Handle}
   */

  function onexitlabel() {
    const fragment = this.stack[this.stack.length - 1];
    const value = this.resume();
    const node = this.stack[this.stack.length - 1];
    // Assume a reference.
    setData('inReference', true);
    if (node.type === 'link') {
      /** @type {Array<StaticPhrasingContent>} */
      // @ts-expect-error: Assume static phrasing content.
      const children = fragment.children;
      node.children = children;
    } else {
      node.alt = value;
    }
  }

  /**
   * @this {CompileContext}
   * @type {Handle}
   */

  function onexitresourcedestinationstring() {
    const data = this.resume();
    const node = this.stack[this.stack.length - 1];
    node.url = data;
  }

  /**
   * @this {CompileContext}
   * @type {Handle}
   */

  function onexitresourcetitlestring() {
    const data = this.resume();
    const node = this.stack[this.stack.length - 1];
    node.title = data;
  }

  /**
   * @this {CompileContext}
   * @type {Handle}
   */

  function onexitresource() {
    setData('inReference');
  }

  /**
   * @this {CompileContext}
   * @type {Handle}
   */

  function onenterreference() {
    setData('referenceType', 'collapsed');
  }

  /**
   * @this {CompileContext}
   * @type {Handle}
   */

  function onexitreferencestring(token) {
    const label = this.resume();
    const node = this.stack[this.stack.length - 1];
    // @ts-expect-error: stash this on the node, as it might become a reference
    // later.
    node.label = label;
    // @ts-expect-error: same as above.
    node.identifier = normalizeIdentifier(
      this.sliceSerialize(token)
    ).toLowerCase();
    setData('referenceType', 'full');
  }

  /**
   * @this {CompileContext}
   * @type {Handle}
   */

  function onexitcharacterreferencemarker(token) {
    setData('characterReferenceType', token.type);
  }

  /**
   * @this {CompileContext}
   * @type {Handle}
   */
  function onexitcharacterreferencevalue(token) {
    const data = this.sliceSerialize(token);
    const type = getData('characterReferenceType');
    /** @type {string} */
    let value;
    if (type) {
      value = decodeNumericCharacterReference(
        data,
        type === 'characterReferenceMarkerNumeric' ? 10 : 16
      );
      setData('characterReferenceType');
    } else {
      const result = decodeNamedCharacterReference(data);
      value = result;
    }
    const tail = this.stack.pop();
    tail.value += value;
    tail.position.end = point$1(token.end);
  }

  /**
   * @this {CompileContext}
   * @type {Handle}
   */
  function onexitautolinkprotocol(token) {
    onexitdata.call(this, token);
    const node = this.stack[this.stack.length - 1];
    node.url = this.sliceSerialize(token);
  }

  /**
   * @this {CompileContext}
   * @type {Handle}
   */
  function onexitautolinkemail(token) {
    onexitdata.call(this, token);
    const node = this.stack[this.stack.length - 1];
    node.url = 'mailto:' + this.sliceSerialize(token);
  }

  //
  // Creaters.
  //

  /** @returns {Blockquote} */
  function blockQuote() {
    return {
      type: 'blockquote',
      children: []
    }
  }

  /** @returns {Code} */
  function codeFlow() {
    return {
      type: 'code',
      lang: null,
      meta: null,
      value: ''
    }
  }

  /** @returns {InlineCode} */
  function codeText() {
    return {
      type: 'inlineCode',
      value: ''
    }
  }

  /** @returns {Definition} */
  function definition() {
    return {
      type: 'definition',
      identifier: '',
      label: null,
      title: null,
      url: ''
    }
  }

  /** @returns {Emphasis} */
  function emphasis() {
    return {
      type: 'emphasis',
      children: []
    }
  }

  /** @returns {Heading} */
  function heading() {
    // @ts-expect-error `depth` will be set later.
    return {
      type: 'heading',
      depth: undefined,
      children: []
    }
  }

  /** @returns {Break} */
  function hardBreak() {
    return {
      type: 'break'
    }
  }

  /** @returns {HTML} */
  function html() {
    return {
      type: 'html',
      value: ''
    }
  }

  /** @returns {Image} */
  function image() {
    return {
      type: 'image',
      title: null,
      url: '',
      alt: null
    }
  }

  /** @returns {Link} */
  function link() {
    return {
      type: 'link',
      title: null,
      url: '',
      children: []
    }
  }

  /**
   * @param {Token} token
   * @returns {List}
   */
  function list(token) {
    return {
      type: 'list',
      ordered: token.type === 'listOrdered',
      start: null,
      // @ts-expect-error Patched.
      spread: token._spread,
      children: []
    }
  }

  /**
   * @param {Token} token
   * @returns {ListItem}
   */
  function listItem(token) {
    return {
      type: 'listItem',
      // @ts-expect-error Patched.
      spread: token._spread,
      checked: null,
      children: []
    }
  }

  /** @returns {Paragraph} */
  function paragraph() {
    return {
      type: 'paragraph',
      children: []
    }
  }

  /** @returns {Strong} */
  function strong() {
    return {
      type: 'strong',
      children: []
    }
  }

  /** @returns {Text} */
  function text() {
    return {
      type: 'text',
      value: ''
    }
  }

  /** @returns {ThematicBreak} */
  function thematicBreak() {
    return {
      type: 'thematicBreak'
    }
  }
}

/**
 * Copy a point-like value.
 *
 * @param {Point} d
 *   Point-like value.
 * @returns {Point}
 *   unist point.
 */
function point$1(d) {
  return {
    line: d.line,
    column: d.column,
    offset: d.offset
  }
}

/**
 * @param {Config} combined
 * @param {Array<Extension | Array<Extension>>} extensions
 * @returns {void}
 */
function configure(combined, extensions) {
  let index = -1;
  while (++index < extensions.length) {
    const value = extensions[index];
    if (Array.isArray(value)) {
      configure(combined, value);
    } else {
      extension(combined, value);
    }
  }
}

/**
 * @param {Config} combined
 * @param {Extension} extension
 * @returns {void}
 */
function extension(combined, extension) {
  /** @type {keyof Extension} */
  let key;
  for (key in extension) {
    if (own$5.call(extension, key)) {
      if (key === 'canContainEols') {
        const right = extension[key];
        if (right) {
          combined[key].push(...right);
        }
      } else if (key === 'transforms') {
        const right = extension[key];
        if (right) {
          combined[key].push(...right);
        }
      } else if (key === 'enter' || key === 'exit') {
        const right = extension[key];
        if (right) {
          Object.assign(combined[key], right);
        }
      }
    }
  }
}

/** @type {OnEnterError} */
function defaultOnError(left, right) {
  if (left) {
    throw new Error(
      'Cannot close `' +
        left.type +
        '` (' +
        stringifyPosition({
          start: left.start,
          end: left.end
        }) +
        '): a different token (`' +
        right.type +
        '`, ' +
        stringifyPosition({
          start: right.start,
          end: right.end
        }) +
        ') is open'
    )
  } else {
    throw new Error(
      'Cannot close document, a token (`' +
        right.type +
        '`, ' +
        stringifyPosition({
          start: right.start,
          end: right.end
        }) +
        ') is still open'
    )
  }
}

/**
 * @typedef {import('mdast').Root} Root
 * @typedef {import('mdast-util-from-markdown').Options} Options
 */

/** @type {import('unified').Plugin<[Options?] | void[], string, Root>} */
function remarkParse(options) {
  /** @type {import('unified').ParserFunction<Root>} */
  const parser = (doc) => {
    // Assume options.
    const settings = /** @type {Options} */ (this.data('settings'));

    return fromMarkdown(
      doc,
      Object.assign({}, settings, options, {
        // Note: these options are not in the readme.
        // The goal is for them to be set by plugins on `data` instead of being
        // passed by users.
        extensions: this.data('micromarkExtensions') || [],
        mdastExtensions: this.data('fromMarkdownExtensions') || []
      })
    )
  };

  Object.assign(this, {Parser: parser});
}

/**
 * @typedef {import('unist').Node} Node
 * @typedef {import('unist').Parent} Parent
 */

/**
 * Generate an assertion from a test.
 *
 * Useful if you‚Äôre going to test many nodes, for example when creating a
 * utility where something else passes a compatible test.
 *
 * The created function is a bit faster because it expects valid input only:
 * a `node`, `index`, and `parent`.
 *
 * @param test
 *   *   when nullish, checks if `node` is a `Node`.
 *   *   when `string`, works like passing `(node) => node.type === test`.
 *   *   when `function` checks if function passed the node is true.
 *   *   when `object`, checks that all keys in test are in node, and that they have (strictly) equal values.
 *   *   when `array`, checks if any one of the subtests pass.
 * @returns
 *   An assertion.
 */
const convert =
  /**
   * @type {(
   *   (<Kind extends Node>(test: PredicateTest<Kind>) => AssertPredicate<Kind>) &
   *   ((test?: Test) => AssertAnything)
   * )}
   */
  (
    /**
     * @param {Test} [test]
     * @returns {AssertAnything}
     */
    function (test) {
      if (test === undefined || test === null) {
        return ok
      }

      if (typeof test === 'string') {
        return typeFactory(test)
      }

      if (typeof test === 'object') {
        return Array.isArray(test) ? anyFactory(test) : propsFactory(test)
      }

      if (typeof test === 'function') {
        return castFactory(test)
      }

      throw new Error('Expected function, string, or object as test')
    }
  );

/**
 * @param {Array<string | Props | TestFunctionAnything>} tests
 * @returns {AssertAnything}
 */
function anyFactory(tests) {
  /** @type {Array<AssertAnything>} */
  const checks = [];
  let index = -1;

  while (++index < tests.length) {
    checks[index] = convert(tests[index]);
  }

  return castFactory(any)

  /**
   * @this {unknown}
   * @param {Array<unknown>} parameters
   * @returns {boolean}
   */
  function any(...parameters) {
    let index = -1;

    while (++index < checks.length) {
      if (checks[index].call(this, ...parameters)) return true
    }

    return false
  }
}

/**
 * Turn an object into a test for a node with a certain fields.
 *
 * @param {Props} check
 * @returns {AssertAnything}
 */
function propsFactory(check) {
  return castFactory(all)

  /**
   * @param {Node} node
   * @returns {boolean}
   */
  function all(node) {
    /** @type {string} */
    let key;

    for (key in check) {
      // @ts-expect-error: hush, it sure works as an index.
      if (node[key] !== check[key]) return false
    }

    return true
  }
}

/**
 * Turn a string into a test for a node with a certain type.
 *
 * @param {string} check
 * @returns {AssertAnything}
 */
function typeFactory(check) {
  return castFactory(type)

  /**
   * @param {Node} node
   */
  function type(node) {
    return node && node.type === check
  }
}

/**
 * Turn a custom test into a test for a node that passes that test.
 *
 * @param {TestFunctionAnything} check
 * @returns {AssertAnything}
 */
function castFactory(check) {
  return assertion

  /**
   * @this {unknown}
   * @param {unknown} node
   * @param {Array<unknown>} parameters
   * @returns {boolean}
   */
  function assertion(node, ...parameters) {
    return Boolean(
      node &&
        typeof node === 'object' &&
        'type' in node &&
        // @ts-expect-error: fine.
        Boolean(check.call(this, node, ...parameters))
    )
  }
}

function ok() {
  return true
}

/**
 * @param {string} d
 * @returns {string}
 */
function color(d) {
  return '\u001B[33m' + d + '\u001B[39m'
}

/**
 * @typedef {import('unist').Node} Node
 * @typedef {import('unist').Parent} Parent
 * @typedef {import('unist-util-is').Test} Test
 */

/**
 * Continue traversing as normal.
 */
const CONTINUE = true;

/**
 * Stop traversing immediately.
 */
const EXIT = false;

/**
 * Do not traverse this node‚Äôs children.
 */
const SKIP = 'skip';

/**
 * Visit nodes, with ancestral information.
 *
 * This algorithm performs *depth-first* *tree traversal* in *preorder*
 * (**NLR**) or if `reverse` is given, in *reverse preorder* (**NRL**).
 *
 * You can choose for which nodes `visitor` is called by passing a `test`.
 * For complex tests, you should test yourself in `visitor`, as it will be
 * faster and will have improved type information.
 *
 * Walking the tree is an intensive task.
 * Make use of the return values of the visitor when possible.
 * Instead of walking a tree multiple times, walk it once, use `unist-util-is`
 * to check if a node matches, and then perform different operations.
 *
 * You can change the tree.
 * See `Visitor` for more info.
 *
 * @param tree
 *   Tree to traverse.
 * @param test
 *   `unist-util-is`-compatible test
 * @param visitor
 *   Handle each node.
 * @param reverse
 *   Traverse in reverse preorder (NRL) instead of the default preorder (NLR).
 * @returns
 *   Nothing.
 */
const visitParents =
  /**
   * @type {(
   *   (<Tree extends Node, Check extends Test>(tree: Tree, test: Check, visitor: BuildVisitor<Tree, Check>, reverse?: boolean | null | undefined) => void) &
   *   (<Tree extends Node>(tree: Tree, visitor: BuildVisitor<Tree>, reverse?: boolean | null | undefined) => void)
   * )}
   */
  (
    /**
     * @param {Node} tree
     * @param {Test} test
     * @param {Visitor<Node>} visitor
     * @param {boolean | null | undefined} [reverse]
     * @returns {void}
     */
    function (tree, test, visitor, reverse) {
      if (typeof test === 'function' && typeof visitor !== 'function') {
        reverse = visitor;
        // @ts-expect-error no visitor given, so `visitor` is test.
        visitor = test;
        test = null;
      }

      const is = convert(test);
      const step = reverse ? -1 : 1;

      factory(tree, undefined, [])();

      /**
       * @param {Node} node
       * @param {number | undefined} index
       * @param {Array<Parent>} parents
       */
      function factory(node, index, parents) {
        /** @type {Record<string, unknown>} */
        // @ts-expect-error: hush
        const value = node && typeof node === 'object' ? node : {};

        if (typeof value.type === 'string') {
          const name =
            // `hast`
            typeof value.tagName === 'string'
              ? value.tagName
              : // `xast`
              typeof value.name === 'string'
              ? value.name
              : undefined;

          Object.defineProperty(visit, 'name', {
            value:
              'node (' + color(node.type + (name ? '<' + name + '>' : '')) + ')'
          });
        }

        return visit

        function visit() {
          /** @type {ActionTuple} */
          let result = [];
          /** @type {ActionTuple} */
          let subresult;
          /** @type {number} */
          let offset;
          /** @type {Array<Parent>} */
          let grandparents;

          if (!test || is(node, index, parents[parents.length - 1] || null)) {
            result = toResult(visitor(node, parents));

            if (result[0] === EXIT) {
              return result
            }
          }

          // @ts-expect-error looks like a parent.
          if (node.children && result[0] !== SKIP) {
            // @ts-expect-error looks like a parent.
            offset = (reverse ? node.children.length : -1) + step;
            // @ts-expect-error looks like a parent.
            grandparents = parents.concat(node);

            // @ts-expect-error looks like a parent.
            while (offset > -1 && offset < node.children.length) {
              // @ts-expect-error looks like a parent.
              subresult = factory(node.children[offset], offset, grandparents)();

              if (subresult[0] === EXIT) {
                return subresult
              }

              offset =
                typeof subresult[1] === 'number' ? subresult[1] : offset + step;
            }
          }

          return result
        }
      }
    }
  );

/**
 * Turn a return value into a clean result.
 *
 * @param {VisitorResult} value
 *   Valid return values from visitors.
 * @returns {ActionTuple}
 *   Clean result.
 */
function toResult(value) {
  if (Array.isArray(value)) {
    return value
  }

  if (typeof value === 'number') {
    return [CONTINUE, value]
  }

  return [value]
}

/**
 * @typedef {import('unist').Node} Node
 * @typedef {import('unist').Parent} Parent
 * @typedef {import('unist-util-is').Test} Test
 * @typedef {import('unist-util-visit-parents').VisitorResult} VisitorResult
 */

/**
 * Visit nodes.
 *
 * This algorithm performs *depth-first* *tree traversal* in *preorder*
 * (**NLR**) or if `reverse` is given, in *reverse preorder* (**NRL**).
 *
 * You can choose for which nodes `visitor` is called by passing a `test`.
 * For complex tests, you should test yourself in `visitor`, as it will be
 * faster and will have improved type information.
 *
 * Walking the tree is an intensive task.
 * Make use of the return values of the visitor when possible.
 * Instead of walking a tree multiple times, walk it once, use `unist-util-is`
 * to check if a node matches, and then perform different operations.
 *
 * You can change the tree.
 * See `Visitor` for more info.
 *
 * @param tree
 *   Tree to traverse.
 * @param test
 *   `unist-util-is`-compatible test
 * @param visitor
 *   Handle each node.
 * @param reverse
 *   Traverse in reverse preorder (NRL) instead of the default preorder (NLR).
 * @returns
 *   Nothing.
 */
const visit =
  /**
   * @type {(
   *   (<Tree extends Node, Check extends Test>(tree: Tree, test: Check, visitor: BuildVisitor<Tree, Check>, reverse?: boolean | null | undefined) => void) &
   *   (<Tree extends Node>(tree: Tree, visitor: BuildVisitor<Tree>, reverse?: boolean | null | undefined) => void)
   * )}
   */
  (
    /**
     * @param {Node} tree
     * @param {Test} test
     * @param {Visitor} visitor
     * @param {boolean | null | undefined} [reverse]
     * @returns {void}
     */
    function (tree, test, visitor, reverse) {
      if (typeof test === 'function' && typeof visitor !== 'function') {
        reverse = visitor;
        visitor = test;
        test = null;
      }

      visitParents(tree, test, overload, reverse);

      /**
       * @param {Node} node
       * @param {Array<Parent>} parents
       */
      function overload(node, parents) {
        const parent = parents[parents.length - 1];
        return visitor(
          node,
          parent ? parent.children.indexOf(node) : null,
          parent
        )
      }
    }
  );

/**
 * @typedef {import('mdast').Root} Root
 * @typedef {import('mdast').PhrasingContent} PhrasingContent
 */

const find$1 = /[\t ]*(?:\r?\n|\r)/g;

/**
 * Plugin to support hard breaks without needing spaces or escapes (turns enters
 * into `<br>`s).
 *
 * @type {import('unified').Plugin<void[], Root>}
 */
function remarkBreaks() {
  return (tree) => {
    visit(tree, 'text', (node, index, parent) => {
      /** @type {PhrasingContent[]} */
      const result = [];
      let start = 0;

      find$1.lastIndex = 0;

      let match = find$1.exec(node.value);

      while (match) {
        const position = match.index;

        if (start !== position) {
          result.push({type: 'text', value: node.value.slice(start, position)});
        }

        result.push({type: 'break'});
        start = position + match[0].length;
        match = find$1.exec(node.value);
      }

      if (result.length > 0 && parent && typeof index === 'number') {
        if (start < node.value.length) {
          result.push({type: 'text', value: node.value.slice(start)});
        }

        parent.children.splice(index, 1, ...result);
        return index + result.length
      }
    });
  }
}

var formatExports = {};
var format = {
  get exports(){ return formatExports; },
  set exports(v){ formatExports = v; },
};

(function (module) {
(function() {

	  //// Export the API
	  var namespace;

	  // CommonJS / Node module
	  {
	    namespace = module.exports = format;
	  }

	  namespace.format = format;
	  namespace.vsprintf = vsprintf;

	  if (typeof console !== 'undefined' && typeof console.log === 'function') {
	    namespace.printf = printf;
	  }

	  function printf(/* ... */) {
	    console.log(format.apply(null, arguments));
	  }

	  function vsprintf(fmt, replacements) {
	    return format.apply(null, [fmt].concat(replacements));
	  }

	  function format(fmt) {
	    var argIndex = 1 // skip initial format argument
	      , args = [].slice.call(arguments)
	      , i = 0
	      , n = fmt.length
	      , result = ''
	      , c
	      , escaped = false
	      , arg
	      , tmp
	      , leadingZero = false
	      , precision
	      , nextArg = function() { return args[argIndex++]; }
	      , slurpNumber = function() {
	          var digits = '';
	          while (/\d/.test(fmt[i])) {
	            digits += fmt[i++];
	            c = fmt[i];
	          }
	          return digits.length > 0 ? parseInt(digits) : null;
	        }
	      ;
	    for (; i < n; ++i) {
	      c = fmt[i];
	      if (escaped) {
	        escaped = false;
	        if (c == '.') {
	          leadingZero = false;
	          c = fmt[++i];
	        }
	        else if (c == '0' && fmt[i + 1] == '.') {
	          leadingZero = true;
	          i += 2;
	          c = fmt[i];
	        }
	        else {
	          leadingZero = true;
	        }
	        precision = slurpNumber();
	        switch (c) {
	        case 'b': // number in binary
	          result += parseInt(nextArg(), 10).toString(2);
	          break;
	        case 'c': // character
	          arg = nextArg();
	          if (typeof arg === 'string' || arg instanceof String)
	            result += arg;
	          else
	            result += String.fromCharCode(parseInt(arg, 10));
	          break;
	        case 'd': // number in decimal
	          result += parseInt(nextArg(), 10);
	          break;
	        case 'f': // floating point number
	          tmp = String(parseFloat(nextArg()).toFixed(precision || 6));
	          result += leadingZero ? tmp : tmp.replace(/^0/, '');
	          break;
	        case 'j': // JSON
	          result += JSON.stringify(nextArg());
	          break;
	        case 'o': // number in octal
	          result += '0' + parseInt(nextArg(), 10).toString(8);
	          break;
	        case 's': // string
	          result += nextArg();
	          break;
	        case 'x': // lowercase hexadecimal
	          result += '0x' + parseInt(nextArg(), 10).toString(16);
	          break;
	        case 'X': // uppercase hexadecimal
	          result += '0x' + parseInt(nextArg(), 10).toString(16).toUpperCase();
	          break;
	        default:
	          result += c;
	          break;
	        }
	      } else if (c === '%') {
	        escaped = true;
	      } else {
	        result += c;
	      }
	    }
	    return result;
	  }

	}());
} (format));

var formatter = formatExports;

// @ts-expect-error

const fault = Object.assign(create(Error), {
  eval: create(EvalError),
  range: create(RangeError),
  reference: create(ReferenceError),
  syntax: create(SyntaxError),
  type: create(TypeError),
  uri: create(URIError)
});

/**
 * Create a new `EConstructor`, with the formatted `format` as a first argument.
 *
 * @template {Error} Fault
 * @template {new (reason: string) => Fault} Class
 * @param {Class} Constructor
 */
function create(Constructor) {
  /** @type {string} */
  // @ts-expect-error
  FormattedError.displayName = Constructor.displayName || Constructor.name;

  return FormattedError

  /**
   * Create an error with a printf-like formatted message.
   *
   * @param {string|null} [format]
   *   Template string.
   * @param {...unknown} values
   *   Values to render in `format`.
   * @returns {Fault}
   */
  function FormattedError(format, ...values) {
    /** @type {string} */
    const reason = format ? formatter(format, ...values) : format;
    return new Constructor(reason)
  }
}

/**
 * @typedef {'yaml'|'toml'} Preset
 *   Either `'yaml'` or `'toml'`.
 *
 * @typedef Info
 * @property {string} open
 * @property {string} close
 *
 * @typedef MatterProps
 * @property {string} type
 *   Type to tokenize as.
 * @property {boolean} [anywhere=false]
 *   If `true`, matter can be found anywhere in the document.
 *   If `false` (default), only matter at the start of the document is
 *   recognized.
 *
 * @typedef MarkerProps
 *   Marker configuration.
 * @property {string|Info} marker
 *   Character used to construct fences.
 *   By providing an object with `open` and `close` different characters can be
 *   used for opening and closing fences.
 *   For example the character `'-'` will result in `'---'` being used as the
 *   fence
 * @property {never} [fence]
 *   If `marker` is set, `fence` must not be set.
 *
 * @typedef FenceProps
 *   Fence configuration.
 * @property {string|Info} fence
 *   String used as the complete fence.
 *   By providing an object with `open` and `close` different values can be used
 *   for opening and closing fences.
 *   This can be used too if fences contain different characters or lengths
 *   other than 3.
 * @property {never} [marker]
 *   If `fence` is set, `marker` must not be set.
 *
 * @typedef {(MatterProps & FenceProps)|(MatterProps & MarkerProps)} Matter
 *   Matter object describing frontmatter.
 *
 * @typedef {Preset|Matter|Array<Preset|Matter>} Options
 *   Matter object or preset, or many.
 */
const own$4 = {}.hasOwnProperty;
const markers = {
  yaml: '-',
  toml: '+'
};

/**
 * @param {Options} [options='yaml']
 * @returns {Array<Matter>}
 */
function matters(options = 'yaml') {
  /** @type {Array<Matter>} */
  const results = [];
  let index = -1;

  // One preset or matter.
  if (!Array.isArray(options)) {
    options = [options];
  }
  while (++index < options.length) {
    results[index] = matter(options[index]);
  }
  return results
}

/**
 * @param {Preset|Matter} option
 * @returns {Matter}
 */
function matter(option) {
  let result = option;
  if (typeof result === 'string') {
    if (!own$4.call(markers, result)) {
      throw fault('Missing matter definition for `%s`', result)
    }
    result = {
      type: result,
      marker: markers[result]
    };
  } else if (typeof result !== 'object') {
    throw fault('Expected matter to be an object, not `%j`', result)
  }
  if (!own$4.call(result, 'type')) {
    throw fault('Missing `type` in matter `%j`', result)
  }
  if (!own$4.call(result, 'fence') && !own$4.call(result, 'marker')) {
    throw fault('Missing `marker` or `fence` in matter `%j`', result)
  }
  return result
}

/**
 * @typedef {import('micromark-util-types').Extension} Extension
 * @typedef {import('micromark-util-types').ConstructRecord} ConstructRecord
 * @typedef {import('micromark-util-types').Construct} Construct
 * @typedef {import('micromark-util-types').Tokenizer} Tokenizer
 * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext
 * @typedef {import('micromark-util-types').State} State
 * @typedef {import('../matters.js').Options} Options
 * @typedef {import('../matters.js').Matter} Matter
 * @typedef {import('../matters.js').Info} Info
 */

/**
 * Add support for parsing frontmatter in markdown.
 *
 * Function that can be called to get a syntax extension for micromark (passed
 * in `extensions`).
 *
 * Supports YAML by default.
 * Can be configured to support TOML and more.
 *
 * @param {Options} [options='yaml']
 *   Configuration (optional).
 * @returns {Extension}
 *   Syntax extension for micromark (passed in `extensions`).
 */
function frontmatter(options) {
  const settings = matters(options);
  /** @type {ConstructRecord} */
  const flow = {};
  let index = -1;
  while (++index < settings.length) {
    const matter = settings[index];
    const code = fence$1(matter, 'open').charCodeAt(0);
    if (code in flow) {
      // @ts-expect-error it clearly does exist.
      flow[code].push(parse(matter));
    } else {
      flow[code] = [parse(matter)];
    }
  }
  return {
    flow
  }
}

/**
 * @param {Matter} matter
 * @returns {Construct}
 */
function parse(matter) {
  const name = matter.type;
  const anywhere = matter.anywhere;
  const valueType = name + 'Value';
  const fenceType = name + 'Fence';
  const sequenceType = fenceType + 'Sequence';
  const fenceConstruct = {
    tokenize: tokenizeFence,
    partial: true
  };
  /** @type {string} */
  let buffer;
  return {
    tokenize: tokenizeFrontmatter,
    concrete: true
  }

  /**
   * @this {TokenizeContext}
   * @type {Tokenizer}
   */
  function tokenizeFrontmatter(effects, ok, nok) {
    const self = this;
    return start

    /** @type {State} */
    function start(code) {
      const position = self.now();
      if (position.column !== 1 || (!anywhere && position.line !== 1)) {
        return nok(code)
      }
      effects.enter(name);
      buffer = fence$1(matter, 'open');
      return effects.attempt(fenceConstruct, afterOpeningFence, nok)(code)
    }

    /** @type {State} */
    function afterOpeningFence(code) {
      buffer = fence$1(matter, 'close');
      return lineEnd(code)
    }

    /** @type {State} */
    function lineStart(code) {
      if (code === null || markdownLineEnding(code)) {
        return lineEnd(code)
      }
      effects.enter(valueType);
      return lineData(code)
    }

    /** @type {State} */
    function lineData(code) {
      if (code === null || markdownLineEnding(code)) {
        effects.exit(valueType);
        return lineEnd(code)
      }
      effects.consume(code);
      return lineData
    }

    /** @type {State} */
    function lineEnd(code) {
      // Require a closing fence.
      if (code === null) {
        return nok(code)
      }

      // Can only be an eol.
      effects.enter('lineEnding');
      effects.consume(code);
      effects.exit('lineEnding');
      return effects.attempt(fenceConstruct, after, lineStart)
    }

    /** @type {State} */
    function after(code) {
      effects.exit(name);
      return ok(code)
    }
  }

  /** @type {Tokenizer} */
  function tokenizeFence(effects, ok, nok) {
    let bufferIndex = 0;
    return start

    /** @type {State} */
    function start(code) {
      if (code === buffer.charCodeAt(bufferIndex)) {
        effects.enter(fenceType);
        effects.enter(sequenceType);
        return insideSequence(code)
      }
      return nok(code)
    }

    /** @type {State} */
    function insideSequence(code) {
      if (bufferIndex === buffer.length) {
        effects.exit(sequenceType);
        if (markdownSpace(code)) {
          effects.enter('whitespace');
          return insideWhitespace(code)
        }
        return fenceEnd(code)
      }
      if (code === buffer.charCodeAt(bufferIndex++)) {
        effects.consume(code);
        return insideSequence
      }
      return nok(code)
    }

    /** @type {State} */
    function insideWhitespace(code) {
      if (markdownSpace(code)) {
        effects.consume(code);
        return insideWhitespace
      }
      effects.exit('whitespace');
      return fenceEnd(code)
    }

    /** @type {State} */
    function fenceEnd(code) {
      if (code === null || markdownLineEnding(code)) {
        effects.exit(fenceType);
        return ok(code)
      }
      return nok(code)
    }
  }
}

/**
 * @param {Matter} matter
 * @param {'open'|'close'} prop
 * @returns {string}
 */
function fence$1(matter, prop) {
  return matter.marker
    ? pick$1(matter.marker, prop).repeat(3)
    : // @ts-expect-error: They‚Äôre mutually exclusive.
      pick$1(matter.fence, prop)
}

/**
 * @param {Info|string} schema
 * @param {'open'|'close'} prop
 * @returns {string}
 */
function pick$1(schema, prop) {
  return typeof schema === 'string' ? schema : schema[prop]
}

/**
 * @typedef {import('mdast').Literal} Literal
 * @typedef {import('mdast-util-from-markdown').Extension} FromMarkdownExtension
 * @typedef {import('mdast-util-from-markdown').CompileContext} CompileContext
 * @typedef {import('mdast-util-from-markdown').Handle} FromMarkdownHandle
 * @typedef {import('mdast-util-to-markdown').Options} ToMarkdownExtension
 *
 * @typedef {import('micromark-extension-frontmatter').Options} Options
 * @typedef {import('micromark-extension-frontmatter/matters.js').Matter} Matter
 * @typedef {import('micromark-extension-frontmatter/matters.js').Info} Info
 */

/**
 * Create an extension for `mdast-util-from-markdown`.
 *
 * @param {Options | null | undefined} [options]
 *   Configuration.
 * @returns {FromMarkdownExtension}
 *   Extension for `mdast-util-from-markdown`.
 */
function frontmatterFromMarkdown(options) {
  // @ts-expect-error: `micromark-extension-frontmatter` should fix types to
  // accept `null` as options.
  const settings = matters(options);
  /** @type {FromMarkdownExtension['enter']} */
  const enter = {};
  /** @type {FromMarkdownExtension['exit']} */
  const exit = {};
  let index = -1;

  while (++index < settings.length) {
    const matter = settings[index];
    enter[matter.type] = opener(matter);
    exit[matter.type] = close;
    exit[matter.type + 'Value'] = value;
  }

  return {enter, exit}
}

/**
 * @param {Matter} matter
 * @returns {FromMarkdownHandle} enter
 */
function opener(matter) {
  return open

  /**
   * @this {CompileContext}
   * @type {FromMarkdownHandle}
   */
  function open(token) {
    // @ts-expect-error: custom.
    this.enter({type: matter.type, value: ''}, token);
    this.buffer();
  }
}

/**
 * @this {CompileContext}
 * @type {FromMarkdownHandle}
 */
function close(token) {
  const data = this.resume();
  const node = /** @type {Literal} */ (this.exit(token));
  // Remove the initial and final eol.
  node.value = data.replace(/^(\r?\n|\r)|(\r?\n|\r)$/g, '');
}

/**
 * @this {CompileContext}
 * @type {FromMarkdownHandle}
 */
function value(token) {
  this.config.enter.data.call(this, token);
  this.config.exit.data.call(this, token);
}

/**
 * Create an extension for `mdast-util-to-markdown`.
 *
 * @param {Options | null | undefined} [options]
 *   Configuration.
 * @returns {ToMarkdownExtension}
 *   Extension for `mdast-util-to-markdown`.
 */
function frontmatterToMarkdown(options) {
  // To do: use an extension object with `satisfies` later.
  /** @type {ToMarkdownExtension['unsafe']} */
  const unsafe = [];
  /** @type {ToMarkdownExtension['handlers']} */
  const handlers = {};
  // @ts-expect-error: `micromark-extension-frontmatter` should fix types to
  // accept `null` as options.
  const settings = matters(options);
  let index = -1;

  while (++index < settings.length) {
    const matter = settings[index];

    // @ts-expect-error: this can add custom frontmatter nodes.
    // Typing those is the responsibility of the end user.
    handlers[matter.type] = handler(matter);

    // To do: idea: perhaps make this smarter, with an `after` of the second char?
    unsafe.push({atBreak: true, character: fence(matter, 'open').charAt(0)});
  }

  return {unsafe, handlers}
}

/**
 * Create a handle that can serialize a frontmatter node as markdown.
 *
 * @param {Matter} matter
 *   Structure.
 * @returns {(node: Literal) => string} enter
 *   Handler.
 */
function handler(matter) {
  const open = fence(matter, 'open');
  const close = fence(matter, 'close');

  return handle

  /**
   * Serialize a frontmatter node as markdown.
   *
   * @param {Literal} node
   *   Node to serialize.
   * @returns {string}
   *   Serialized node.
   */
  function handle(node) {
    return open + (node.value ? '\n' + node.value : '') + '\n' + close
  }
}

/**
 * Get an `open` or `close` fence.
 *
 * @param {Matter} matter
 *   Structure.
 * @param {'open' | 'close'} prop
 *   Field to get.
 * @returns {string}
 *   Fence.
 */
function fence(matter, prop) {
  return matter.marker
    ? pick(matter.marker, prop).repeat(3)
    : // @ts-expect-error: They‚Äôre mutually exclusive.
      pick(matter.fence, prop)
}

/**
 * Take `open` or `close` fields when schema is an info object, or use the
 * given value when it is a string.
 *
 * @param {Info | string} schema
 *   Info object or value.
 * @param {'open' | 'close'} prop
 *   Field to get.
 * @returns {string}
 *   Thing to use for the opening or closing.
 */
function pick(schema, prop) {
  return typeof schema === 'string' ? schema : schema[prop]
}

/**
 * @typedef {import('mdast').Root} Root
 * @typedef {import('micromark-extension-frontmatter').Options} Options
 */

/**
 * Plugin to add support for frontmatter.
 *
 * @type {import('unified').Plugin<[Options?]|void[], Root>}
 */
function remarkFrontmatter(options = 'yaml') {
  const data = this.data();

  add('micromarkExtensions', frontmatter(options));
  add('fromMarkdownExtensions', frontmatterFromMarkdown(options));
  add('toMarkdownExtensions', frontmatterToMarkdown(options));

  /**
   * @param {string} field
   * @param {unknown} value
   */
  function add(field, value) {
    const list = /** @type {unknown[]} */ (
      // Other extensions
      /* c8 ignore next 2 */
      data[field] ? data[field] : (data[field] = [])
    );

    list.push(value);
  }
}

/**
 * @typedef Gemoji
 * @property {string} emoji
 *   Example: `'üòÄ'`.
 * @property {Array<string>} names
 *   Example: `['grinning']`.
 * @property {Array<string>} tags
 *   Example: `['smile', 'happy']`.
 * @property {string} description
 *   Example: `'grinning face'`.
 * @property {string} category
 *   Example: `'Smileys & Emotion'`.
 */

/**
 * Map of names to emoji.
 *
 * @type {Record<string, string>}
 */
const nameToEmoji = {
  100: 'üíØ',
  1234: 'üî¢',
  grinning: 'üòÄ',
  smiley: 'üòÉ',
  smile: 'üòÑ',
  grin: 'üòÅ',
  laughing: 'üòÜ',
  satisfied: 'üòÜ',
  sweat_smile: 'üòÖ',
  rofl: 'ü§£',
  joy: 'üòÇ',
  slightly_smiling_face: 'üôÇ',
  upside_down_face: 'üôÉ',
  wink: 'üòâ',
  blush: 'üòä',
  innocent: 'üòá',
  smiling_face_with_three_hearts: 'ü•∞',
  heart_eyes: 'üòç',
  star_struck: 'ü§©',
  kissing_heart: 'üòò',
  kissing: 'üòó',
  relaxed: '‚ò∫Ô∏è',
  kissing_closed_eyes: 'üòö',
  kissing_smiling_eyes: 'üòô',
  smiling_face_with_tear: 'ü•≤',
  yum: 'üòã',
  stuck_out_tongue: 'üòõ',
  stuck_out_tongue_winking_eye: 'üòú',
  zany_face: 'ü§™',
  stuck_out_tongue_closed_eyes: 'üòù',
  money_mouth_face: 'ü§ë',
  hugs: 'ü§ó',
  hand_over_mouth: 'ü§≠',
  shushing_face: 'ü§´',
  thinking: 'ü§î',
  zipper_mouth_face: 'ü§ê',
  raised_eyebrow: 'ü§®',
  neutral_face: 'üòê',
  expressionless: 'üòë',
  no_mouth: 'üò∂',
  face_in_clouds: 'üò∂‚Äçüå´Ô∏è',
  smirk: 'üòè',
  unamused: 'üòí',
  roll_eyes: 'üôÑ',
  grimacing: 'üò¨',
  face_exhaling: 'üòÆ‚Äçüí®',
  lying_face: 'ü§•',
  relieved: 'üòå',
  pensive: 'üòî',
  sleepy: 'üò™',
  drooling_face: 'ü§§',
  sleeping: 'üò¥',
  mask: 'üò∑',
  face_with_thermometer: 'ü§í',
  face_with_head_bandage: 'ü§ï',
  nauseated_face: 'ü§¢',
  vomiting_face: 'ü§Æ',
  sneezing_face: 'ü§ß',
  hot_face: 'ü•µ',
  cold_face: 'ü•∂',
  woozy_face: 'ü•¥',
  dizzy_face: 'üòµ',
  face_with_spiral_eyes: 'üòµ‚Äçüí´',
  exploding_head: 'ü§Ø',
  cowboy_hat_face: 'ü§†',
  partying_face: 'ü•≥',
  disguised_face: 'ü•∏',
  sunglasses: 'üòé',
  nerd_face: 'ü§ì',
  monocle_face: 'üßê',
  confused: 'üòï',
  worried: 'üòü',
  slightly_frowning_face: 'üôÅ',
  frowning_face: '‚òπÔ∏è',
  open_mouth: 'üòÆ',
  hushed: 'üòØ',
  astonished: 'üò≤',
  flushed: 'üò≥',
  pleading_face: 'ü•∫',
  frowning: 'üò¶',
  anguished: 'üòß',
  fearful: 'üò®',
  cold_sweat: 'üò∞',
  disappointed_relieved: 'üò•',
  cry: 'üò¢',
  sob: 'üò≠',
  scream: 'üò±',
  confounded: 'üòñ',
  persevere: 'üò£',
  disappointed: 'üòû',
  sweat: 'üòì',
  weary: 'üò©',
  tired_face: 'üò´',
  yawning_face: 'ü•±',
  triumph: 'üò§',
  rage: 'üò°',
  pout: 'üò°',
  angry: 'üò†',
  cursing_face: 'ü§¨',
  smiling_imp: 'üòà',
  imp: 'üëø',
  skull: 'üíÄ',
  skull_and_crossbones: '‚ò†Ô∏è',
  hankey: 'üí©',
  poop: 'üí©',
  shit: 'üí©',
  clown_face: 'ü§°',
  japanese_ogre: 'üëπ',
  japanese_goblin: 'üë∫',
  ghost: 'üëª',
  alien: 'üëΩ',
  space_invader: 'üëæ',
  robot: 'ü§ñ',
  smiley_cat: 'üò∫',
  smile_cat: 'üò∏',
  joy_cat: 'üòπ',
  heart_eyes_cat: 'üòª',
  smirk_cat: 'üòº',
  kissing_cat: 'üòΩ',
  scream_cat: 'üôÄ',
  crying_cat_face: 'üòø',
  pouting_cat: 'üòæ',
  see_no_evil: 'üôà',
  hear_no_evil: 'üôâ',
  speak_no_evil: 'üôä',
  kiss: 'üíã',
  love_letter: 'üíå',
  cupid: 'üíò',
  gift_heart: 'üíù',
  sparkling_heart: 'üíñ',
  heartpulse: 'üíó',
  heartbeat: 'üíì',
  revolving_hearts: 'üíû',
  two_hearts: 'üíï',
  heart_decoration: 'üíü',
  heavy_heart_exclamation: '‚ù£Ô∏è',
  broken_heart: 'üíî',
  heart_on_fire: '‚ù§Ô∏è‚Äçüî•',
  mending_heart: '‚ù§Ô∏è‚Äçü©π',
  heart: '‚ù§Ô∏è',
  orange_heart: 'üß°',
  yellow_heart: 'üíõ',
  green_heart: 'üíö',
  blue_heart: 'üíô',
  purple_heart: 'üíú',
  brown_heart: 'ü§é',
  black_heart: 'üñ§',
  white_heart: 'ü§ç',
  anger: 'üí¢',
  boom: 'üí•',
  collision: 'üí•',
  dizzy: 'üí´',
  sweat_drops: 'üí¶',
  dash: 'üí®',
  hole: 'üï≥Ô∏è',
  bomb: 'üí£',
  speech_balloon: 'üí¨',
  eye_speech_bubble: 'üëÅÔ∏è‚Äçüó®Ô∏è',
  left_speech_bubble: 'üó®Ô∏è',
  right_anger_bubble: 'üóØÔ∏è',
  thought_balloon: 'üí≠',
  zzz: 'üí§',
  wave: 'üëã',
  raised_back_of_hand: 'ü§ö',
  raised_hand_with_fingers_splayed: 'üñêÔ∏è',
  hand: '‚úã',
  raised_hand: '‚úã',
  vulcan_salute: 'üññ',
  ok_hand: 'üëå',
  pinched_fingers: 'ü§å',
  pinching_hand: 'ü§è',
  v: '‚úåÔ∏è',
  crossed_fingers: 'ü§û',
  love_you_gesture: 'ü§ü',
  metal: 'ü§ò',
  call_me_hand: 'ü§ô',
  point_left: 'üëà',
  point_right: 'üëâ',
  point_up_2: 'üëÜ',
  middle_finger: 'üñï',
  fu: 'üñï',
  point_down: 'üëá',
  point_up: '‚òùÔ∏è',
  '+1': 'üëç',
  thumbsup: 'üëç',
  '-1': 'üëé',
  thumbsdown: 'üëé',
  fist_raised: '‚úä',
  fist: '‚úä',
  fist_oncoming: 'üëä',
  facepunch: 'üëä',
  punch: 'üëä',
  fist_left: 'ü§õ',
  fist_right: 'ü§ú',
  clap: 'üëè',
  raised_hands: 'üôå',
  open_hands: 'üëê',
  palms_up_together: 'ü§≤',
  handshake: 'ü§ù',
  pray: 'üôè',
  writing_hand: '‚úçÔ∏è',
  nail_care: 'üíÖ',
  selfie: 'ü§≥',
  muscle: 'üí™',
  mechanical_arm: 'ü¶æ',
  mechanical_leg: 'ü¶ø',
  leg: 'ü¶µ',
  foot: 'ü¶∂',
  ear: 'üëÇ',
  ear_with_hearing_aid: 'ü¶ª',
  nose: 'üëÉ',
  brain: 'üß†',
  anatomical_heart: 'ü´Ä',
  lungs: 'ü´Å',
  tooth: 'ü¶∑',
  bone: 'ü¶¥',
  eyes: 'üëÄ',
  eye: 'üëÅÔ∏è',
  tongue: 'üëÖ',
  lips: 'üëÑ',
  baby: 'üë∂',
  child: 'üßí',
  boy: 'üë¶',
  girl: 'üëß',
  adult: 'üßë',
  blond_haired_person: 'üë±',
  man: 'üë®',
  bearded_person: 'üßî',
  man_beard: 'üßî‚Äç‚ôÇÔ∏è',
  woman_beard: 'üßî‚Äç‚ôÄÔ∏è',
  red_haired_man: 'üë®‚Äçü¶∞',
  curly_haired_man: 'üë®‚Äçü¶±',
  white_haired_man: 'üë®‚Äçü¶≥',
  bald_man: 'üë®‚Äçü¶≤',
  woman: 'üë©',
  red_haired_woman: 'üë©‚Äçü¶∞',
  person_red_hair: 'üßë‚Äçü¶∞',
  curly_haired_woman: 'üë©‚Äçü¶±',
  person_curly_hair: 'üßë‚Äçü¶±',
  white_haired_woman: 'üë©‚Äçü¶≥',
  person_white_hair: 'üßë‚Äçü¶≥',
  bald_woman: 'üë©‚Äçü¶≤',
  person_bald: 'üßë‚Äçü¶≤',
  blond_haired_woman: 'üë±‚Äç‚ôÄÔ∏è',
  blonde_woman: 'üë±‚Äç‚ôÄÔ∏è',
  blond_haired_man: 'üë±‚Äç‚ôÇÔ∏è',
  older_adult: 'üßì',
  older_man: 'üë¥',
  older_woman: 'üëµ',
  frowning_person: 'üôç',
  frowning_man: 'üôç‚Äç‚ôÇÔ∏è',
  frowning_woman: 'üôç‚Äç‚ôÄÔ∏è',
  pouting_face: 'üôé',
  pouting_man: 'üôé‚Äç‚ôÇÔ∏è',
  pouting_woman: 'üôé‚Äç‚ôÄÔ∏è',
  no_good: 'üôÖ',
  no_good_man: 'üôÖ‚Äç‚ôÇÔ∏è',
  ng_man: 'üôÖ‚Äç‚ôÇÔ∏è',
  no_good_woman: 'üôÖ‚Äç‚ôÄÔ∏è',
  ng_woman: 'üôÖ‚Äç‚ôÄÔ∏è',
  ok_person: 'üôÜ',
  ok_man: 'üôÜ‚Äç‚ôÇÔ∏è',
  ok_woman: 'üôÜ‚Äç‚ôÄÔ∏è',
  tipping_hand_person: 'üíÅ',
  information_desk_person: 'üíÅ',
  tipping_hand_man: 'üíÅ‚Äç‚ôÇÔ∏è',
  sassy_man: 'üíÅ‚Äç‚ôÇÔ∏è',
  tipping_hand_woman: 'üíÅ‚Äç‚ôÄÔ∏è',
  sassy_woman: 'üíÅ‚Äç‚ôÄÔ∏è',
  raising_hand: 'üôã',
  raising_hand_man: 'üôã‚Äç‚ôÇÔ∏è',
  raising_hand_woman: 'üôã‚Äç‚ôÄÔ∏è',
  deaf_person: 'üßè',
  deaf_man: 'üßè‚Äç‚ôÇÔ∏è',
  deaf_woman: 'üßè‚Äç‚ôÄÔ∏è',
  bow: 'üôá',
  bowing_man: 'üôá‚Äç‚ôÇÔ∏è',
  bowing_woman: 'üôá‚Äç‚ôÄÔ∏è',
  facepalm: 'ü§¶',
  man_facepalming: 'ü§¶‚Äç‚ôÇÔ∏è',
  woman_facepalming: 'ü§¶‚Äç‚ôÄÔ∏è',
  shrug: 'ü§∑',
  man_shrugging: 'ü§∑‚Äç‚ôÇÔ∏è',
  woman_shrugging: 'ü§∑‚Äç‚ôÄÔ∏è',
  health_worker: 'üßë‚Äç‚öïÔ∏è',
  man_health_worker: 'üë®‚Äç‚öïÔ∏è',
  woman_health_worker: 'üë©‚Äç‚öïÔ∏è',
  student: 'üßë‚Äçüéì',
  man_student: 'üë®‚Äçüéì',
  woman_student: 'üë©‚Äçüéì',
  teacher: 'üßë‚Äçüè´',
  man_teacher: 'üë®‚Äçüè´',
  woman_teacher: 'üë©‚Äçüè´',
  judge: 'üßë‚Äç‚öñÔ∏è',
  man_judge: 'üë®‚Äç‚öñÔ∏è',
  woman_judge: 'üë©‚Äç‚öñÔ∏è',
  farmer: 'üßë‚Äçüåæ',
  man_farmer: 'üë®‚Äçüåæ',
  woman_farmer: 'üë©‚Äçüåæ',
  cook: 'üßë‚Äçüç≥',
  man_cook: 'üë®‚Äçüç≥',
  woman_cook: 'üë©‚Äçüç≥',
  mechanic: 'üßë‚Äçüîß',
  man_mechanic: 'üë®‚Äçüîß',
  woman_mechanic: 'üë©‚Äçüîß',
  factory_worker: 'üßë‚Äçüè≠',
  man_factory_worker: 'üë®‚Äçüè≠',
  woman_factory_worker: 'üë©‚Äçüè≠',
  office_worker: 'üßë‚Äçüíº',
  man_office_worker: 'üë®‚Äçüíº',
  woman_office_worker: 'üë©‚Äçüíº',
  scientist: 'üßë‚Äçüî¨',
  man_scientist: 'üë®‚Äçüî¨',
  woman_scientist: 'üë©‚Äçüî¨',
  technologist: 'üßë‚Äçüíª',
  man_technologist: 'üë®‚Äçüíª',
  woman_technologist: 'üë©‚Äçüíª',
  singer: 'üßë‚Äçüé§',
  man_singer: 'üë®‚Äçüé§',
  woman_singer: 'üë©‚Äçüé§',
  artist: 'üßë‚Äçüé®',
  man_artist: 'üë®‚Äçüé®',
  woman_artist: 'üë©‚Äçüé®',
  pilot: 'üßë‚Äç‚úàÔ∏è',
  man_pilot: 'üë®‚Äç‚úàÔ∏è',
  woman_pilot: 'üë©‚Äç‚úàÔ∏è',
  astronaut: 'üßë‚ÄçüöÄ',
  man_astronaut: 'üë®‚ÄçüöÄ',
  woman_astronaut: 'üë©‚ÄçüöÄ',
  firefighter: 'üßë‚Äçüöí',
  man_firefighter: 'üë®‚Äçüöí',
  woman_firefighter: 'üë©‚Äçüöí',
  police_officer: 'üëÆ',
  cop: 'üëÆ',
  policeman: 'üëÆ‚Äç‚ôÇÔ∏è',
  policewoman: 'üëÆ‚Äç‚ôÄÔ∏è',
  detective: 'üïµÔ∏è',
  male_detective: 'üïµÔ∏è‚Äç‚ôÇÔ∏è',
  female_detective: 'üïµÔ∏è‚Äç‚ôÄÔ∏è',
  guard: 'üíÇ',
  guardsman: 'üíÇ‚Äç‚ôÇÔ∏è',
  guardswoman: 'üíÇ‚Äç‚ôÄÔ∏è',
  ninja: 'ü•∑',
  construction_worker: 'üë∑',
  construction_worker_man: 'üë∑‚Äç‚ôÇÔ∏è',
  construction_worker_woman: 'üë∑‚Äç‚ôÄÔ∏è',
  prince: 'ü§¥',
  princess: 'üë∏',
  person_with_turban: 'üë≥',
  man_with_turban: 'üë≥‚Äç‚ôÇÔ∏è',
  woman_with_turban: 'üë≥‚Äç‚ôÄÔ∏è',
  man_with_gua_pi_mao: 'üë≤',
  woman_with_headscarf: 'üßï',
  person_in_tuxedo: 'ü§µ',
  man_in_tuxedo: 'ü§µ‚Äç‚ôÇÔ∏è',
  woman_in_tuxedo: 'ü§µ‚Äç‚ôÄÔ∏è',
  person_with_veil: 'üë∞',
  man_with_veil: 'üë∞‚Äç‚ôÇÔ∏è',
  woman_with_veil: 'üë∞‚Äç‚ôÄÔ∏è',
  bride_with_veil: 'üë∞‚Äç‚ôÄÔ∏è',
  pregnant_woman: 'ü§∞',
  breast_feeding: 'ü§±',
  woman_feeding_baby: 'üë©‚Äçüçº',
  man_feeding_baby: 'üë®‚Äçüçº',
  person_feeding_baby: 'üßë‚Äçüçº',
  angel: 'üëº',
  santa: 'üéÖ',
  mrs_claus: 'ü§∂',
  mx_claus: 'üßë‚ÄçüéÑ',
  superhero: 'ü¶∏',
  superhero_man: 'ü¶∏‚Äç‚ôÇÔ∏è',
  superhero_woman: 'ü¶∏‚Äç‚ôÄÔ∏è',
  supervillain: 'ü¶π',
  supervillain_man: 'ü¶π‚Äç‚ôÇÔ∏è',
  supervillain_woman: 'ü¶π‚Äç‚ôÄÔ∏è',
  mage: 'üßô',
  mage_man: 'üßô‚Äç‚ôÇÔ∏è',
  mage_woman: 'üßô‚Äç‚ôÄÔ∏è',
  fairy: 'üßö',
  fairy_man: 'üßö‚Äç‚ôÇÔ∏è',
  fairy_woman: 'üßö‚Äç‚ôÄÔ∏è',
  vampire: 'üßõ',
  vampire_man: 'üßõ‚Äç‚ôÇÔ∏è',
  vampire_woman: 'üßõ‚Äç‚ôÄÔ∏è',
  merperson: 'üßú',
  merman: 'üßú‚Äç‚ôÇÔ∏è',
  mermaid: 'üßú‚Äç‚ôÄÔ∏è',
  elf: 'üßù',
  elf_man: 'üßù‚Äç‚ôÇÔ∏è',
  elf_woman: 'üßù‚Äç‚ôÄÔ∏è',
  genie: 'üßû',
  genie_man: 'üßû‚Äç‚ôÇÔ∏è',
  genie_woman: 'üßû‚Äç‚ôÄÔ∏è',
  zombie: 'üßü',
  zombie_man: 'üßü‚Äç‚ôÇÔ∏è',
  zombie_woman: 'üßü‚Äç‚ôÄÔ∏è',
  massage: 'üíÜ',
  massage_man: 'üíÜ‚Äç‚ôÇÔ∏è',
  massage_woman: 'üíÜ‚Äç‚ôÄÔ∏è',
  haircut: 'üíá',
  haircut_man: 'üíá‚Äç‚ôÇÔ∏è',
  haircut_woman: 'üíá‚Äç‚ôÄÔ∏è',
  walking: 'üö∂',
  walking_man: 'üö∂‚Äç‚ôÇÔ∏è',
  walking_woman: 'üö∂‚Äç‚ôÄÔ∏è',
  standing_person: 'üßç',
  standing_man: 'üßç‚Äç‚ôÇÔ∏è',
  standing_woman: 'üßç‚Äç‚ôÄÔ∏è',
  kneeling_person: 'üßé',
  kneeling_man: 'üßé‚Äç‚ôÇÔ∏è',
  kneeling_woman: 'üßé‚Äç‚ôÄÔ∏è',
  person_with_probing_cane: 'üßë‚Äçü¶Ø',
  man_with_probing_cane: 'üë®‚Äçü¶Ø',
  woman_with_probing_cane: 'üë©‚Äçü¶Ø',
  person_in_motorized_wheelchair: 'üßë‚Äçü¶º',
  man_in_motorized_wheelchair: 'üë®‚Äçü¶º',
  woman_in_motorized_wheelchair: 'üë©‚Äçü¶º',
  person_in_manual_wheelchair: 'üßë‚Äçü¶Ω',
  man_in_manual_wheelchair: 'üë®‚Äçü¶Ω',
  woman_in_manual_wheelchair: 'üë©‚Äçü¶Ω',
  runner: 'üèÉ',
  running: 'üèÉ',
  running_man: 'üèÉ‚Äç‚ôÇÔ∏è',
  running_woman: 'üèÉ‚Äç‚ôÄÔ∏è',
  woman_dancing: 'üíÉ',
  dancer: 'üíÉ',
  man_dancing: 'üï∫',
  business_suit_levitating: 'üï¥Ô∏è',
  dancers: 'üëØ',
  dancing_men: 'üëØ‚Äç‚ôÇÔ∏è',
  dancing_women: 'üëØ‚Äç‚ôÄÔ∏è',
  sauna_person: 'üßñ',
  sauna_man: 'üßñ‚Äç‚ôÇÔ∏è',
  sauna_woman: 'üßñ‚Äç‚ôÄÔ∏è',
  climbing: 'üßó',
  climbing_man: 'üßó‚Äç‚ôÇÔ∏è',
  climbing_woman: 'üßó‚Äç‚ôÄÔ∏è',
  person_fencing: 'ü§∫',
  horse_racing: 'üèá',
  skier: '‚õ∑Ô∏è',
  snowboarder: 'üèÇ',
  golfing: 'üèåÔ∏è',
  golfing_man: 'üèåÔ∏è‚Äç‚ôÇÔ∏è',
  golfing_woman: 'üèåÔ∏è‚Äç‚ôÄÔ∏è',
  surfer: 'üèÑ',
  surfing_man: 'üèÑ‚Äç‚ôÇÔ∏è',
  surfing_woman: 'üèÑ‚Äç‚ôÄÔ∏è',
  rowboat: 'üö£',
  rowing_man: 'üö£‚Äç‚ôÇÔ∏è',
  rowing_woman: 'üö£‚Äç‚ôÄÔ∏è',
  swimmer: 'üèä',
  swimming_man: 'üèä‚Äç‚ôÇÔ∏è',
  swimming_woman: 'üèä‚Äç‚ôÄÔ∏è',
  bouncing_ball_person: '‚õπÔ∏è',
  bouncing_ball_man: '‚õπÔ∏è‚Äç‚ôÇÔ∏è',
  basketball_man: '‚õπÔ∏è‚Äç‚ôÇÔ∏è',
  bouncing_ball_woman: '‚õπÔ∏è‚Äç‚ôÄÔ∏è',
  basketball_woman: '‚õπÔ∏è‚Äç‚ôÄÔ∏è',
  weight_lifting: 'üèãÔ∏è',
  weight_lifting_man: 'üèãÔ∏è‚Äç‚ôÇÔ∏è',
  weight_lifting_woman: 'üèãÔ∏è‚Äç‚ôÄÔ∏è',
  bicyclist: 'üö¥',
  biking_man: 'üö¥‚Äç‚ôÇÔ∏è',
  biking_woman: 'üö¥‚Äç‚ôÄÔ∏è',
  mountain_bicyclist: 'üöµ',
  mountain_biking_man: 'üöµ‚Äç‚ôÇÔ∏è',
  mountain_biking_woman: 'üöµ‚Äç‚ôÄÔ∏è',
  cartwheeling: 'ü§∏',
  man_cartwheeling: 'ü§∏‚Äç‚ôÇÔ∏è',
  woman_cartwheeling: 'ü§∏‚Äç‚ôÄÔ∏è',
  wrestling: 'ü§º',
  men_wrestling: 'ü§º‚Äç‚ôÇÔ∏è',
  women_wrestling: 'ü§º‚Äç‚ôÄÔ∏è',
  water_polo: 'ü§Ω',
  man_playing_water_polo: 'ü§Ω‚Äç‚ôÇÔ∏è',
  woman_playing_water_polo: 'ü§Ω‚Äç‚ôÄÔ∏è',
  handball_person: 'ü§æ',
  man_playing_handball: 'ü§æ‚Äç‚ôÇÔ∏è',
  woman_playing_handball: 'ü§æ‚Äç‚ôÄÔ∏è',
  juggling_person: 'ü§π',
  man_juggling: 'ü§π‚Äç‚ôÇÔ∏è',
  woman_juggling: 'ü§π‚Äç‚ôÄÔ∏è',
  lotus_position: 'üßò',
  lotus_position_man: 'üßò‚Äç‚ôÇÔ∏è',
  lotus_position_woman: 'üßò‚Äç‚ôÄÔ∏è',
  bath: 'üõÄ',
  sleeping_bed: 'üõå',
  people_holding_hands: 'üßë‚Äçü§ù‚Äçüßë',
  two_women_holding_hands: 'üë≠',
  couple: 'üë´',
  two_men_holding_hands: 'üë¨',
  couplekiss: 'üíè',
  couplekiss_man_woman: 'üë©‚Äç‚ù§Ô∏è‚Äçüíã‚Äçüë®',
  couplekiss_man_man: 'üë®‚Äç‚ù§Ô∏è‚Äçüíã‚Äçüë®',
  couplekiss_woman_woman: 'üë©‚Äç‚ù§Ô∏è‚Äçüíã‚Äçüë©',
  couple_with_heart: 'üíë',
  couple_with_heart_woman_man: 'üë©‚Äç‚ù§Ô∏è‚Äçüë®',
  couple_with_heart_man_man: 'üë®‚Äç‚ù§Ô∏è‚Äçüë®',
  couple_with_heart_woman_woman: 'üë©‚Äç‚ù§Ô∏è‚Äçüë©',
  family: 'üë™',
  family_man_woman_boy: 'üë®‚Äçüë©‚Äçüë¶',
  family_man_woman_girl: 'üë®‚Äçüë©‚Äçüëß',
  family_man_woman_girl_boy: 'üë®‚Äçüë©‚Äçüëß‚Äçüë¶',
  family_man_woman_boy_boy: 'üë®‚Äçüë©‚Äçüë¶‚Äçüë¶',
  family_man_woman_girl_girl: 'üë®‚Äçüë©‚Äçüëß‚Äçüëß',
  family_man_man_boy: 'üë®‚Äçüë®‚Äçüë¶',
  family_man_man_girl: 'üë®‚Äçüë®‚Äçüëß',
  family_man_man_girl_boy: 'üë®‚Äçüë®‚Äçüëß‚Äçüë¶',
  family_man_man_boy_boy: 'üë®‚Äçüë®‚Äçüë¶‚Äçüë¶',
  family_man_man_girl_girl: 'üë®‚Äçüë®‚Äçüëß‚Äçüëß',
  family_woman_woman_boy: 'üë©‚Äçüë©‚Äçüë¶',
  family_woman_woman_girl: 'üë©‚Äçüë©‚Äçüëß',
  family_woman_woman_girl_boy: 'üë©‚Äçüë©‚Äçüëß‚Äçüë¶',
  family_woman_woman_boy_boy: 'üë©‚Äçüë©‚Äçüë¶‚Äçüë¶',
  family_woman_woman_girl_girl: 'üë©‚Äçüë©‚Äçüëß‚Äçüëß',
  family_man_boy: 'üë®‚Äçüë¶',
  family_man_boy_boy: 'üë®‚Äçüë¶‚Äçüë¶',
  family_man_girl: 'üë®‚Äçüëß',
  family_man_girl_boy: 'üë®‚Äçüëß‚Äçüë¶',
  family_man_girl_girl: 'üë®‚Äçüëß‚Äçüëß',
  family_woman_boy: 'üë©‚Äçüë¶',
  family_woman_boy_boy: 'üë©‚Äçüë¶‚Äçüë¶',
  family_woman_girl: 'üë©‚Äçüëß',
  family_woman_girl_boy: 'üë©‚Äçüëß‚Äçüë¶',
  family_woman_girl_girl: 'üë©‚Äçüëß‚Äçüëß',
  speaking_head: 'üó£Ô∏è',
  bust_in_silhouette: 'üë§',
  busts_in_silhouette: 'üë•',
  people_hugging: 'ü´Ç',
  footprints: 'üë£',
  monkey_face: 'üêµ',
  monkey: 'üêí',
  gorilla: 'ü¶ç',
  orangutan: 'ü¶ß',
  dog: 'üê∂',
  dog2: 'üêï',
  guide_dog: 'ü¶Æ',
  service_dog: 'üêï‚Äçü¶∫',
  poodle: 'üê©',
  wolf: 'üê∫',
  fox_face: 'ü¶ä',
  raccoon: 'ü¶ù',
  cat: 'üê±',
  cat2: 'üêà',
  black_cat: 'üêà‚Äç‚¨õ',
  lion: 'ü¶Å',
  tiger: 'üêØ',
  tiger2: 'üêÖ',
  leopard: 'üêÜ',
  horse: 'üê¥',
  racehorse: 'üêé',
  unicorn: 'ü¶Ñ',
  zebra: 'ü¶ì',
  deer: 'ü¶å',
  bison: 'ü¶¨',
  cow: 'üêÆ',
  ox: 'üêÇ',
  water_buffalo: 'üêÉ',
  cow2: 'üêÑ',
  pig: 'üê∑',
  pig2: 'üêñ',
  boar: 'üêó',
  pig_nose: 'üêΩ',
  ram: 'üêè',
  sheep: 'üêë',
  goat: 'üêê',
  dromedary_camel: 'üê™',
  camel: 'üê´',
  llama: 'ü¶ô',
  giraffe: 'ü¶í',
  elephant: 'üêò',
  mammoth: 'ü¶£',
  rhinoceros: 'ü¶è',
  hippopotamus: 'ü¶õ',
  mouse: 'üê≠',
  mouse2: 'üêÅ',
  rat: 'üêÄ',
  hamster: 'üêπ',
  rabbit: 'üê∞',
  rabbit2: 'üêá',
  chipmunk: 'üêøÔ∏è',
  beaver: 'ü¶´',
  hedgehog: 'ü¶î',
  bat: 'ü¶á',
  bear: 'üêª',
  polar_bear: 'üêª‚Äç‚ùÑÔ∏è',
  koala: 'üê®',
  panda_face: 'üêº',
  sloth: 'ü¶•',
  otter: 'ü¶¶',
  skunk: 'ü¶®',
  kangaroo: 'ü¶ò',
  badger: 'ü¶°',
  feet: 'üêæ',
  paw_prints: 'üêæ',
  turkey: 'ü¶É',
  chicken: 'üêî',
  rooster: 'üêì',
  hatching_chick: 'üê£',
  baby_chick: 'üê§',
  hatched_chick: 'üê•',
  bird: 'üê¶',
  penguin: 'üêß',
  dove: 'üïäÔ∏è',
  eagle: 'ü¶Ö',
  duck: 'ü¶Ü',
  swan: 'ü¶¢',
  owl: 'ü¶â',
  dodo: 'ü¶§',
  feather: 'ü™∂',
  flamingo: 'ü¶©',
  peacock: 'ü¶ö',
  parrot: 'ü¶ú',
  frog: 'üê∏',
  crocodile: 'üêä',
  turtle: 'üê¢',
  lizard: 'ü¶é',
  snake: 'üêç',
  dragon_face: 'üê≤',
  dragon: 'üêâ',
  sauropod: 'ü¶ï',
  't-rex': 'ü¶ñ',
  whale: 'üê≥',
  whale2: 'üêã',
  dolphin: 'üê¨',
  flipper: 'üê¨',
  seal: 'ü¶≠',
  fish: 'üêü',
  tropical_fish: 'üê†',
  blowfish: 'üê°',
  shark: 'ü¶à',
  octopus: 'üêô',
  shell: 'üêö',
  snail: 'üêå',
  butterfly: 'ü¶ã',
  bug: 'üêõ',
  ant: 'üêú',
  bee: 'üêù',
  honeybee: 'üêù',
  beetle: 'ü™≤',
  lady_beetle: 'üêû',
  cricket: 'ü¶ó',
  cockroach: 'ü™≥',
  spider: 'üï∑Ô∏è',
  spider_web: 'üï∏Ô∏è',
  scorpion: 'ü¶Ç',
  mosquito: 'ü¶ü',
  fly: 'ü™∞',
  worm: 'ü™±',
  microbe: 'ü¶†',
  bouquet: 'üíê',
  cherry_blossom: 'üå∏',
  white_flower: 'üíÆ',
  rosette: 'üèµÔ∏è',
  rose: 'üåπ',
  wilted_flower: 'ü•Ä',
  hibiscus: 'üå∫',
  sunflower: 'üåª',
  blossom: 'üåº',
  tulip: 'üå∑',
  seedling: 'üå±',
  potted_plant: 'ü™¥',
  evergreen_tree: 'üå≤',
  deciduous_tree: 'üå≥',
  palm_tree: 'üå¥',
  cactus: 'üåµ',
  ear_of_rice: 'üåæ',
  herb: 'üåø',
  shamrock: '‚òòÔ∏è',
  four_leaf_clover: 'üçÄ',
  maple_leaf: 'üçÅ',
  fallen_leaf: 'üçÇ',
  leaves: 'üçÉ',
  grapes: 'üçá',
  melon: 'üçà',
  watermelon: 'üçâ',
  tangerine: 'üçä',
  orange: 'üçä',
  mandarin: 'üçä',
  lemon: 'üçã',
  banana: 'üçå',
  pineapple: 'üçç',
  mango: 'ü•≠',
  apple: 'üçé',
  green_apple: 'üçè',
  pear: 'üçê',
  peach: 'üçë',
  cherries: 'üçí',
  strawberry: 'üçì',
  blueberries: 'ü´ê',
  kiwi_fruit: 'ü•ù',
  tomato: 'üçÖ',
  olive: 'ü´í',
  coconut: 'ü••',
  avocado: 'ü•ë',
  eggplant: 'üçÜ',
  potato: 'ü•î',
  carrot: 'ü•ï',
  corn: 'üåΩ',
  hot_pepper: 'üå∂Ô∏è',
  bell_pepper: 'ü´ë',
  cucumber: 'ü•í',
  leafy_green: 'ü•¨',
  broccoli: 'ü•¶',
  garlic: 'üßÑ',
  onion: 'üßÖ',
  mushroom: 'üçÑ',
  peanuts: 'ü•ú',
  chestnut: 'üå∞',
  bread: 'üçû',
  croissant: 'ü•ê',
  baguette_bread: 'ü•ñ',
  flatbread: 'ü´ì',
  pretzel: 'ü•®',
  bagel: 'ü•Ø',
  pancakes: 'ü•û',
  waffle: 'üßá',
  cheese: 'üßÄ',
  meat_on_bone: 'üçñ',
  poultry_leg: 'üçó',
  cut_of_meat: 'ü•©',
  bacon: 'ü•ì',
  hamburger: 'üçî',
  fries: 'üçü',
  pizza: 'üçï',
  hotdog: 'üå≠',
  sandwich: 'ü•™',
  taco: 'üåÆ',
  burrito: 'üåØ',
  tamale: 'ü´î',
  stuffed_flatbread: 'ü•ô',
  falafel: 'üßÜ',
  egg: 'ü•ö',
  fried_egg: 'üç≥',
  shallow_pan_of_food: 'ü•ò',
  stew: 'üç≤',
  fondue: 'ü´ï',
  bowl_with_spoon: 'ü•£',
  green_salad: 'ü•ó',
  popcorn: 'üçø',
  butter: 'üßà',
  salt: 'üßÇ',
  canned_food: 'ü•´',
  bento: 'üç±',
  rice_cracker: 'üçò',
  rice_ball: 'üçô',
  rice: 'üçö',
  curry: 'üçõ',
  ramen: 'üçú',
  spaghetti: 'üçù',
  sweet_potato: 'üç†',
  oden: 'üç¢',
  sushi: 'üç£',
  fried_shrimp: 'üç§',
  fish_cake: 'üç•',
  moon_cake: 'ü•Æ',
  dango: 'üç°',
  dumpling: 'ü•ü',
  fortune_cookie: 'ü•†',
  takeout_box: 'ü•°',
  crab: 'ü¶Ä',
  lobster: 'ü¶û',
  shrimp: 'ü¶ê',
  squid: 'ü¶ë',
  oyster: 'ü¶™',
  icecream: 'üç¶',
  shaved_ice: 'üçß',
  ice_cream: 'üç®',
  doughnut: 'üç©',
  cookie: 'üç™',
  birthday: 'üéÇ',
  cake: 'üç∞',
  cupcake: 'üßÅ',
  pie: 'ü•ß',
  chocolate_bar: 'üç´',
  candy: 'üç¨',
  lollipop: 'üç≠',
  custard: 'üçÆ',
  honey_pot: 'üçØ',
  baby_bottle: 'üçº',
  milk_glass: 'ü•õ',
  coffee: '‚òï',
  teapot: 'ü´ñ',
  tea: 'üçµ',
  sake: 'üç∂',
  champagne: 'üçæ',
  wine_glass: 'üç∑',
  cocktail: 'üç∏',
  tropical_drink: 'üçπ',
  beer: 'üç∫',
  beers: 'üçª',
  clinking_glasses: 'ü•Ç',
  tumbler_glass: 'ü•É',
  cup_with_straw: 'ü•§',
  bubble_tea: 'üßã',
  beverage_box: 'üßÉ',
  mate: 'üßâ',
  ice_cube: 'üßä',
  chopsticks: 'ü•¢',
  plate_with_cutlery: 'üçΩÔ∏è',
  fork_and_knife: 'üç¥',
  spoon: 'ü•Ñ',
  hocho: 'üî™',
  knife: 'üî™',
  amphora: 'üè∫',
  earth_africa: 'üåç',
  earth_americas: 'üåé',
  earth_asia: 'üåè',
  globe_with_meridians: 'üåê',
  world_map: 'üó∫Ô∏è',
  japan: 'üóæ',
  compass: 'üß≠',
  mountain_snow: 'üèîÔ∏è',
  mountain: '‚õ∞Ô∏è',
  volcano: 'üåã',
  mount_fuji: 'üóª',
  camping: 'üèïÔ∏è',
  beach_umbrella: 'üèñÔ∏è',
  desert: 'üèúÔ∏è',
  desert_island: 'üèùÔ∏è',
  national_park: 'üèûÔ∏è',
  stadium: 'üèüÔ∏è',
  classical_building: 'üèõÔ∏è',
  building_construction: 'üèóÔ∏è',
  bricks: 'üß±',
  rock: 'ü™®',
  wood: 'ü™µ',
  hut: 'üõñ',
  houses: 'üèòÔ∏è',
  derelict_house: 'üèöÔ∏è',
  house: 'üè†',
  house_with_garden: 'üè°',
  office: 'üè¢',
  post_office: 'üè£',
  european_post_office: 'üè§',
  hospital: 'üè•',
  bank: 'üè¶',
  hotel: 'üè®',
  love_hotel: 'üè©',
  convenience_store: 'üè™',
  school: 'üè´',
  department_store: 'üè¨',
  factory: 'üè≠',
  japanese_castle: 'üèØ',
  european_castle: 'üè∞',
  wedding: 'üíí',
  tokyo_tower: 'üóº',
  statue_of_liberty: 'üóΩ',
  church: '‚õ™',
  mosque: 'üïå',
  hindu_temple: 'üõï',
  synagogue: 'üïç',
  shinto_shrine: '‚õ©Ô∏è',
  kaaba: 'üïã',
  fountain: '‚õ≤',
  tent: '‚õ∫',
  foggy: 'üåÅ',
  night_with_stars: 'üåÉ',
  cityscape: 'üèôÔ∏è',
  sunrise_over_mountains: 'üåÑ',
  sunrise: 'üåÖ',
  city_sunset: 'üåÜ',
  city_sunrise: 'üåá',
  bridge_at_night: 'üåâ',
  hotsprings: '‚ô®Ô∏è',
  carousel_horse: 'üé†',
  ferris_wheel: 'üé°',
  roller_coaster: 'üé¢',
  barber: 'üíà',
  circus_tent: 'üé™',
  steam_locomotive: 'üöÇ',
  railway_car: 'üöÉ',
  bullettrain_side: 'üöÑ',
  bullettrain_front: 'üöÖ',
  train2: 'üöÜ',
  metro: 'üöá',
  light_rail: 'üöà',
  station: 'üöâ',
  tram: 'üöä',
  monorail: 'üöù',
  mountain_railway: 'üöû',
  train: 'üöã',
  bus: 'üöå',
  oncoming_bus: 'üöç',
  trolleybus: 'üöé',
  minibus: 'üöê',
  ambulance: 'üöë',
  fire_engine: 'üöí',
  police_car: 'üöì',
  oncoming_police_car: 'üöî',
  taxi: 'üöï',
  oncoming_taxi: 'üöñ',
  car: 'üöó',
  red_car: 'üöó',
  oncoming_automobile: 'üöò',
  blue_car: 'üöô',
  pickup_truck: 'üõª',
  truck: 'üöö',
  articulated_lorry: 'üöõ',
  tractor: 'üöú',
  racing_car: 'üèéÔ∏è',
  motorcycle: 'üèçÔ∏è',
  motor_scooter: 'üõµ',
  manual_wheelchair: 'ü¶Ω',
  motorized_wheelchair: 'ü¶º',
  auto_rickshaw: 'üõ∫',
  bike: 'üö≤',
  kick_scooter: 'üõ¥',
  skateboard: 'üõπ',
  roller_skate: 'üõº',
  busstop: 'üöè',
  motorway: 'üõ£Ô∏è',
  railway_track: 'üõ§Ô∏è',
  oil_drum: 'üõ¢Ô∏è',
  fuelpump: '‚õΩ',
  rotating_light: 'üö®',
  traffic_light: 'üö•',
  vertical_traffic_light: 'üö¶',
  stop_sign: 'üõë',
  construction: 'üöß',
  anchor: '‚öì',
  boat: '‚õµ',
  sailboat: '‚õµ',
  canoe: 'üõ∂',
  speedboat: 'üö§',
  passenger_ship: 'üõ≥Ô∏è',
  ferry: '‚õ¥Ô∏è',
  motor_boat: 'üõ•Ô∏è',
  ship: 'üö¢',
  airplane: '‚úàÔ∏è',
  small_airplane: 'üõ©Ô∏è',
  flight_departure: 'üõ´',
  flight_arrival: 'üõ¨',
  parachute: 'ü™Ç',
  seat: 'üí∫',
  helicopter: 'üöÅ',
  suspension_railway: 'üöü',
  mountain_cableway: 'üö†',
  aerial_tramway: 'üö°',
  artificial_satellite: 'üõ∞Ô∏è',
  rocket: 'üöÄ',
  flying_saucer: 'üõ∏',
  bellhop_bell: 'üõéÔ∏è',
  luggage: 'üß≥',
  hourglass: '‚åõ',
  hourglass_flowing_sand: '‚è≥',
  watch: '‚åö',
  alarm_clock: '‚è∞',
  stopwatch: '‚è±Ô∏è',
  timer_clock: '‚è≤Ô∏è',
  mantelpiece_clock: 'üï∞Ô∏è',
  clock12: 'üïõ',
  clock1230: 'üïß',
  clock1: 'üïê',
  clock130: 'üïú',
  clock2: 'üïë',
  clock230: 'üïù',
  clock3: 'üïí',
  clock330: 'üïû',
  clock4: 'üïì',
  clock430: 'üïü',
  clock5: 'üïî',
  clock530: 'üï†',
  clock6: 'üïï',
  clock630: 'üï°',
  clock7: 'üïñ',
  clock730: 'üï¢',
  clock8: 'üïó',
  clock830: 'üï£',
  clock9: 'üïò',
  clock930: 'üï§',
  clock10: 'üïô',
  clock1030: 'üï•',
  clock11: 'üïö',
  clock1130: 'üï¶',
  new_moon: 'üåë',
  waxing_crescent_moon: 'üåí',
  first_quarter_moon: 'üåì',
  moon: 'üåî',
  waxing_gibbous_moon: 'üåî',
  full_moon: 'üåï',
  waning_gibbous_moon: 'üåñ',
  last_quarter_moon: 'üåó',
  waning_crescent_moon: 'üåò',
  crescent_moon: 'üåô',
  new_moon_with_face: 'üåö',
  first_quarter_moon_with_face: 'üåõ',
  last_quarter_moon_with_face: 'üåú',
  thermometer: 'üå°Ô∏è',
  sunny: '‚òÄÔ∏è',
  full_moon_with_face: 'üåù',
  sun_with_face: 'üåû',
  ringed_planet: 'ü™ê',
  star: '‚≠ê',
  star2: 'üåü',
  stars: 'üå†',
  milky_way: 'üåå',
  cloud: '‚òÅÔ∏è',
  partly_sunny: '‚õÖ',
  cloud_with_lightning_and_rain: '‚õàÔ∏è',
  sun_behind_small_cloud: 'üå§Ô∏è',
  sun_behind_large_cloud: 'üå•Ô∏è',
  sun_behind_rain_cloud: 'üå¶Ô∏è',
  cloud_with_rain: 'üåßÔ∏è',
  cloud_with_snow: 'üå®Ô∏è',
  cloud_with_lightning: 'üå©Ô∏è',
  tornado: 'üå™Ô∏è',
  fog: 'üå´Ô∏è',
  wind_face: 'üå¨Ô∏è',
  cyclone: 'üåÄ',
  rainbow: 'üåà',
  closed_umbrella: 'üåÇ',
  open_umbrella: '‚òÇÔ∏è',
  umbrella: '‚òî',
  parasol_on_ground: '‚õ±Ô∏è',
  zap: '‚ö°',
  snowflake: '‚ùÑÔ∏è',
  snowman_with_snow: '‚òÉÔ∏è',
  snowman: '‚õÑ',
  comet: '‚òÑÔ∏è',
  fire: 'üî•',
  droplet: 'üíß',
  ocean: 'üåä',
  jack_o_lantern: 'üéÉ',
  christmas_tree: 'üéÑ',
  fireworks: 'üéÜ',
  sparkler: 'üéá',
  firecracker: 'üß®',
  sparkles: '‚ú®',
  balloon: 'üéà',
  tada: 'üéâ',
  confetti_ball: 'üéä',
  tanabata_tree: 'üéã',
  bamboo: 'üéç',
  dolls: 'üéé',
  flags: 'üéè',
  wind_chime: 'üéê',
  rice_scene: 'üéë',
  red_envelope: 'üßß',
  ribbon: 'üéÄ',
  gift: 'üéÅ',
  reminder_ribbon: 'üéóÔ∏è',
  tickets: 'üéüÔ∏è',
  ticket: 'üé´',
  medal_military: 'üéñÔ∏è',
  trophy: 'üèÜ',
  medal_sports: 'üèÖ',
  '1st_place_medal': 'ü•á',
  '2nd_place_medal': 'ü•à',
  '3rd_place_medal': 'ü•â',
  soccer: '‚öΩ',
  baseball: '‚öæ',
  softball: 'ü•é',
  basketball: 'üèÄ',
  volleyball: 'üèê',
  football: 'üèà',
  rugby_football: 'üèâ',
  tennis: 'üéæ',
  flying_disc: 'ü•è',
  bowling: 'üé≥',
  cricket_game: 'üèè',
  field_hockey: 'üèë',
  ice_hockey: 'üèí',
  lacrosse: 'ü•ç',
  ping_pong: 'üèì',
  badminton: 'üè∏',
  boxing_glove: 'ü•ä',
  martial_arts_uniform: 'ü•ã',
  goal_net: 'ü•Ö',
  golf: '‚õ≥',
  ice_skate: '‚õ∏Ô∏è',
  fishing_pole_and_fish: 'üé£',
  diving_mask: 'ü§ø',
  running_shirt_with_sash: 'üéΩ',
  ski: 'üéø',
  sled: 'üõ∑',
  curling_stone: 'ü•å',
  dart: 'üéØ',
  yo_yo: 'ü™Ä',
  kite: 'ü™Å',
  '8ball': 'üé±',
  crystal_ball: 'üîÆ',
  magic_wand: 'ü™Ñ',
  nazar_amulet: 'üßø',
  video_game: 'üéÆ',
  joystick: 'üïπÔ∏è',
  slot_machine: 'üé∞',
  game_die: 'üé≤',
  jigsaw: 'üß©',
  teddy_bear: 'üß∏',
  pinata: 'ü™Ö',
  nesting_dolls: 'ü™Ü',
  spades: '‚ô†Ô∏è',
  hearts: '‚ô•Ô∏è',
  diamonds: '‚ô¶Ô∏è',
  clubs: '‚ô£Ô∏è',
  chess_pawn: '‚ôüÔ∏è',
  black_joker: 'üÉè',
  mahjong: 'üÄÑ',
  flower_playing_cards: 'üé¥',
  performing_arts: 'üé≠',
  framed_picture: 'üñºÔ∏è',
  art: 'üé®',
  thread: 'üßµ',
  sewing_needle: 'ü™°',
  yarn: 'üß∂',
  knot: 'ü™¢',
  eyeglasses: 'üëì',
  dark_sunglasses: 'üï∂Ô∏è',
  goggles: 'ü•Ω',
  lab_coat: 'ü•º',
  safety_vest: 'ü¶∫',
  necktie: 'üëî',
  shirt: 'üëï',
  tshirt: 'üëï',
  jeans: 'üëñ',
  scarf: 'üß£',
  gloves: 'üß§',
  coat: 'üß•',
  socks: 'üß¶',
  dress: 'üëó',
  kimono: 'üëò',
  sari: 'ü•ª',
  one_piece_swimsuit: 'ü©±',
  swim_brief: 'ü©≤',
  shorts: 'ü©≥',
  bikini: 'üëô',
  womans_clothes: 'üëö',
  purse: 'üëõ',
  handbag: 'üëú',
  pouch: 'üëù',
  shopping: 'üõçÔ∏è',
  school_satchel: 'üéí',
  thong_sandal: 'ü©¥',
  mans_shoe: 'üëû',
  shoe: 'üëû',
  athletic_shoe: 'üëü',
  hiking_boot: 'ü•æ',
  flat_shoe: 'ü•ø',
  high_heel: 'üë†',
  sandal: 'üë°',
  ballet_shoes: 'ü©∞',
  boot: 'üë¢',
  crown: 'üëë',
  womans_hat: 'üëí',
  tophat: 'üé©',
  mortar_board: 'üéì',
  billed_cap: 'üß¢',
  military_helmet: 'ü™ñ',
  rescue_worker_helmet: '‚õëÔ∏è',
  prayer_beads: 'üìø',
  lipstick: 'üíÑ',
  ring: 'üíç',
  gem: 'üíé',
  mute: 'üîá',
  speaker: 'üîà',
  sound: 'üîâ',
  loud_sound: 'üîä',
  loudspeaker: 'üì¢',
  mega: 'üì£',
  postal_horn: 'üìØ',
  bell: 'üîî',
  no_bell: 'üîï',
  musical_score: 'üéº',
  musical_note: 'üéµ',
  notes: 'üé∂',
  studio_microphone: 'üéôÔ∏è',
  level_slider: 'üéöÔ∏è',
  control_knobs: 'üéõÔ∏è',
  microphone: 'üé§',
  headphones: 'üéß',
  radio: 'üìª',
  saxophone: 'üé∑',
  accordion: 'ü™ó',
  guitar: 'üé∏',
  musical_keyboard: 'üéπ',
  trumpet: 'üé∫',
  violin: 'üéª',
  banjo: 'ü™ï',
  drum: 'ü•Å',
  long_drum: 'ü™ò',
  iphone: 'üì±',
  calling: 'üì≤',
  phone: '‚òéÔ∏è',
  telephone: '‚òéÔ∏è',
  telephone_receiver: 'üìû',
  pager: 'üìü',
  fax: 'üì†',
  battery: 'üîã',
  electric_plug: 'üîå',
  computer: 'üíª',
  desktop_computer: 'üñ•Ô∏è',
  printer: 'üñ®Ô∏è',
  keyboard: '‚å®Ô∏è',
  computer_mouse: 'üñ±Ô∏è',
  trackball: 'üñ≤Ô∏è',
  minidisc: 'üíΩ',
  floppy_disk: 'üíæ',
  cd: 'üíø',
  dvd: 'üìÄ',
  abacus: 'üßÆ',
  movie_camera: 'üé•',
  film_strip: 'üéûÔ∏è',
  film_projector: 'üìΩÔ∏è',
  clapper: 'üé¨',
  tv: 'üì∫',
  camera: 'üì∑',
  camera_flash: 'üì∏',
  video_camera: 'üìπ',
  vhs: 'üìº',
  mag: 'üîç',
  mag_right: 'üîé',
  candle: 'üïØÔ∏è',
  bulb: 'üí°',
  flashlight: 'üî¶',
  izakaya_lantern: 'üèÆ',
  lantern: 'üèÆ',
  diya_lamp: 'ü™î',
  notebook_with_decorative_cover: 'üìî',
  closed_book: 'üìï',
  book: 'üìñ',
  open_book: 'üìñ',
  green_book: 'üìó',
  blue_book: 'üìò',
  orange_book: 'üìô',
  books: 'üìö',
  notebook: 'üìì',
  ledger: 'üìí',
  page_with_curl: 'üìÉ',
  scroll: 'üìú',
  page_facing_up: 'üìÑ',
  newspaper: 'üì∞',
  newspaper_roll: 'üóûÔ∏è',
  bookmark_tabs: 'üìë',
  bookmark: 'üîñ',
  label: 'üè∑Ô∏è',
  moneybag: 'üí∞',
  coin: 'ü™ô',
  yen: 'üí¥',
  dollar: 'üíµ',
  euro: 'üí∂',
  pound: 'üí∑',
  money_with_wings: 'üí∏',
  credit_card: 'üí≥',
  receipt: 'üßæ',
  chart: 'üíπ',
  envelope: '‚úâÔ∏è',
  email: 'üìß',
  'e-mail': 'üìß',
  incoming_envelope: 'üì®',
  envelope_with_arrow: 'üì©',
  outbox_tray: 'üì§',
  inbox_tray: 'üì•',
  package: 'üì¶',
  mailbox: 'üì´',
  mailbox_closed: 'üì™',
  mailbox_with_mail: 'üì¨',
  mailbox_with_no_mail: 'üì≠',
  postbox: 'üìÆ',
  ballot_box: 'üó≥Ô∏è',
  pencil2: '‚úèÔ∏è',
  black_nib: '‚úíÔ∏è',
  fountain_pen: 'üñãÔ∏è',
  pen: 'üñäÔ∏è',
  paintbrush: 'üñåÔ∏è',
  crayon: 'üñçÔ∏è',
  memo: 'üìù',
  pencil: 'üìù',
  briefcase: 'üíº',
  file_folder: 'üìÅ',
  open_file_folder: 'üìÇ',
  card_index_dividers: 'üóÇÔ∏è',
  date: 'üìÖ',
  calendar: 'üìÜ',
  spiral_notepad: 'üóíÔ∏è',
  spiral_calendar: 'üóìÔ∏è',
  card_index: 'üìá',
  chart_with_upwards_trend: 'üìà',
  chart_with_downwards_trend: 'üìâ',
  bar_chart: 'üìä',
  clipboard: 'üìã',
  pushpin: 'üìå',
  round_pushpin: 'üìç',
  paperclip: 'üìé',
  paperclips: 'üñáÔ∏è',
  straight_ruler: 'üìè',
  triangular_ruler: 'üìê',
  scissors: '‚úÇÔ∏è',
  card_file_box: 'üóÉÔ∏è',
  file_cabinet: 'üóÑÔ∏è',
  wastebasket: 'üóëÔ∏è',
  lock: 'üîí',
  unlock: 'üîì',
  lock_with_ink_pen: 'üîè',
  closed_lock_with_key: 'üîê',
  key: 'üîë',
  old_key: 'üóùÔ∏è',
  hammer: 'üî®',
  axe: 'ü™ì',
  pick: '‚õèÔ∏è',
  hammer_and_pick: '‚öíÔ∏è',
  hammer_and_wrench: 'üõ†Ô∏è',
  dagger: 'üó°Ô∏è',
  crossed_swords: '‚öîÔ∏è',
  gun: 'üî´',
  boomerang: 'ü™É',
  bow_and_arrow: 'üèπ',
  shield: 'üõ°Ô∏è',
  carpentry_saw: 'ü™ö',
  wrench: 'üîß',
  screwdriver: 'ü™õ',
  nut_and_bolt: 'üî©',
  gear: '‚öôÔ∏è',
  clamp: 'üóúÔ∏è',
  balance_scale: '‚öñÔ∏è',
  probing_cane: 'ü¶Ø',
  link: 'üîó',
  chains: '‚õìÔ∏è',
  hook: 'ü™ù',
  toolbox: 'üß∞',
  magnet: 'üß≤',
  ladder: 'ü™ú',
  alembic: '‚öóÔ∏è',
  test_tube: 'üß™',
  petri_dish: 'üß´',
  dna: 'üß¨',
  microscope: 'üî¨',
  telescope: 'üî≠',
  satellite: 'üì°',
  syringe: 'üíâ',
  drop_of_blood: 'ü©∏',
  pill: 'üíä',
  adhesive_bandage: 'ü©π',
  stethoscope: 'ü©∫',
  door: 'üö™',
  elevator: 'üõó',
  mirror: 'ü™û',
  window: 'ü™ü',
  bed: 'üõèÔ∏è',
  couch_and_lamp: 'üõãÔ∏è',
  chair: 'ü™ë',
  toilet: 'üöΩ',
  plunger: 'ü™†',
  shower: 'üöø',
  bathtub: 'üõÅ',
  mouse_trap: 'ü™§',
  razor: 'ü™í',
  lotion_bottle: 'üß¥',
  safety_pin: 'üß∑',
  broom: 'üßπ',
  basket: 'üß∫',
  roll_of_paper: 'üßª',
  bucket: 'ü™£',
  soap: 'üßº',
  toothbrush: 'ü™•',
  sponge: 'üßΩ',
  fire_extinguisher: 'üßØ',
  shopping_cart: 'üõí',
  smoking: 'üö¨',
  coffin: '‚ö∞Ô∏è',
  headstone: 'ü™¶',
  funeral_urn: '‚ö±Ô∏è',
  moyai: 'üóø',
  placard: 'ü™ß',
  atm: 'üèß',
  put_litter_in_its_place: 'üöÆ',
  potable_water: 'üö∞',
  wheelchair: '‚ôø',
  mens: 'üöπ',
  womens: 'üö∫',
  restroom: 'üöª',
  baby_symbol: 'üöº',
  wc: 'üöæ',
  passport_control: 'üõÇ',
  customs: 'üõÉ',
  baggage_claim: 'üõÑ',
  left_luggage: 'üõÖ',
  warning: '‚ö†Ô∏è',
  children_crossing: 'üö∏',
  no_entry: '‚õî',
  no_entry_sign: 'üö´',
  no_bicycles: 'üö≥',
  no_smoking: 'üö≠',
  do_not_litter: 'üöØ',
  'non-potable_water': 'üö±',
  no_pedestrians: 'üö∑',
  no_mobile_phones: 'üìµ',
  underage: 'üîû',
  radioactive: '‚ò¢Ô∏è',
  biohazard: '‚ò£Ô∏è',
  arrow_up: '‚¨ÜÔ∏è',
  arrow_upper_right: '‚ÜóÔ∏è',
  arrow_right: '‚û°Ô∏è',
  arrow_lower_right: '‚ÜòÔ∏è',
  arrow_down: '‚¨áÔ∏è',
  arrow_lower_left: '‚ÜôÔ∏è',
  arrow_left: '‚¨ÖÔ∏è',
  arrow_upper_left: '‚ÜñÔ∏è',
  arrow_up_down: '‚ÜïÔ∏è',
  left_right_arrow: '‚ÜîÔ∏è',
  leftwards_arrow_with_hook: '‚Ü©Ô∏è',
  arrow_right_hook: '‚Ü™Ô∏è',
  arrow_heading_up: '‚§¥Ô∏è',
  arrow_heading_down: '‚§µÔ∏è',
  arrows_clockwise: 'üîÉ',
  arrows_counterclockwise: 'üîÑ',
  back: 'üîô',
  end: 'üîö',
  on: 'üîõ',
  soon: 'üîú',
  top: 'üîù',
  place_of_worship: 'üõê',
  atom_symbol: '‚öõÔ∏è',
  om: 'üïâÔ∏è',
  star_of_david: '‚ú°Ô∏è',
  wheel_of_dharma: '‚ò∏Ô∏è',
  yin_yang: '‚òØÔ∏è',
  latin_cross: '‚úùÔ∏è',
  orthodox_cross: '‚ò¶Ô∏è',
  star_and_crescent: '‚ò™Ô∏è',
  peace_symbol: '‚òÆÔ∏è',
  menorah: 'üïé',
  six_pointed_star: 'üîØ',
  aries: '‚ôà',
  taurus: '‚ôâ',
  gemini: '‚ôä',
  cancer: '‚ôã',
  leo: '‚ôå',
  virgo: '‚ôç',
  libra: '‚ôé',
  scorpius: '‚ôè',
  sagittarius: '‚ôê',
  capricorn: '‚ôë',
  aquarius: '‚ôí',
  pisces: '‚ôì',
  ophiuchus: '‚õé',
  twisted_rightwards_arrows: 'üîÄ',
  repeat: 'üîÅ',
  repeat_one: 'üîÇ',
  arrow_forward: '‚ñ∂Ô∏è',
  fast_forward: '‚è©',
  next_track_button: '‚è≠Ô∏è',
  play_or_pause_button: '‚èØÔ∏è',
  arrow_backward: '‚óÄÔ∏è',
  rewind: '‚è™',
  previous_track_button: '‚èÆÔ∏è',
  arrow_up_small: 'üîº',
  arrow_double_up: '‚è´',
  arrow_down_small: 'üîΩ',
  arrow_double_down: '‚è¨',
  pause_button: '‚è∏Ô∏è',
  stop_button: '‚èπÔ∏è',
  record_button: '‚è∫Ô∏è',
  eject_button: '‚èèÔ∏è',
  cinema: 'üé¶',
  low_brightness: 'üîÖ',
  high_brightness: 'üîÜ',
  signal_strength: 'üì∂',
  vibration_mode: 'üì≥',
  mobile_phone_off: 'üì¥',
  female_sign: '‚ôÄÔ∏è',
  male_sign: '‚ôÇÔ∏è',
  transgender_symbol: '‚ößÔ∏è',
  heavy_multiplication_x: '‚úñÔ∏è',
  heavy_plus_sign: '‚ûï',
  heavy_minus_sign: '‚ûñ',
  heavy_division_sign: '‚ûó',
  infinity: '‚ôæÔ∏è',
  bangbang: '‚ÄºÔ∏è',
  interrobang: '‚ÅâÔ∏è',
  question: '‚ùì',
  grey_question: '‚ùî',
  grey_exclamation: '‚ùï',
  exclamation: '‚ùó',
  heavy_exclamation_mark: '‚ùó',
  wavy_dash: '„Ä∞Ô∏è',
  currency_exchange: 'üí±',
  heavy_dollar_sign: 'üí≤',
  medical_symbol: '‚öïÔ∏è',
  recycle: '‚ôªÔ∏è',
  fleur_de_lis: '‚öúÔ∏è',
  trident: 'üî±',
  name_badge: 'üìõ',
  beginner: 'üî∞',
  o: '‚≠ï',
  white_check_mark: '‚úÖ',
  ballot_box_with_check: '‚òëÔ∏è',
  heavy_check_mark: '‚úîÔ∏è',
  x: '‚ùå',
  negative_squared_cross_mark: '‚ùé',
  curly_loop: '‚û∞',
  loop: '‚ûø',
  part_alternation_mark: '„ÄΩÔ∏è',
  eight_spoked_asterisk: '‚ú≥Ô∏è',
  eight_pointed_black_star: '‚ú¥Ô∏è',
  sparkle: '‚ùáÔ∏è',
  copyright: '¬©Ô∏è',
  registered: '¬ÆÔ∏è',
  tm: '‚Ñ¢Ô∏è',
  hash: '#Ô∏è‚É£',
  asterisk: '*Ô∏è‚É£',
  zero: '0Ô∏è‚É£',
  one: '1Ô∏è‚É£',
  two: '2Ô∏è‚É£',
  three: '3Ô∏è‚É£',
  four: '4Ô∏è‚É£',
  five: '5Ô∏è‚É£',
  six: '6Ô∏è‚É£',
  seven: '7Ô∏è‚É£',
  eight: '8Ô∏è‚É£',
  nine: '9Ô∏è‚É£',
  keycap_ten: 'üîü',
  capital_abcd: 'üî†',
  abcd: 'üî°',
  symbols: 'üî£',
  abc: 'üî§',
  a: 'üÖ∞Ô∏è',
  ab: 'üÜé',
  b: 'üÖ±Ô∏è',
  cl: 'üÜë',
  cool: 'üÜí',
  free: 'üÜì',
  information_source: '‚ÑπÔ∏è',
  id: 'üÜî',
  m: '‚ìÇÔ∏è',
  new: 'üÜï',
  ng: 'üÜñ',
  o2: 'üÖæÔ∏è',
  ok: 'üÜó',
  parking: 'üÖøÔ∏è',
  sos: 'üÜò',
  up: 'üÜô',
  vs: 'üÜö',
  koko: 'üàÅ',
  sa: 'üàÇÔ∏è',
  u6708: 'üà∑Ô∏è',
  u6709: 'üà∂',
  u6307: 'üàØ',
  ideograph_advantage: 'üâê',
  u5272: 'üàπ',
  u7121: 'üàö',
  u7981: 'üà≤',
  accept: 'üâë',
  u7533: 'üà∏',
  u5408: 'üà¥',
  u7a7a: 'üà≥',
  congratulations: '„äóÔ∏è',
  secret: '„äôÔ∏è',
  u55b6: 'üà∫',
  u6e80: 'üàµ',
  red_circle: 'üî¥',
  orange_circle: 'üü†',
  yellow_circle: 'üü°',
  green_circle: 'üü¢',
  large_blue_circle: 'üîµ',
  purple_circle: 'üü£',
  brown_circle: 'üü§',
  black_circle: '‚ö´',
  white_circle: '‚ö™',
  red_square: 'üü•',
  orange_square: 'üüß',
  yellow_square: 'üü®',
  green_square: 'üü©',
  blue_square: 'üü¶',
  purple_square: 'üü™',
  brown_square: 'üü´',
  black_large_square: '‚¨õ',
  white_large_square: '‚¨ú',
  black_medium_square: '‚óºÔ∏è',
  white_medium_square: '‚óªÔ∏è',
  black_medium_small_square: '‚óæ',
  white_medium_small_square: '‚óΩ',
  black_small_square: '‚ñ™Ô∏è',
  white_small_square: '‚ñ´Ô∏è',
  large_orange_diamond: 'üî∂',
  large_blue_diamond: 'üî∑',
  small_orange_diamond: 'üî∏',
  small_blue_diamond: 'üîπ',
  small_red_triangle: 'üî∫',
  small_red_triangle_down: 'üîª',
  diamond_shape_with_a_dot_inside: 'üí†',
  radio_button: 'üîò',
  white_square_button: 'üî≥',
  black_square_button: 'üî≤',
  checkered_flag: 'üèÅ',
  triangular_flag_on_post: 'üö©',
  crossed_flags: 'üéå',
  black_flag: 'üè¥',
  white_flag: 'üè≥Ô∏è',
  rainbow_flag: 'üè≥Ô∏è‚Äçüåà',
  transgender_flag: 'üè≥Ô∏è‚Äç‚ößÔ∏è',
  pirate_flag: 'üè¥‚Äç‚ò†Ô∏è',
  ascension_island: 'üá¶üá®',
  andorra: 'üá¶üá©',
  united_arab_emirates: 'üá¶üá™',
  afghanistan: 'üá¶üá´',
  antigua_barbuda: 'üá¶üá¨',
  anguilla: 'üá¶üáÆ',
  albania: 'üá¶üá±',
  armenia: 'üá¶üá≤',
  angola: 'üá¶üá¥',
  antarctica: 'üá¶üá∂',
  argentina: 'üá¶üá∑',
  american_samoa: 'üá¶üá∏',
  austria: 'üá¶üáπ',
  australia: 'üá¶üá∫',
  aruba: 'üá¶üáº',
  aland_islands: 'üá¶üáΩ',
  azerbaijan: 'üá¶üáø',
  bosnia_herzegovina: 'üáßüá¶',
  barbados: 'üáßüáß',
  bangladesh: 'üáßüá©',
  belgium: 'üáßüá™',
  burkina_faso: 'üáßüá´',
  bulgaria: 'üáßüá¨',
  bahrain: 'üáßüá≠',
  burundi: 'üáßüáÆ',
  benin: 'üáßüáØ',
  st_barthelemy: 'üáßüá±',
  bermuda: 'üáßüá≤',
  brunei: 'üáßüá≥',
  bolivia: 'üáßüá¥',
  caribbean_netherlands: 'üáßüá∂',
  brazil: 'üáßüá∑',
  bahamas: 'üáßüá∏',
  bhutan: 'üáßüáπ',
  bouvet_island: 'üáßüáª',
  botswana: 'üáßüáº',
  belarus: 'üáßüáæ',
  belize: 'üáßüáø',
  canada: 'üá®üá¶',
  cocos_islands: 'üá®üá®',
  congo_kinshasa: 'üá®üá©',
  central_african_republic: 'üá®üá´',
  congo_brazzaville: 'üá®üá¨',
  switzerland: 'üá®üá≠',
  cote_divoire: 'üá®üáÆ',
  cook_islands: 'üá®üá∞',
  chile: 'üá®üá±',
  cameroon: 'üá®üá≤',
  cn: 'üá®üá≥',
  colombia: 'üá®üá¥',
  clipperton_island: 'üá®üáµ',
  costa_rica: 'üá®üá∑',
  cuba: 'üá®üá∫',
  cape_verde: 'üá®üáª',
  curacao: 'üá®üáº',
  christmas_island: 'üá®üáΩ',
  cyprus: 'üá®üáæ',
  czech_republic: 'üá®üáø',
  de: 'üá©üá™',
  diego_garcia: 'üá©üá¨',
  djibouti: 'üá©üáØ',
  denmark: 'üá©üá∞',
  dominica: 'üá©üá≤',
  dominican_republic: 'üá©üá¥',
  algeria: 'üá©üáø',
  ceuta_melilla: 'üá™üá¶',
  ecuador: 'üá™üá®',
  estonia: 'üá™üá™',
  egypt: 'üá™üá¨',
  western_sahara: 'üá™üá≠',
  eritrea: 'üá™üá∑',
  es: 'üá™üá∏',
  ethiopia: 'üá™üáπ',
  eu: 'üá™üá∫',
  european_union: 'üá™üá∫',
  finland: 'üá´üáÆ',
  fiji: 'üá´üáØ',
  falkland_islands: 'üá´üá∞',
  micronesia: 'üá´üá≤',
  faroe_islands: 'üá´üá¥',
  fr: 'üá´üá∑',
  gabon: 'üá¨üá¶',
  gb: 'üá¨üáß',
  uk: 'üá¨üáß',
  grenada: 'üá¨üá©',
  georgia: 'üá¨üá™',
  french_guiana: 'üá¨üá´',
  guernsey: 'üá¨üá¨',
  ghana: 'üá¨üá≠',
  gibraltar: 'üá¨üáÆ',
  greenland: 'üá¨üá±',
  gambia: 'üá¨üá≤',
  guinea: 'üá¨üá≥',
  guadeloupe: 'üá¨üáµ',
  equatorial_guinea: 'üá¨üá∂',
  greece: 'üá¨üá∑',
  south_georgia_south_sandwich_islands: 'üá¨üá∏',
  guatemala: 'üá¨üáπ',
  guam: 'üá¨üá∫',
  guinea_bissau: 'üá¨üáº',
  guyana: 'üá¨üáæ',
  hong_kong: 'üá≠üá∞',
  heard_mcdonald_islands: 'üá≠üá≤',
  honduras: 'üá≠üá≥',
  croatia: 'üá≠üá∑',
  haiti: 'üá≠üáπ',
  hungary: 'üá≠üá∫',
  canary_islands: 'üáÆüá®',
  indonesia: 'üáÆüá©',
  ireland: 'üáÆüá™',
  israel: 'üáÆüá±',
  isle_of_man: 'üáÆüá≤',
  india: 'üáÆüá≥',
  british_indian_ocean_territory: 'üáÆüá¥',
  iraq: 'üáÆüá∂',
  iran: 'üáÆüá∑',
  iceland: 'üáÆüá∏',
  it: 'üáÆüáπ',
  jersey: 'üáØüá™',
  jamaica: 'üáØüá≤',
  jordan: 'üáØüá¥',
  jp: 'üáØüáµ',
  kenya: 'üá∞üá™',
  kyrgyzstan: 'üá∞üá¨',
  cambodia: 'üá∞üá≠',
  kiribati: 'üá∞üáÆ',
  comoros: 'üá∞üá≤',
  st_kitts_nevis: 'üá∞üá≥',
  north_korea: 'üá∞üáµ',
  kr: 'üá∞üá∑',
  kuwait: 'üá∞üáº',
  cayman_islands: 'üá∞üáæ',
  kazakhstan: 'üá∞üáø',
  laos: 'üá±üá¶',
  lebanon: 'üá±üáß',
  st_lucia: 'üá±üá®',
  liechtenstein: 'üá±üáÆ',
  sri_lanka: 'üá±üá∞',
  liberia: 'üá±üá∑',
  lesotho: 'üá±üá∏',
  lithuania: 'üá±üáπ',
  luxembourg: 'üá±üá∫',
  latvia: 'üá±üáª',
  libya: 'üá±üáæ',
  morocco: 'üá≤üá¶',
  monaco: 'üá≤üá®',
  moldova: 'üá≤üá©',
  montenegro: 'üá≤üá™',
  st_martin: 'üá≤üá´',
  madagascar: 'üá≤üá¨',
  marshall_islands: 'üá≤üá≠',
  macedonia: 'üá≤üá∞',
  mali: 'üá≤üá±',
  myanmar: 'üá≤üá≤',
  mongolia: 'üá≤üá≥',
  macau: 'üá≤üá¥',
  northern_mariana_islands: 'üá≤üáµ',
  martinique: 'üá≤üá∂',
  mauritania: 'üá≤üá∑',
  montserrat: 'üá≤üá∏',
  malta: 'üá≤üáπ',
  mauritius: 'üá≤üá∫',
  maldives: 'üá≤üáª',
  malawi: 'üá≤üáº',
  mexico: 'üá≤üáΩ',
  malaysia: 'üá≤üáæ',
  mozambique: 'üá≤üáø',
  namibia: 'üá≥üá¶',
  new_caledonia: 'üá≥üá®',
  niger: 'üá≥üá™',
  norfolk_island: 'üá≥üá´',
  nigeria: 'üá≥üá¨',
  nicaragua: 'üá≥üáÆ',
  netherlands: 'üá≥üá±',
  norway: 'üá≥üá¥',
  nepal: 'üá≥üáµ',
  nauru: 'üá≥üá∑',
  niue: 'üá≥üá∫',
  new_zealand: 'üá≥üáø',
  oman: 'üá¥üá≤',
  panama: 'üáµüá¶',
  peru: 'üáµüá™',
  french_polynesia: 'üáµüá´',
  papua_new_guinea: 'üáµüá¨',
  philippines: 'üáµüá≠',
  pakistan: 'üáµüá∞',
  poland: 'üáµüá±',
  st_pierre_miquelon: 'üáµüá≤',
  pitcairn_islands: 'üáµüá≥',
  puerto_rico: 'üáµüá∑',
  palestinian_territories: 'üáµüá∏',
  portugal: 'üáµüáπ',
  palau: 'üáµüáº',
  paraguay: 'üáµüáæ',
  qatar: 'üá∂üá¶',
  reunion: 'üá∑üá™',
  romania: 'üá∑üá¥',
  serbia: 'üá∑üá∏',
  ru: 'üá∑üá∫',
  rwanda: 'üá∑üáº',
  saudi_arabia: 'üá∏üá¶',
  solomon_islands: 'üá∏üáß',
  seychelles: 'üá∏üá®',
  sudan: 'üá∏üá©',
  sweden: 'üá∏üá™',
  singapore: 'üá∏üá¨',
  st_helena: 'üá∏üá≠',
  slovenia: 'üá∏üáÆ',
  svalbard_jan_mayen: 'üá∏üáØ',
  slovakia: 'üá∏üá∞',
  sierra_leone: 'üá∏üá±',
  san_marino: 'üá∏üá≤',
  senegal: 'üá∏üá≥',
  somalia: 'üá∏üá¥',
  suriname: 'üá∏üá∑',
  south_sudan: 'üá∏üá∏',
  sao_tome_principe: 'üá∏üáπ',
  el_salvador: 'üá∏üáª',
  sint_maarten: 'üá∏üáΩ',
  syria: 'üá∏üáæ',
  swaziland: 'üá∏üáø',
  tristan_da_cunha: 'üáπüá¶',
  turks_caicos_islands: 'üáπüá®',
  chad: 'üáπüá©',
  french_southern_territories: 'üáπüá´',
  togo: 'üáπüá¨',
  thailand: 'üáπüá≠',
  tajikistan: 'üáπüáØ',
  tokelau: 'üáπüá∞',
  timor_leste: 'üáπüá±',
  turkmenistan: 'üáπüá≤',
  tunisia: 'üáπüá≥',
  tonga: 'üáπüá¥',
  tr: 'üáπüá∑',
  trinidad_tobago: 'üáπüáπ',
  tuvalu: 'üáπüáª',
  taiwan: 'üáπüáº',
  tanzania: 'üáπüáø',
  ukraine: 'üá∫üá¶',
  uganda: 'üá∫üá¨',
  us_outlying_islands: 'üá∫üá≤',
  united_nations: 'üá∫üá≥',
  us: 'üá∫üá∏',
  uruguay: 'üá∫üáæ',
  uzbekistan: 'üá∫üáø',
  vatican_city: 'üáªüá¶',
  st_vincent_grenadines: 'üáªüá®',
  venezuela: 'üáªüá™',
  british_virgin_islands: 'üáªüá¨',
  us_virgin_islands: 'üáªüáÆ',
  vietnam: 'üáªüá≥',
  vanuatu: 'üáªüá∫',
  wallis_futuna: 'üáºüá´',
  samoa: 'üáºüá∏',
  kosovo: 'üáΩüá∞',
  yemen: 'üáæüá™',
  mayotte: 'üáæüáπ',
  south_africa: 'üáøüá¶',
  zambia: 'üáøüá≤',
  zimbabwe: 'üáøüáº',
  england: 'üè¥Û†ÅßÛ†Å¢Û†Å•Û†ÅÆÛ†ÅßÛ†Åø',
  scotland: 'üè¥Û†ÅßÛ†Å¢Û†Å≥Û†Å£Û†Å¥Û†Åø',
  wales: 'üè¥Û†ÅßÛ†Å¢Û†Å∑Û†Å¨Û†Å≥Û†Åø'
};

/**
 * @typedef {import('mdast').Root} Root
 */

const find = /:(\+1|[-\w]+):/g;

const own$3 = {}.hasOwnProperty;

/**
 * Plugin to turn gemoji shortcodes (`:+1:`) into emoji (`üëç`).
 *
 * @type {import('unified').Plugin<void[], Root>}
 */
function remarkGemoji() {
  return (tree) => {
    visit(tree, 'text', (node) => {
      const value = node.value;
      /** @type {string[]} */
      const slices = [];
      find.lastIndex = 0;
      let match = find.exec(value);
      let start = 0;

      while (match) {
        const emoji = /** @type {keyof nameToEmoji} */ (match[1]);
        const position = match.index;

        if (own$3.call(nameToEmoji, emoji)) {
          if (start !== position) {
            slices.push(value.slice(start, position));
          }

          slices.push(nameToEmoji[emoji]);
          start = position + match[0].length;
        } else {
          find.lastIndex = position + 1;
        }

        match = find.exec(value);
      }

      if (slices.length > 0) {
        slices.push(value.slice(start));
        node.value = slices.join('');
      }
    });
  }
}

/**
 * @typedef {import('micromark-util-types').Extension} Extension
 * @typedef {import('micromark-util-types').ConstructRecord} ConstructRecord
 * @typedef {import('micromark-util-types').Tokenizer} Tokenizer
 * @typedef {import('micromark-util-types').Previous} Previous
 * @typedef {import('micromark-util-types').State} State
 * @typedef {import('micromark-util-types').Event} Event
 * @typedef {import('micromark-util-types').Code} Code
 */
const www = {
  tokenize: tokenizeWww,
  partial: true
};
const domain = {
  tokenize: tokenizeDomain,
  partial: true
};
const path = {
  tokenize: tokenizePath,
  partial: true
};
const punctuation = {
  tokenize: tokenizePunctuation,
  partial: true
};
const namedCharacterReference = {
  tokenize: tokenizeNamedCharacterReference,
  partial: true
};
const wwwAutolink = {
  tokenize: tokenizeWwwAutolink,
  previous: previousWww
};
const httpAutolink = {
  tokenize: tokenizeHttpAutolink,
  previous: previousHttp
};
const emailAutolink = {
  tokenize: tokenizeEmailAutolink,
  previous: previousEmail
};
/** @type {ConstructRecord} */

const text$1 = {};
/** @type {Extension} */

const gfmAutolinkLiteral = {
  text: text$1
};
let code$1 = 48; // Add alphanumerics.

while (code$1 < 123) {
  text$1[code$1] = emailAutolink;
  code$1++;
  if (code$1 === 58) code$1 = 65;
  else if (code$1 === 91) code$1 = 97;
}

text$1[43] = emailAutolink;
text$1[45] = emailAutolink;
text$1[46] = emailAutolink;
text$1[95] = emailAutolink;
text$1[72] = [emailAutolink, httpAutolink];
text$1[104] = [emailAutolink, httpAutolink];
text$1[87] = [emailAutolink, wwwAutolink];
text$1[119] = [emailAutolink, wwwAutolink];
/** @type {Tokenizer} */

function tokenizeEmailAutolink(effects, ok, nok) {
  const self = this;
  /** @type {boolean} */

  let hasDot;
  /** @type {boolean|undefined} */

  let hasDigitInLastSegment;
  return start
  /** @type {State} */

  function start(code) {
    if (
      !gfmAtext(code) ||
      !previousEmail(self.previous) ||
      previousUnbalanced(self.events)
    ) {
      return nok(code)
    }

    effects.enter('literalAutolink');
    effects.enter('literalAutolinkEmail');
    return atext(code)
  }
  /** @type {State} */

  function atext(code) {
    if (gfmAtext(code)) {
      effects.consume(code);
      return atext
    }

    if (code === 64) {
      effects.consume(code);
      return label
    }

    return nok(code)
  }
  /** @type {State} */

  function label(code) {
    if (code === 46) {
      return effects.check(punctuation, done, dotContinuation)(code)
    }

    if (code === 45 || code === 95) {
      return effects.check(punctuation, nok, dashOrUnderscoreContinuation)(code)
    }

    if (asciiAlphanumeric(code)) {
      if (!hasDigitInLastSegment && asciiDigit(code)) {
        hasDigitInLastSegment = true;
      }

      effects.consume(code);
      return label
    }

    return done(code)
  }
  /** @type {State} */

  function dotContinuation(code) {
    effects.consume(code);
    hasDot = true;
    hasDigitInLastSegment = undefined;
    return label
  }
  /** @type {State} */

  function dashOrUnderscoreContinuation(code) {
    effects.consume(code);
    return afterDashOrUnderscore
  }
  /** @type {State} */

  function afterDashOrUnderscore(code) {
    if (code === 46) {
      return effects.check(punctuation, nok, dotContinuation)(code)
    }

    return label(code)
  }
  /** @type {State} */

  function done(code) {
    if (hasDot && !hasDigitInLastSegment) {
      effects.exit('literalAutolinkEmail');
      effects.exit('literalAutolink');
      return ok(code)
    }

    return nok(code)
  }
}
/** @type {Tokenizer} */

function tokenizeWwwAutolink(effects, ok, nok) {
  const self = this;
  return start
  /** @type {State} */

  function start(code) {
    if (
      (code !== 87 && code !== 119) ||
      !previousWww(self.previous) ||
      previousUnbalanced(self.events)
    ) {
      return nok(code)
    }

    effects.enter('literalAutolink');
    effects.enter('literalAutolinkWww'); // For `www.` we check instead of attempt, because when it matches, GH
    // treats it as part of a domain (yes, it says a valid domain must come
    // after `www.`, but that‚Äôs not how it‚Äôs implemented by them).

    return effects.check(
      www,
      effects.attempt(domain, effects.attempt(path, done), nok),
      nok
    )(code)
  }
  /** @type {State} */

  function done(code) {
    effects.exit('literalAutolinkWww');
    effects.exit('literalAutolink');
    return ok(code)
  }
}
/** @type {Tokenizer} */

function tokenizeHttpAutolink(effects, ok, nok) {
  const self = this;
  return start
  /** @type {State} */

  function start(code) {
    if (
      (code !== 72 && code !== 104) ||
      !previousHttp(self.previous) ||
      previousUnbalanced(self.events)
    ) {
      return nok(code)
    }

    effects.enter('literalAutolink');
    effects.enter('literalAutolinkHttp');
    effects.consume(code);
    return t1
  }
  /** @type {State} */

  function t1(code) {
    if (code === 84 || code === 116) {
      effects.consume(code);
      return t2
    }

    return nok(code)
  }
  /** @type {State} */

  function t2(code) {
    if (code === 84 || code === 116) {
      effects.consume(code);
      return p
    }

    return nok(code)
  }
  /** @type {State} */

  function p(code) {
    if (code === 80 || code === 112) {
      effects.consume(code);
      return s
    }

    return nok(code)
  }
  /** @type {State} */

  function s(code) {
    if (code === 83 || code === 115) {
      effects.consume(code);
      return colon
    }

    return colon(code)
  }
  /** @type {State} */

  function colon(code) {
    if (code === 58) {
      effects.consume(code);
      return slash1
    }

    return nok(code)
  }
  /** @type {State} */

  function slash1(code) {
    if (code === 47) {
      effects.consume(code);
      return slash2
    }

    return nok(code)
  }
  /** @type {State} */

  function slash2(code) {
    if (code === 47) {
      effects.consume(code);
      return after
    }

    return nok(code)
  }
  /** @type {State} */

  function after(code) {
    return code === null ||
      asciiControl(code) ||
      unicodeWhitespace(code) ||
      unicodePunctuation(code)
      ? nok(code)
      : effects.attempt(domain, effects.attempt(path, done), nok)(code)
  }
  /** @type {State} */

  function done(code) {
    effects.exit('literalAutolinkHttp');
    effects.exit('literalAutolink');
    return ok(code)
  }
}
/** @type {Tokenizer} */

function tokenizeWww(effects, ok, nok) {
  return start
  /** @type {State} */

  function start(code) {
    effects.consume(code);
    return w2
  }
  /** @type {State} */

  function w2(code) {
    if (code === 87 || code === 119) {
      effects.consume(code);
      return w3
    }

    return nok(code)
  }
  /** @type {State} */

  function w3(code) {
    if (code === 87 || code === 119) {
      effects.consume(code);
      return dot
    }

    return nok(code)
  }
  /** @type {State} */

  function dot(code) {
    if (code === 46) {
      effects.consume(code);
      return after
    }

    return nok(code)
  }
  /** @type {State} */

  function after(code) {
    return code === null || markdownLineEnding(code) ? nok(code) : ok(code)
  }
}
/** @type {Tokenizer} */

function tokenizeDomain(effects, ok, nok) {
  /** @type {boolean|undefined} */
  let hasUnderscoreInLastSegment;
  /** @type {boolean|undefined} */

  let hasUnderscoreInLastLastSegment;
  return domain
  /** @type {State} */

  function domain(code) {
    if (code === 38) {
      return effects.check(
        namedCharacterReference,
        done,
        punctuationContinuation
      )(code)
    }

    if (code === 46 || code === 95) {
      return effects.check(punctuation, done, punctuationContinuation)(code)
    } // GH documents that only alphanumerics (other than `-`, `.`, and `_`) can
    // occur, which sounds like ASCII only, but they also support `www.ÈªûÁúã.com`,
    // so that‚Äôs Unicode.
    // Instead of some new production for Unicode alphanumerics, markdown
    // already has that for Unicode punctuation and whitespace, so use those.

    if (
      code === null ||
      asciiControl(code) ||
      unicodeWhitespace(code) ||
      (code !== 45 && unicodePunctuation(code))
    ) {
      return done(code)
    }

    effects.consume(code);
    return domain
  }
  /** @type {State} */

  function punctuationContinuation(code) {
    if (code === 46) {
      hasUnderscoreInLastLastSegment = hasUnderscoreInLastSegment;
      hasUnderscoreInLastSegment = undefined;
      effects.consume(code);
      return domain
    }

    if (code === 95) hasUnderscoreInLastSegment = true;
    effects.consume(code);
    return domain
  }
  /** @type {State} */

  function done(code) {
    if (!hasUnderscoreInLastLastSegment && !hasUnderscoreInLastSegment) {
      return ok(code)
    }

    return nok(code)
  }
}
/** @type {Tokenizer} */

function tokenizePath(effects, ok) {
  let balance = 0;
  return inPath
  /** @type {State} */

  function inPath(code) {
    if (code === 38) {
      return effects.check(
        namedCharacterReference,
        ok,
        continuedPunctuation
      )(code)
    }

    if (code === 40) {
      balance++;
    }

    if (code === 41) {
      return effects.check(
        punctuation,
        parenAtPathEnd,
        continuedPunctuation
      )(code)
    }

    if (pathEnd(code)) {
      return ok(code)
    }

    if (trailingPunctuation(code)) {
      return effects.check(punctuation, ok, continuedPunctuation)(code)
    }

    effects.consume(code);
    return inPath
  }
  /** @type {State} */

  function continuedPunctuation(code) {
    effects.consume(code);
    return inPath
  }
  /** @type {State} */

  function parenAtPathEnd(code) {
    balance--;
    return balance < 0 ? ok(code) : continuedPunctuation(code)
  }
}
/** @type {Tokenizer} */

function tokenizeNamedCharacterReference(effects, ok, nok) {
  return start
  /** @type {State} */

  function start(code) {
    effects.consume(code);
    return inside
  }
  /** @type {State} */

  function inside(code) {
    if (asciiAlpha(code)) {
      effects.consume(code);
      return inside
    }

    if (code === 59) {
      effects.consume(code);
      return after
    }

    return nok(code)
  }
  /** @type {State} */

  function after(code) {
    // If the named character reference is followed by the end of the path, it‚Äôs
    // not continued punctuation.
    return pathEnd(code) ? ok(code) : nok(code)
  }
}
/** @type {Tokenizer} */

function tokenizePunctuation(effects, ok, nok) {
  return start
  /** @type {State} */

  function start(code) {
    effects.consume(code);
    return after
  }
  /** @type {State} */

  function after(code) {
    // Check the next.
    if (trailingPunctuation(code)) {
      effects.consume(code);
      return after
    } // If the punctuation marker is followed by the end of the path, it‚Äôs not
    // continued punctuation.

    return pathEnd(code) ? ok(code) : nok(code)
  }
}
/**
 * @param {Code} code
 * @returns {boolean}
 */

function trailingPunctuation(code) {
  return (
    code === 33 ||
    code === 34 ||
    code === 39 ||
    code === 41 ||
    code === 42 ||
    code === 44 ||
    code === 46 ||
    code === 58 ||
    code === 59 ||
    code === 60 ||
    code === 63 ||
    code === 95 ||
    code === 126
  )
}
/**
 * @param {Code} code
 * @returns {boolean}
 */

function pathEnd(code) {
  return code === null || code === 60 || markdownLineEndingOrSpace(code)
}
/**
 * @param {Code} code
 * @returns {boolean}
 */

function gfmAtext(code) {
  return (
    code === 43 ||
    code === 45 ||
    code === 46 ||
    code === 95 ||
    asciiAlphanumeric(code)
  )
}
/** @type {Previous} */

function previousWww(code) {
  return (
    code === null ||
    code === 40 ||
    code === 42 ||
    code === 95 ||
    code === 126 ||
    markdownLineEndingOrSpace(code)
  )
}
/** @type {Previous} */

function previousHttp(code) {
  return code === null || !asciiAlpha(code)
}
/** @type {Previous} */

function previousEmail(code) {
  return code !== 47 && previousHttp(code)
}
/**
 * @param {Array<Event>} events
 * @returns {boolean}
 */

function previousUnbalanced(events) {
  let index = events.length;
  let result = false;

  while (index--) {
    const token = events[index][1];

    if (
      (token.type === 'labelLink' || token.type === 'labelImage') &&
      !token._balanced
    ) {
      result = true;
      break
    } // @ts-expect-error If we‚Äôve seen this token, and it was marked as not
    // having any unbalanced bracket before it, we can exit.

    if (token._gfmAutolinkLiteralWalkedInto) {
      result = false;
      break
    }
  }

  if (events.length > 0 && !result) {
    // @ts-expect-error Mark the last token as ‚Äúwalked into‚Äù w/o finding
    // anything.
    events[events.length - 1][1]._gfmAutolinkLiteralWalkedInto = true;
  }

  return result
}

/**
 * Normalize a URL (such as used in definitions).
 *
 * Encode unsafe characters with percent-encoding, skipping already encoded
 * sequences.
 *
 * @param {string} value
 * @returns {string}
 */

function normalizeUri(value) {
  /** @type {Array<string>} */
  const result = [];
  let index = -1;
  let start = 0;
  let skip = 0;

  while (++index < value.length) {
    const code = value.charCodeAt(index);
    /** @type {string} */

    let replace = ''; // A correct percent encoded value.

    if (
      code === 37 &&
      asciiAlphanumeric(value.charCodeAt(index + 1)) &&
      asciiAlphanumeric(value.charCodeAt(index + 2))
    ) {
      skip = 2;
    } // ASCII.
    else if (code < 128) {
      if (!/[!#$&-;=?-Z_a-z~]/.test(String.fromCharCode(code))) {
        replace = String.fromCharCode(code);
      }
    } // Astral.
    else if (code > 55295 && code < 57344) {
      const next = value.charCodeAt(index + 1); // A correct surrogate pair.

      if (code < 56320 && next > 56319 && next < 57344) {
        replace = String.fromCharCode(code, next);
        skip = 1;
      } // Lone surrogate.
      else {
        replace = '\uFFFD';
      }
    } // Unicode.
    else {
      replace = String.fromCharCode(code);
    }

    if (replace) {
      result.push(value.slice(start, index), encodeURIComponent(replace));
      start = index + skip + 1;
      replace = '';
    }

    if (skip) {
      index += skip;
      skip = 0;
    }
  }

  return result.join('') + value.slice(start)
}

/**
 * @typedef {import('micromark-util-types').Extension} Extension
 * @typedef {import('micromark-util-types').Resolver} Resolver
 * @typedef {import('micromark-util-types').Token} Token
 * @typedef {import('micromark-util-types').Tokenizer} Tokenizer
 * @typedef {import('micromark-util-types').Exiter} Exiter
 * @typedef {import('micromark-util-types').State} State
 * @typedef {import('micromark-util-types').Event} Event
 */
const indent = {
  tokenize: tokenizeIndent,
  partial: true
};
/**
 * @returns {Extension}
 */

function gfmFootnote() {
  /** @type {Extension} */
  return {
    document: {
      [91]: {
        tokenize: tokenizeDefinitionStart,
        continuation: {
          tokenize: tokenizeDefinitionContinuation
        },
        exit: gfmFootnoteDefinitionEnd
      }
    },
    text: {
      [91]: {
        tokenize: tokenizeGfmFootnoteCall
      },
      [93]: {
        add: 'after',
        tokenize: tokenizePotentialGfmFootnoteCall,
        resolveTo: resolveToPotentialGfmFootnoteCall
      }
    }
  }
}
/** @type {Tokenizer} */

function tokenizePotentialGfmFootnoteCall(effects, ok, nok) {
  const self = this;
  let index = self.events.length;
  /** @type {Array<string>} */
  // @ts-expect-error It‚Äôs fine!

  const defined = self.parser.gfmFootnotes || (self.parser.gfmFootnotes = []);
  /** @type {Token} */

  let labelStart; // Find an opening.

  while (index--) {
    const token = self.events[index][1];

    if (token.type === 'labelImage') {
      labelStart = token;
      break
    } // Exit if we‚Äôve walked far enough.

    if (
      token.type === 'gfmFootnoteCall' ||
      token.type === 'labelLink' ||
      token.type === 'label' ||
      token.type === 'image' ||
      token.type === 'link'
    ) {
      break
    }
  }

  return start
  /** @type {State} */

  function start(code) {
    if (!labelStart || !labelStart._balanced) {
      return nok(code)
    }

    const id = normalizeIdentifier(
      self.sliceSerialize({
        start: labelStart.end,
        end: self.now()
      })
    );

    if (id.charCodeAt(0) !== 94 || !defined.includes(id.slice(1))) {
      return nok(code)
    }

    effects.enter('gfmFootnoteCallLabelMarker');
    effects.consume(code);
    effects.exit('gfmFootnoteCallLabelMarker');
    return ok(code)
  }
}
/** @type {Resolver} */

function resolveToPotentialGfmFootnoteCall(events, context) {
  let index = events.length;

  while (index--) {
    if (
      events[index][1].type === 'labelImage' &&
      events[index][0] === 'enter'
    ) {
      events[index][1];
      break
    }
  }

  // Change the `labelImageMarker` to a `data`.
  events[index + 1][1].type = 'data';
  events[index + 3][1].type = 'gfmFootnoteCallLabelMarker'; // The whole (without `!`):

  const call = {
    type: 'gfmFootnoteCall',
    start: Object.assign({}, events[index + 3][1].start),
    end: Object.assign({}, events[events.length - 1][1].end)
  }; // The `^` marker

  const marker = {
    type: 'gfmFootnoteCallMarker',
    start: Object.assign({}, events[index + 3][1].end),
    end: Object.assign({}, events[index + 3][1].end)
  }; // Increment the end 1 character.

  marker.end.column++;
  marker.end.offset++;
  marker.end._bufferIndex++;
  const string = {
    type: 'gfmFootnoteCallString',
    start: Object.assign({}, marker.end),
    end: Object.assign({}, events[events.length - 1][1].start)
  };
  const chunk = {
    type: 'chunkString',
    contentType: 'string',
    start: Object.assign({}, string.start),
    end: Object.assign({}, string.end)
  };
  /** @type {Array<Event>} */

  const replacement = [
    // Take the `labelImageMarker` (now `data`, the `!`)
    events[index + 1],
    events[index + 2],
    ['enter', call, context], // The `[`
    events[index + 3],
    events[index + 4], // The `^`.
    ['enter', marker, context],
    ['exit', marker, context], // Everything in between.
    ['enter', string, context],
    ['enter', chunk, context],
    ['exit', chunk, context],
    ['exit', string, context], // The ending (`]`, properly parsed and labelled).
    events[events.length - 2],
    events[events.length - 1],
    ['exit', call, context]
  ];
  events.splice(index, events.length - index + 1, ...replacement);
  return events
}
/** @type {Tokenizer} */

function tokenizeGfmFootnoteCall(effects, ok, nok) {
  const self = this;
  /** @type {Array<string>} */
  // @ts-expect-error It‚Äôs fine!

  const defined = self.parser.gfmFootnotes || (self.parser.gfmFootnotes = []);
  let size = 0;
  /** @type {boolean} */

  let data;
  return start
  /** @type {State} */

  function start(code) {
    effects.enter('gfmFootnoteCall');
    effects.enter('gfmFootnoteCallLabelMarker');
    effects.consume(code);
    effects.exit('gfmFootnoteCallLabelMarker');
    return callStart
  }
  /** @type {State} */

  function callStart(code) {
    if (code !== 94) return nok(code)
    effects.enter('gfmFootnoteCallMarker');
    effects.consume(code);
    effects.exit('gfmFootnoteCallMarker');
    effects.enter('gfmFootnoteCallString');
    effects.enter('chunkString').contentType = 'string';
    return callData
  }
  /** @type {State} */

  function callData(code) {
    /** @type {Token} */
    let token;

    if (code === null || code === 91 || size++ > 999) {
      return nok(code)
    }

    if (code === 93) {
      if (!data) {
        return nok(code)
      }

      effects.exit('chunkString');
      token = effects.exit('gfmFootnoteCallString');
      return defined.includes(normalizeIdentifier(self.sliceSerialize(token)))
        ? end(code)
        : nok(code)
    }

    effects.consume(code);

    if (!markdownLineEndingOrSpace(code)) {
      data = true;
    }

    return code === 92 ? callEscape : callData
  }
  /** @type {State} */

  function callEscape(code) {
    if (code === 91 || code === 92 || code === 93) {
      effects.consume(code);
      size++;
      return callData
    }

    return callData(code)
  }
  /** @type {State} */

  function end(code) {
    effects.enter('gfmFootnoteCallLabelMarker');
    effects.consume(code);
    effects.exit('gfmFootnoteCallLabelMarker');
    effects.exit('gfmFootnoteCall');
    return ok
  }
}
/** @type {Tokenizer} */

function tokenizeDefinitionStart(effects, ok, nok) {
  const self = this;
  /** @type {Array<string>} */
  // @ts-expect-error It‚Äôs fine!

  const defined = self.parser.gfmFootnotes || (self.parser.gfmFootnotes = []);
  /** @type {string} */

  let identifier;
  let size = 0;
  /** @type {boolean|undefined} */

  let data;
  return start
  /** @type {State} */

  function start(code) {
    effects.enter('gfmFootnoteDefinition')._container = true;
    effects.enter('gfmFootnoteDefinitionLabel');
    effects.enter('gfmFootnoteDefinitionLabelMarker');
    effects.consume(code);
    effects.exit('gfmFootnoteDefinitionLabelMarker');
    return labelStart
  }
  /** @type {State} */

  function labelStart(code) {
    if (code === 94) {
      effects.enter('gfmFootnoteDefinitionMarker');
      effects.consume(code);
      effects.exit('gfmFootnoteDefinitionMarker');
      effects.enter('gfmFootnoteDefinitionLabelString');
      return atBreak
    }

    return nok(code)
  }
  /** @type {State} */

  function atBreak(code) {
    /** @type {Token} */
    let token;

    if (code === null || code === 91 || size > 999) {
      return nok(code)
    }

    if (code === 93) {
      if (!data) {
        return nok(code)
      }

      token = effects.exit('gfmFootnoteDefinitionLabelString');
      identifier = normalizeIdentifier(self.sliceSerialize(token));
      effects.enter('gfmFootnoteDefinitionLabelMarker');
      effects.consume(code);
      effects.exit('gfmFootnoteDefinitionLabelMarker');
      effects.exit('gfmFootnoteDefinitionLabel');
      return labelAfter
    }

    if (markdownLineEnding(code)) {
      effects.enter('lineEnding');
      effects.consume(code);
      effects.exit('lineEnding');
      size++;
      return atBreak
    }

    effects.enter('chunkString').contentType = 'string';
    return label(code)
  }
  /** @type {State} */

  function label(code) {
    if (
      code === null ||
      markdownLineEnding(code) ||
      code === 91 ||
      code === 93 ||
      size > 999
    ) {
      effects.exit('chunkString');
      return atBreak(code)
    }

    if (!markdownLineEndingOrSpace(code)) {
      data = true;
    }

    size++;
    effects.consume(code);
    return code === 92 ? labelEscape : label
  }
  /** @type {State} */

  function labelEscape(code) {
    if (code === 91 || code === 92 || code === 93) {
      effects.consume(code);
      size++;
      return label
    }

    return label(code)
  }
  /** @type {State} */

  function labelAfter(code) {
    if (code === 58) {
      effects.enter('definitionMarker');
      effects.consume(code);
      effects.exit('definitionMarker'); // Any whitespace after the marker is eaten, forming indented code
      // is not possible.
      // No space is also fine, just like a block quote marker.

      return factorySpace(effects, done, 'gfmFootnoteDefinitionWhitespace')
    }

    return nok(code)
  }
  /** @type {State} */

  function done(code) {
    if (!defined.includes(identifier)) {
      defined.push(identifier);
    }

    return ok(code)
  }
}
/** @type {Tokenizer} */

function tokenizeDefinitionContinuation(effects, ok, nok) {
  // Either a blank line, which is okay, or an indented thing.
  return effects.check(blankLine, ok, effects.attempt(indent, ok, nok))
}
/** @type {Exiter} */

function gfmFootnoteDefinitionEnd(effects) {
  effects.exit('gfmFootnoteDefinition');
}
/** @type {Tokenizer} */

function tokenizeIndent(effects, ok, nok) {
  const self = this;
  return factorySpace(
    effects,
    afterPrefix,
    'gfmFootnoteDefinitionIndent',
    4 + 1
  )
  /** @type {State} */

  function afterPrefix(code) {
    const tail = self.events[self.events.length - 1];
    return tail &&
      tail[1].type === 'gfmFootnoteDefinitionIndent' &&
      tail[2].sliceSerialize(tail[1], true).length === 4
      ? ok(code)
      : nok(code)
  }
}

/**
 * @typedef {import('micromark-util-types').Extension} Extension
 * @typedef {import('micromark-util-types').Resolver} Resolver
 * @typedef {import('micromark-util-types').Tokenizer} Tokenizer
 * @typedef {import('micromark-util-types').State} State
 * @typedef {import('micromark-util-types').Token} Token
 * @typedef {import('micromark-util-types').Event} Event
 */

/**
 * @param {Options} [options]
 * @returns {Extension}
 */
function gfmStrikethrough(options = {}) {
  let single = options.singleTilde;
  const tokenizer = {
    tokenize: tokenizeStrikethrough,
    resolveAll: resolveAllStrikethrough
  };

  if (single === null || single === undefined) {
    single = true;
  }

  return {
    text: {
      [126]: tokenizer
    },
    insideSpan: {
      null: [tokenizer]
    },
    attentionMarkers: {
      null: [126]
    }
  }
  /**
   * Take events and resolve strikethrough.
   *
   * @type {Resolver}
   */

  function resolveAllStrikethrough(events, context) {
    let index = -1; // Walk through all events.

    while (++index < events.length) {
      // Find a token that can close.
      if (
        events[index][0] === 'enter' &&
        events[index][1].type === 'strikethroughSequenceTemporary' &&
        events[index][1]._close
      ) {
        let open = index; // Now walk back to find an opener.

        while (open--) {
          // Find a token that can open the closer.
          if (
            events[open][0] === 'exit' &&
            events[open][1].type === 'strikethroughSequenceTemporary' &&
            events[open][1]._open && // If the sizes are the same:
            events[index][1].end.offset - events[index][1].start.offset ===
              events[open][1].end.offset - events[open][1].start.offset
          ) {
            events[index][1].type = 'strikethroughSequence';
            events[open][1].type = 'strikethroughSequence';
            const strikethrough = {
              type: 'strikethrough',
              start: Object.assign({}, events[open][1].start),
              end: Object.assign({}, events[index][1].end)
            };
            const text = {
              type: 'strikethroughText',
              start: Object.assign({}, events[open][1].end),
              end: Object.assign({}, events[index][1].start)
            }; // Opening.

            const nextEvents = [
              ['enter', strikethrough, context],
              ['enter', events[open][1], context],
              ['exit', events[open][1], context],
              ['enter', text, context]
            ]; // Between.

            splice(
              nextEvents,
              nextEvents.length,
              0,
              resolveAll(
                context.parser.constructs.insideSpan.null,
                events.slice(open + 1, index),
                context
              )
            ); // Closing.

            splice(nextEvents, nextEvents.length, 0, [
              ['exit', text, context],
              ['enter', events[index][1], context],
              ['exit', events[index][1], context],
              ['exit', strikethrough, context]
            ]);
            splice(events, open - 1, index - open + 3, nextEvents);
            index = open + nextEvents.length - 2;
            break
          }
        }
      }
    }

    index = -1;

    while (++index < events.length) {
      if (events[index][1].type === 'strikethroughSequenceTemporary') {
        events[index][1].type = 'data';
      }
    }

    return events
  }
  /** @type {Tokenizer} */

  function tokenizeStrikethrough(effects, ok, nok) {
    const previous = this.previous;
    const events = this.events;
    let size = 0;
    return start
    /** @type {State} */

    function start(code) {
      if (
        previous === 126 &&
        events[events.length - 1][1].type !== 'characterEscape'
      ) {
        return nok(code)
      }

      effects.enter('strikethroughSequenceTemporary');
      return more(code)
    }
    /** @type {State} */

    function more(code) {
      const before = classifyCharacter(previous);

      if (code === 126) {
        // If this is the third marker, exit.
        if (size > 1) return nok(code)
        effects.consume(code);
        size++;
        return more
      }

      if (size < 2 && !single) return nok(code)
      const token = effects.exit('strikethroughSequenceTemporary');
      const after = classifyCharacter(code);
      token._open = !after || (after === 2 && Boolean(before));
      token._close = !before || (before === 2 && Boolean(after));
      return ok(code)
    }
  }
}

/**
 * @typedef {import('micromark-util-types').Extension} Extension
 * @typedef {import('micromark-util-types').Resolver} Resolver
 * @typedef {import('micromark-util-types').Tokenizer} Tokenizer
 * @typedef {import('micromark-util-types').State} State
 * @typedef {import('micromark-util-types').Token} Token
 */

/** @type {Extension} */
const gfmTable = {
  flow: {
    null: {
      tokenize: tokenizeTable,
      resolve: resolveTable
    }
  }
};
const nextPrefixedOrBlank = {
  tokenize: tokenizeNextPrefixedOrBlank,
  partial: true
};
/** @type {Resolver} */

function resolveTable(events, context) {
  let index = -1;
  /** @type {boolean|undefined} */

  let inHead;
  /** @type {boolean|undefined} */

  let inDelimiterRow;
  /** @type {boolean|undefined} */

  let inRow;
  /** @type {number|undefined} */

  let contentStart;
  /** @type {number|undefined} */

  let contentEnd;
  /** @type {number|undefined} */

  let cellStart;
  /** @type {boolean|undefined} */

  let seenCellInRow;

  while (++index < events.length) {
    const token = events[index][1];

    if (inRow) {
      if (token.type === 'temporaryTableCellContent') {
        contentStart = contentStart || index;
        contentEnd = index;
      }

      if (
        // Combine separate content parts into one.
        (token.type === 'tableCellDivider' || token.type === 'tableRow') &&
        contentEnd
      ) {
        const content = {
          type: 'tableContent',
          start: events[contentStart][1].start,
          end: events[contentEnd][1].end
        };
        /** @type {Token} */

        const text = {
          type: 'chunkText',
          start: content.start,
          end: content.end,
          // @ts-expect-error It‚Äôs fine.
          contentType: 'text'
        };
        events.splice(
          contentStart,
          contentEnd - contentStart + 1,
          ['enter', content, context],
          ['enter', text, context],
          ['exit', text, context],
          ['exit', content, context]
        );
        index -= contentEnd - contentStart - 3;
        contentStart = undefined;
        contentEnd = undefined;
      }
    }

    if (
      events[index][0] === 'exit' &&
      cellStart !== undefined &&
      cellStart + (seenCellInRow ? 0 : 1) < index &&
      (token.type === 'tableCellDivider' ||
        (token.type === 'tableRow' &&
          (cellStart + 3 < index ||
            events[cellStart][1].type !== 'whitespace')))
    ) {
      const cell = {
        type: inDelimiterRow
          ? 'tableDelimiter'
          : inHead
          ? 'tableHeader'
          : 'tableData',
        start: events[cellStart][1].start,
        end: events[index][1].end
      };
      events.splice(index + (token.type === 'tableCellDivider' ? 1 : 0), 0, [
        'exit',
        cell,
        context
      ]);
      events.splice(cellStart, 0, ['enter', cell, context]);
      index += 2;
      cellStart = index + 1;
      seenCellInRow = true;
    }

    if (token.type === 'tableRow') {
      inRow = events[index][0] === 'enter';

      if (inRow) {
        cellStart = index + 1;
        seenCellInRow = false;
      }
    }

    if (token.type === 'tableDelimiterRow') {
      inDelimiterRow = events[index][0] === 'enter';

      if (inDelimiterRow) {
        cellStart = index + 1;
        seenCellInRow = false;
      }
    }

    if (token.type === 'tableHead') {
      inHead = events[index][0] === 'enter';
    }
  }

  return events
}
/** @type {Tokenizer} */

function tokenizeTable(effects, ok, nok) {
  const self = this;
  /** @type {Array<Align>} */

  const align = [];
  let tableHeaderCount = 0;
  /** @type {boolean|undefined} */

  let seenDelimiter;
  /** @type {boolean|undefined} */

  let hasDash;
  return start
  /** @type {State} */

  function start(code) {
    // @ts-expect-error Custom.
    effects.enter('table')._align = align;
    effects.enter('tableHead');
    effects.enter('tableRow'); // If we start with a pipe, we open a cell marker.

    if (code === 124) {
      return cellDividerHead(code)
    }

    tableHeaderCount++;
    effects.enter('temporaryTableCellContent'); // Can‚Äôt be space or eols at the start of a construct, so we‚Äôre in a cell.

    return inCellContentHead(code)
  }
  /** @type {State} */

  function cellDividerHead(code) {
    effects.enter('tableCellDivider');
    effects.consume(code);
    effects.exit('tableCellDivider');
    seenDelimiter = true;
    return cellBreakHead
  }
  /** @type {State} */

  function cellBreakHead(code) {
    if (code === null || markdownLineEnding(code)) {
      return atRowEndHead(code)
    }

    if (markdownSpace(code)) {
      effects.enter('whitespace');
      effects.consume(code);
      return inWhitespaceHead
    }

    if (seenDelimiter) {
      seenDelimiter = undefined;
      tableHeaderCount++;
    }

    if (code === 124) {
      return cellDividerHead(code)
    } // Anything else is cell content.

    effects.enter('temporaryTableCellContent');
    return inCellContentHead(code)
  }
  /** @type {State} */

  function inWhitespaceHead(code) {
    if (markdownSpace(code)) {
      effects.consume(code);
      return inWhitespaceHead
    }

    effects.exit('whitespace');
    return cellBreakHead(code)
  }
  /** @type {State} */

  function inCellContentHead(code) {
    // EOF, whitespace, pipe
    if (code === null || code === 124 || markdownLineEndingOrSpace(code)) {
      effects.exit('temporaryTableCellContent');
      return cellBreakHead(code)
    }

    effects.consume(code);
    return code === 92 ? inCellContentEscapeHead : inCellContentHead
  }
  /** @type {State} */

  function inCellContentEscapeHead(code) {
    if (code === 92 || code === 124) {
      effects.consume(code);
      return inCellContentHead
    } // Anything else.

    return inCellContentHead(code)
  }
  /** @type {State} */

  function atRowEndHead(code) {
    if (code === null) {
      return nok(code)
    }

    effects.exit('tableRow');
    effects.exit('tableHead');
    const originalInterrupt = self.interrupt;
    self.interrupt = true;
    return effects.attempt(
      {
        tokenize: tokenizeRowEnd,
        partial: true
      },
      function (code) {
        self.interrupt = originalInterrupt;
        effects.enter('tableDelimiterRow');
        return atDelimiterRowBreak(code)
      },
      function (code) {
        self.interrupt = originalInterrupt;
        return nok(code)
      }
    )(code)
  }
  /** @type {State} */

  function atDelimiterRowBreak(code) {
    if (code === null || markdownLineEnding(code)) {
      return rowEndDelimiter(code)
    }

    if (markdownSpace(code)) {
      effects.enter('whitespace');
      effects.consume(code);
      return inWhitespaceDelimiter
    }

    if (code === 45) {
      effects.enter('tableDelimiterFiller');
      effects.consume(code);
      hasDash = true;
      align.push('none');
      return inFillerDelimiter
    }

    if (code === 58) {
      effects.enter('tableDelimiterAlignment');
      effects.consume(code);
      effects.exit('tableDelimiterAlignment');
      align.push('left');
      return afterLeftAlignment
    } // If we start with a pipe, we open a cell marker.

    if (code === 124) {
      effects.enter('tableCellDivider');
      effects.consume(code);
      effects.exit('tableCellDivider');
      return atDelimiterRowBreak
    }

    return nok(code)
  }
  /** @type {State} */

  function inWhitespaceDelimiter(code) {
    if (markdownSpace(code)) {
      effects.consume(code);
      return inWhitespaceDelimiter
    }

    effects.exit('whitespace');
    return atDelimiterRowBreak(code)
  }
  /** @type {State} */

  function inFillerDelimiter(code) {
    if (code === 45) {
      effects.consume(code);
      return inFillerDelimiter
    }

    effects.exit('tableDelimiterFiller');

    if (code === 58) {
      effects.enter('tableDelimiterAlignment');
      effects.consume(code);
      effects.exit('tableDelimiterAlignment');
      align[align.length - 1] =
        align[align.length - 1] === 'left' ? 'center' : 'right';
      return afterRightAlignment
    }

    return atDelimiterRowBreak(code)
  }
  /** @type {State} */

  function afterLeftAlignment(code) {
    if (code === 45) {
      effects.enter('tableDelimiterFiller');
      effects.consume(code);
      hasDash = true;
      return inFillerDelimiter
    } // Anything else is not ok.

    return nok(code)
  }
  /** @type {State} */

  function afterRightAlignment(code) {
    if (code === null || markdownLineEnding(code)) {
      return rowEndDelimiter(code)
    }

    if (markdownSpace(code)) {
      effects.enter('whitespace');
      effects.consume(code);
      return inWhitespaceDelimiter
    } // `|`

    if (code === 124) {
      effects.enter('tableCellDivider');
      effects.consume(code);
      effects.exit('tableCellDivider');
      return atDelimiterRowBreak
    }

    return nok(code)
  }
  /** @type {State} */

  function rowEndDelimiter(code) {
    effects.exit('tableDelimiterRow'); // Exit if there was no dash at all, or if the header cell count is not the
    // delimiter cell count.

    if (!hasDash || tableHeaderCount !== align.length) {
      return nok(code)
    }

    if (code === null) {
      return tableClose(code)
    }

    return effects.check(
      nextPrefixedOrBlank,
      tableClose,
      effects.attempt(
        {
          tokenize: tokenizeRowEnd,
          partial: true
        },
        factorySpace(effects, bodyStart, 'linePrefix', 4),
        tableClose
      )
    )(code)
  }
  /** @type {State} */

  function tableClose(code) {
    effects.exit('table');
    return ok(code)
  }
  /** @type {State} */

  function bodyStart(code) {
    effects.enter('tableBody');
    return rowStartBody(code)
  }
  /** @type {State} */

  function rowStartBody(code) {
    effects.enter('tableRow'); // If we start with a pipe, we open a cell marker.

    if (code === 124) {
      return cellDividerBody(code)
    }

    effects.enter('temporaryTableCellContent'); // Can‚Äôt be space or eols at the start of a construct, so we‚Äôre in a cell.

    return inCellContentBody(code)
  }
  /** @type {State} */

  function cellDividerBody(code) {
    effects.enter('tableCellDivider');
    effects.consume(code);
    effects.exit('tableCellDivider');
    return cellBreakBody
  }
  /** @type {State} */

  function cellBreakBody(code) {
    if (code === null || markdownLineEnding(code)) {
      return atRowEndBody(code)
    }

    if (markdownSpace(code)) {
      effects.enter('whitespace');
      effects.consume(code);
      return inWhitespaceBody
    } // `|`

    if (code === 124) {
      return cellDividerBody(code)
    } // Anything else is cell content.

    effects.enter('temporaryTableCellContent');
    return inCellContentBody(code)
  }
  /** @type {State} */

  function inWhitespaceBody(code) {
    if (markdownSpace(code)) {
      effects.consume(code);
      return inWhitespaceBody
    }

    effects.exit('whitespace');
    return cellBreakBody(code)
  }
  /** @type {State} */

  function inCellContentBody(code) {
    // EOF, whitespace, pipe
    if (code === null || code === 124 || markdownLineEndingOrSpace(code)) {
      effects.exit('temporaryTableCellContent');
      return cellBreakBody(code)
    }

    effects.consume(code);
    return code === 92 ? inCellContentEscapeBody : inCellContentBody
  }
  /** @type {State} */

  function inCellContentEscapeBody(code) {
    if (code === 92 || code === 124) {
      effects.consume(code);
      return inCellContentBody
    } // Anything else.

    return inCellContentBody(code)
  }
  /** @type {State} */

  function atRowEndBody(code) {
    effects.exit('tableRow');

    if (code === null) {
      return tableBodyClose(code)
    }

    return effects.check(
      nextPrefixedOrBlank,
      tableBodyClose,
      effects.attempt(
        {
          tokenize: tokenizeRowEnd,
          partial: true
        },
        factorySpace(effects, rowStartBody, 'linePrefix', 4),
        tableBodyClose
      )
    )(code)
  }
  /** @type {State} */

  function tableBodyClose(code) {
    effects.exit('tableBody');
    return tableClose(code)
  }
  /** @type {Tokenizer} */

  function tokenizeRowEnd(effects, ok, nok) {
    return start
    /** @type {State} */

    function start(code) {
      effects.enter('lineEnding');
      effects.consume(code);
      effects.exit('lineEnding');
      return factorySpace(effects, prefixed, 'linePrefix')
    }
    /** @type {State} */

    function prefixed(code) {
      // Blank or interrupting line.
      if (
        self.parser.lazy[self.now().line] ||
        code === null ||
        markdownLineEnding(code)
      ) {
        return nok(code)
      }

      const tail = self.events[self.events.length - 1]; // Indented code can interrupt delimiter and body rows.

      if (
        !self.parser.constructs.disable.null.includes('codeIndented') &&
        tail &&
        tail[1].type === 'linePrefix' &&
        tail[2].sliceSerialize(tail[1], true).length >= 4
      ) {
        return nok(code)
      }

      self._gfmTableDynamicInterruptHack = true;
      return effects.check(
        self.parser.constructs.flow,
        function (code) {
          self._gfmTableDynamicInterruptHack = false;
          return nok(code)
        },
        function (code) {
          self._gfmTableDynamicInterruptHack = false;
          return ok(code)
        }
      )(code)
    }
  }
}
/** @type {Tokenizer} */

function tokenizeNextPrefixedOrBlank(effects, ok, nok) {
  let size = 0;
  return start
  /** @type {State} */

  function start(code) {
    // This is a check, so we don‚Äôt care about tokens, but we open a bogus one
    // so we‚Äôre valid.
    effects.enter('check'); // EOL.

    effects.consume(code);
    return whitespace
  }
  /** @type {State} */

  function whitespace(code) {
    if (code === -1 || code === 32) {
      effects.consume(code);
      size++;
      return size === 4 ? ok : whitespace
    } // EOF or whitespace

    if (code === null || markdownLineEndingOrSpace(code)) {
      return ok(code)
    } // Anything else.

    return nok(code)
  }
}

/**
 * @typedef {import('micromark-util-types').Extension} Extension
 * @typedef {import('micromark-util-types').ConstructRecord} ConstructRecord
 * @typedef {import('micromark-util-types').Tokenizer} Tokenizer
 * @typedef {import('micromark-util-types').Previous} Previous
 * @typedef {import('micromark-util-types').State} State
 * @typedef {import('micromark-util-types').Event} Event
 * @typedef {import('micromark-util-types').Code} Code
 */
const tasklistCheck = {
  tokenize: tokenizeTasklistCheck
};
const gfmTaskListItem = {
  text: {
    [91]: tasklistCheck
  }
};
/** @type {Tokenizer} */

function tokenizeTasklistCheck(effects, ok, nok) {
  const self = this;
  return open
  /** @type {State} */

  function open(code) {
    if (
      // Exit if there‚Äôs stuff before.
      self.previous !== null || // Exit if not in the first content that is the first child of a list
      // item.
      !self._gfmTasklistFirstContentOfListItem
    ) {
      return nok(code)
    }

    effects.enter('taskListCheck');
    effects.enter('taskListCheckMarker');
    effects.consume(code);
    effects.exit('taskListCheckMarker');
    return inside
  }
  /** @type {State} */

  function inside(code) {
    // To match how GH works in comments, use `markdownSpace` (`[ \t]`) instead
    // of `markdownLineEndingOrSpace` (`[ \t\r\n]`).
    if (markdownLineEndingOrSpace(code)) {
      effects.enter('taskListCheckValueUnchecked');
      effects.consume(code);
      effects.exit('taskListCheckValueUnchecked');
      return close
    }

    if (code === 88 || code === 120) {
      effects.enter('taskListCheckValueChecked');
      effects.consume(code);
      effects.exit('taskListCheckValueChecked');
      return close
    }

    return nok(code)
  }
  /** @type {State} */

  function close(code) {
    if (code === 93) {
      effects.enter('taskListCheckMarker');
      effects.consume(code);
      effects.exit('taskListCheckMarker');
      effects.exit('taskListCheck');
      return effects.check(
        {
          tokenize: spaceThenNonSpace
        },
        ok,
        nok
      )
    }

    return nok(code)
  }
}
/** @type {Tokenizer} */

function spaceThenNonSpace(effects, ok, nok) {
  const self = this;
  return factorySpace(effects, after, 'whitespace')
  /** @type {State} */

  function after(code) {
    const tail = self.events[self.events.length - 1];
    return (
      // We either found spaces‚Ä¶
      ((tail && tail[1].type === 'whitespace') || // ‚Ä¶or it was followed by a line ending, in which case, there has to be
        // non-whitespace after that line ending, because otherwise we‚Äôd get an
        // EOF as the content is closed with blank lines.
        markdownLineEnding(code)) &&
        code !== null
        ? ok(code)
        : nok(code)
    )
  }
}

/**
 * @typedef {import('micromark-util-types').Extension} Extension
 * @typedef {import('micromark-util-types').HtmlExtension} HtmlExtension
 * @typedef {import('micromark-extension-gfm-strikethrough').Options} Options
 * @typedef {import('micromark-extension-gfm-footnote').HtmlOptions} HtmlOptions
 */

/**
 * Support GFM or markdown on github.com.
 *
 * @param {Options} [options]
 * @returns {Extension}
 */
function gfm(options) {
  return combineExtensions([
    gfmAutolinkLiteral,
    gfmFootnote(),
    gfmStrikethrough(options),
    gfmTable,
    gfmTaskListItem
  ])
}

/**
 * Count how often a character (or substring) is used in a string.
 *
 * @param {string} value
 *   Value to search in.
 * @param {string} character
 *   Character (or substring) to look for.
 * @return {number}
 *   Number of times `character` occurred in `value`.
 */
function ccount(value, character) {
  const source = String(value);

  if (typeof character !== 'string') {
    throw new TypeError('Expected character')
  }

  let count = 0;
  let index = source.indexOf(character);

  while (index !== -1) {
    count++;
    index = source.indexOf(character, index + character.length);
  }

  return count
}

function escapeStringRegexp(string) {
	if (typeof string !== 'string') {
		throw new TypeError('Expected a string');
	}

	// Escape characters with special meaning either inside or outside character sets.
	// Use a simple backslash escape when it‚Äôs always valid, and a `\xnn` escape when the simpler form would be disallowed by Unicode patterns‚Äô stricter grammar.
	return string
		.replace(/[|\\{}()[\]^$+*?.]/g, '\\$&')
		.replace(/-/g, '\\x2d');
}

/**
 * @typedef {import('mdast').Parent} MdastParent
 * @typedef {import('mdast').Root} Root
 * @typedef {import('mdast').Content} Content
 * @typedef {import('mdast').PhrasingContent} PhrasingContent
 * @typedef {import('mdast').Text} Text
 * @typedef {import('unist-util-visit-parents').Test} Test
 * @typedef {import('unist-util-visit-parents').VisitorResult} VisitorResult
 */

const own$2 = {}.hasOwnProperty;

/**
 * Find patterns in a tree and replace them.
 *
 * The algorithm searches the tree in *preorder* for complete values in `Text`
 * nodes.
 * Partial matches are not supported.
 *
 * @param tree
 *   Tree to change.
 * @param find
 *   Patterns to find.
 * @param replace
 *   Things to replace with (when `find` is `Find`) or configuration.
 * @param options
 *   Configuration (when `find` is not `Find`).
 * @returns
 *   Given, modified, tree.
 */
// To do: next major: remove `find` & `replace` combo, remove schema.
const findAndReplace =
  /**
   * @type {(
   *   (<Tree extends Node>(tree: Tree, find: Find, replace?: Replace | null | undefined, options?: Options | null | undefined) => Tree) &
   *   (<Tree extends Node>(tree: Tree, schema: FindAndReplaceSchema | FindAndReplaceList, options?: Options | null | undefined) => Tree)
   * )}
   **/
  (
    /**
     * @template {Node} Tree
     * @param {Tree} tree
     * @param {Find | FindAndReplaceSchema | FindAndReplaceList} find
     * @param {Replace | Options | null | undefined} [replace]
     * @param {Options | null | undefined} [options]
     * @returns {Tree}
     */
    function (tree, find, replace, options) {
      /** @type {Options | null | undefined} */
      let settings;
      /** @type {FindAndReplaceSchema|FindAndReplaceList} */
      let schema;

      if (typeof find === 'string' || find instanceof RegExp) {
        // @ts-expect-error don‚Äôt expect options twice.
        schema = [[find, replace]];
        settings = options;
      } else {
        schema = find;
        // @ts-expect-error don‚Äôt expect replace twice.
        settings = replace;
      }

      if (!settings) {
        settings = {};
      }

      const ignored = convert(settings.ignore || []);
      const pairs = toPairs(schema);
      let pairIndex = -1;

      while (++pairIndex < pairs.length) {
        visitParents(tree, 'text', visitor);
      }

      // To do next major: don‚Äôt return the given tree.
      return tree

      /** @type {import('unist-util-visit-parents/complex-types.js').BuildVisitor<Root, 'text'>} */
      function visitor(node, parents) {
        let index = -1;
        /** @type {Parent | undefined} */
        let grandparent;

        while (++index < parents.length) {
          const parent = parents[index];

          if (
            ignored(
              parent,
              // @ts-expect-error: TS doesn‚Äôt understand but it‚Äôs perfect.
              grandparent ? grandparent.children.indexOf(parent) : undefined,
              grandparent
            )
          ) {
            return
          }

          grandparent = parent;
        }

        if (grandparent) {
          return handler(node, parents)
        }
      }

      /**
       * Handle a text node which is not in an ignored parent.
       *
       * @param {Text} node
       *   Text node.
       * @param {Array<Parent>} parents
       *   Parents.
       * @returns {VisitorResult}
       *   Result.
       */
      function handler(node, parents) {
        const parent = parents[parents.length - 1];
        const find = pairs[pairIndex][0];
        const replace = pairs[pairIndex][1];
        let start = 0;
        // @ts-expect-error: TS is wrong, some of these children can be text.
        const index = parent.children.indexOf(node);
        let change = false;
        /** @type {Array<PhrasingContent>} */
        let nodes = [];

        find.lastIndex = 0;

        let match = find.exec(node.value);

        while (match) {
          const position = match.index;
          /** @type {RegExpMatchObject} */
          const matchObject = {
            index: match.index,
            input: match.input,
            // @ts-expect-error: stack is fine.
            stack: [...parents, node]
          };
          let value = replace(...match, matchObject);

          if (typeof value === 'string') {
            value = value.length > 0 ? {type: 'text', value} : undefined;
          }

          // It wasn‚Äôt a match after all.
          if (value !== false) {
            if (start !== position) {
              nodes.push({
                type: 'text',
                value: node.value.slice(start, position)
              });
            }

            if (Array.isArray(value)) {
              nodes.push(...value);
            } else if (value) {
              nodes.push(value);
            }

            start = position + match[0].length;
            change = true;
          }

          if (!find.global) {
            break
          }

          match = find.exec(node.value);
        }

        if (change) {
          if (start < node.value.length) {
            nodes.push({type: 'text', value: node.value.slice(start)});
          }

          parent.children.splice(index, 1, ...nodes);
        } else {
          nodes = [node];
        }

        return index + nodes.length
      }
    }
  );

/**
 * Turn a schema into pairs.
 *
 * @param {FindAndReplaceSchema | FindAndReplaceList} schema
 *   Schema.
 * @returns {Pairs}
 *   Clean pairs.
 */
function toPairs(schema) {
  /** @type {Pairs} */
  const result = [];

  if (typeof schema !== 'object') {
    throw new TypeError('Expected array or object as schema')
  }

  if (Array.isArray(schema)) {
    let index = -1;

    while (++index < schema.length) {
      result.push([
        toExpression(schema[index][0]),
        toFunction(schema[index][1])
      ]);
    }
  } else {
    /** @type {string} */
    let key;

    for (key in schema) {
      if (own$2.call(schema, key)) {
        result.push([toExpression(key), toFunction(schema[key])]);
      }
    }
  }

  return result
}

/**
 * Turn a find into an expression.
 *
 * @param {Find} find
 *   Find.
 * @returns {RegExp}
 *   Expression.
 */
function toExpression(find) {
  return typeof find === 'string' ? new RegExp(escapeStringRegexp(find), 'g') : find
}

/**
 * Turn a replace into a function.
 *
 * @param {Replace} replace
 *   Replace.
 * @returns {ReplaceFunction}
 *   Function.
 */
function toFunction(replace) {
  return typeof replace === 'function' ? replace : () => replace
}

/**
 * @typedef {import('mdast').Link} Link
 * @typedef {import('mdast').PhrasingContent} PhrasingContent
 *
 * @typedef {import('mdast-util-from-markdown').CompileContext} CompileContext
 * @typedef {import('mdast-util-from-markdown').Extension} FromMarkdownExtension
 * @typedef {import('mdast-util-from-markdown').Handle} FromMarkdownHandle
 * @typedef {import('mdast-util-from-markdown').Transform} FromMarkdownTransform
 *
 * @typedef {import('mdast-util-to-markdown').ConstructName} ConstructName
 * @typedef {import('mdast-util-to-markdown').Options} ToMarkdownExtension
 *
 * @typedef {import('mdast-util-find-and-replace').ReplaceFunction} ReplaceFunction
 * @typedef {import('mdast-util-find-and-replace').RegExpMatchObject} RegExpMatchObject
 */

/** @type {ConstructName} */
const inConstruct = 'phrasing';
/** @type {Array<ConstructName>} */
const notInConstruct = ['autolink', 'link', 'image', 'label'];

// To do: next major: expose functions instead of extensions.

/**
 * Extension for `mdast-util-from-markdown` to enable GFM autolink literals.
 *
 * @type {FromMarkdownExtension}
 */
const gfmAutolinkLiteralFromMarkdown = {
  transforms: [transformGfmAutolinkLiterals],
  enter: {
    literalAutolink: enterLiteralAutolink,
    literalAutolinkEmail: enterLiteralAutolinkValue,
    literalAutolinkHttp: enterLiteralAutolinkValue,
    literalAutolinkWww: enterLiteralAutolinkValue
  },
  exit: {
    literalAutolink: exitLiteralAutolink,
    literalAutolinkEmail: exitLiteralAutolinkEmail,
    literalAutolinkHttp: exitLiteralAutolinkHttp,
    literalAutolinkWww: exitLiteralAutolinkWww
  }
};

/**
 * Extension for `mdast-util-to-markdown` to enable GFM autolink literals.
 *
 * @type {ToMarkdownExtension}
 */
const gfmAutolinkLiteralToMarkdown = {
  unsafe: [
    {
      character: '@',
      before: '[+\\-.\\w]',
      after: '[\\-.\\w]',
      inConstruct,
      notInConstruct
    },
    {
      character: '.',
      before: '[Ww]',
      after: '[\\-.\\w]',
      inConstruct,
      notInConstruct
    },
    {character: ':', before: '[ps]', after: '\\/', inConstruct, notInConstruct}
  ]
};

/**
 * @this {CompileContext}
 * @type {FromMarkdownHandle}
 */
function enterLiteralAutolink(token) {
  this.enter({type: 'link', title: null, url: '', children: []}, token);
}

/**
 * @this {CompileContext}
 * @type {FromMarkdownHandle}
 */
function enterLiteralAutolinkValue(token) {
  this.config.enter.autolinkProtocol.call(this, token);
}

/**
 * @this {CompileContext}
 * @type {FromMarkdownHandle}
 */
function exitLiteralAutolinkHttp(token) {
  this.config.exit.autolinkProtocol.call(this, token);
}

/**
 * @this {CompileContext}
 * @type {FromMarkdownHandle}
 */
function exitLiteralAutolinkWww(token) {
  this.config.exit.data.call(this, token);
  const node = /** @type {Link} */ (this.stack[this.stack.length - 1]);
  node.url = 'http://' + this.sliceSerialize(token);
}

/**
 * @this {CompileContext}
 * @type {FromMarkdownHandle}
 */
function exitLiteralAutolinkEmail(token) {
  this.config.exit.autolinkEmail.call(this, token);
}

/**
 * @this {CompileContext}
 * @type {FromMarkdownHandle}
 */
function exitLiteralAutolink(token) {
  this.exit(token);
}

/** @type {FromMarkdownTransform} */
function transformGfmAutolinkLiterals(tree) {
  findAndReplace(
    tree,
    [
      [/(https?:\/\/|www(?=\.))([-.\w]+)([^ \t\r\n]*)/gi, findUrl],
      [/([-.\w+]+)@([-\w]+(?:\.[-\w]+)+)/g, findEmail]
    ],
    {ignore: ['link', 'linkReference']}
  );
}

/**
 * @type {ReplaceFunction}
 * @param {string} _
 * @param {string} protocol
 * @param {string} domain
 * @param {string} path
 * @param {RegExpMatchObject} match
 * @returns {Link | Array<PhrasingContent> | false}
 */
// eslint-disable-next-line max-params
function findUrl(_, protocol, domain, path, match) {
  let prefix = '';

  // Not an expected previous character.
  if (!previous$1(match)) {
    return false
  }

  // Treat `www` as part of the domain.
  if (/^w/i.test(protocol)) {
    domain = protocol + domain;
    protocol = '';
    prefix = 'http://';
  }

  if (!isCorrectDomain(domain)) {
    return false
  }

  const parts = splitUrl(domain + path);

  if (!parts[0]) return false

  /** @type {Link} */
  const result = {
    type: 'link',
    title: null,
    url: prefix + protocol + parts[0],
    children: [{type: 'text', value: protocol + parts[0]}]
  };

  if (parts[1]) {
    return [result, {type: 'text', value: parts[1]}]
  }

  return result
}

/**
 * @type {ReplaceFunction}
 * @param {string} _
 * @param {string} atext
 * @param {string} label
 * @param {RegExpMatchObject} match
 * @returns {Link | false}
 */
function findEmail(_, atext, label, match) {
  if (
    // Not an expected previous character.
    !previous$1(match, true) ||
    // Label ends in not allowed character.
    /[-\d_]$/.test(label)
  ) {
    return false
  }

  return {
    type: 'link',
    title: null,
    url: 'mailto:' + atext + '@' + label,
    children: [{type: 'text', value: atext + '@' + label}]
  }
}

/**
 * @param {string} domain
 * @returns {boolean}
 */
function isCorrectDomain(domain) {
  const parts = domain.split('.');

  if (
    parts.length < 2 ||
    (parts[parts.length - 1] &&
      (/_/.test(parts[parts.length - 1]) ||
        !/[a-zA-Z\d]/.test(parts[parts.length - 1]))) ||
    (parts[parts.length - 2] &&
      (/_/.test(parts[parts.length - 2]) ||
        !/[a-zA-Z\d]/.test(parts[parts.length - 2])))
  ) {
    return false
  }

  return true
}

/**
 * @param {string} url
 * @returns {[string, string | undefined]}
 */
function splitUrl(url) {
  const trailExec = /[!"&'),.:;<>?\]}]+$/.exec(url);

  if (!trailExec) {
    return [url, undefined]
  }

  url = url.slice(0, trailExec.index);

  let trail = trailExec[0];
  let closingParenIndex = trail.indexOf(')');
  const openingParens = ccount(url, '(');
  let closingParens = ccount(url, ')');

  while (closingParenIndex !== -1 && openingParens > closingParens) {
    url += trail.slice(0, closingParenIndex + 1);
    trail = trail.slice(closingParenIndex + 1);
    closingParenIndex = trail.indexOf(')');
    closingParens++;
  }

  return [url, trail]
}

/**
 * @param {RegExpMatchObject} match
 * @param {boolean | null | undefined} [email=false]
 * @returns {boolean}
 */
function previous$1(match, email) {
  const code = match.input.charCodeAt(match.index - 1);

  return (
    (match.index === 0 ||
      unicodeWhitespace(code) ||
      unicodePunctuation(code)) &&
    (!email || code !== 47)
  )
}

/**
 * @typedef {import('../types.js').AssociationId} AssociationId
 */

/**
 * Get an identifier from an association to match it to others.
 *
 * Associations are nodes that match to something else through an ID:
 * <https://github.com/syntax-tree/mdast#association>.
 *
 * The `label` of an association is the string value: character escapes and
 * references work, and casing is intact.
 * The `identifier` is used to match one association to another:
 * controversially, character escapes and references don‚Äôt work in this
 * matching: `&copy;` does not match `¬©`, and `\+` does not match `+`.
 *
 * But casing is ignored (and whitespace) is trimmed and collapsed: ` A\nb`
 * matches `a b`.
 * So, we do prefer the label when figuring out how we‚Äôre going to serialize:
 * it has whitespace, casing, and we can ignore most useless character
 * escapes and all character references.
 *
 * @type {AssociationId}
 */
function association(node) {
  if (node.label || !node.identifier) {
    return node.label || ''
  }

  return decodeString(node.identifier)
}

/**
 * @typedef {import('../types.js').FlowContent} FlowContent
 * @typedef {import('../types.js').Node} Node
 * @typedef {import('../types.js').Parent} Parent
 * @typedef {import('../types.js').State} State
 * @typedef {import('../types.js').TrackFields} TrackFields
 */

/**
 * @param {Parent & {children: Array<FlowContent>}} parent
 *   Parent of flow nodes.
 * @param {State} state
 *   Info passed around about the current state.
 * @param {TrackFields} info
 *   Info on where we are in the document we are generating.
 * @returns {string}
 *   Serialized children, joined by (blank) lines.
 */
function containerFlow(parent, state, info) {
  const indexStack = state.indexStack;
  const children = parent.children || [];
  const tracker = state.createTracker(info);
  /** @type {Array<string>} */
  const results = [];
  let index = -1;

  indexStack.push(-1);

  while (++index < children.length) {
    const child = children[index];

    indexStack[indexStack.length - 1] = index;

    results.push(
      tracker.move(
        state.handle(child, parent, state, {
          before: '\n',
          after: '\n',
          ...tracker.current()
        })
      )
    );

    if (child.type !== 'list') {
      state.bulletLastUsed = undefined;
    }

    if (index < children.length - 1) {
      results.push(
        tracker.move(between(child, children[index + 1], parent, state))
      );
    }
  }

  indexStack.pop();

  return results.join('')
}

/**
 * @param {Node} left
 * @param {Node} right
 * @param {Parent} parent
 * @param {State} state
 * @returns {string}
 */
function between(left, right, parent, state) {
  let index = state.join.length;

  while (index--) {
    const result = state.join[index](left, right, parent, state);

    if (result === true || result === 1) {
      break
    }

    if (typeof result === 'number') {
      return '\n'.repeat(1 + result)
    }

    if (result === false) {
      return '\n\n<!---->\n\n'
    }
  }

  return '\n\n'
}

/**
 * @typedef {import('../types.js').IndentLines} IndentLines
 */

const eol = /\r?\n|\r/g;

/**
 * @type {IndentLines}
 */
function indentLines(value, map) {
  /** @type {Array<string>} */
  const result = [];
  let start = 0;
  let line = 0;
  /** @type {RegExpExecArray | null} */
  let match;

  while ((match = eol.exec(value))) {
    one(value.slice(start, match.index));
    result.push(match[0]);
    start = match.index + match[0].length;
    line++;
  }

  one(value.slice(start));

  return result.join('')

  /**
   * @param {string} value
   */
  function one(value) {
    result.push(map(value, line, !value));
  }
}

/**
 * @typedef {import('../types.js').Unsafe} Unsafe
 */

/**
 * @param {Unsafe} pattern
 * @returns {RegExp}
 */
function patternCompile(pattern) {
  if (!pattern._compiled) {
    const before =
      (pattern.atBreak ? '[\\r\\n][\\t ]*' : '') +
      (pattern.before ? '(?:' + pattern.before + ')' : '');

    pattern._compiled = new RegExp(
      (before ? '(' + before + ')' : '') +
        (/[|\\{}()[\]^$+*?.-]/.test(pattern.character) ? '\\' : '') +
        pattern.character +
        (pattern.after ? '(?:' + pattern.after + ')' : ''),
      'g'
    );
  }

  return pattern._compiled
}

/**
 * @typedef {import('../types.js').Unsafe} Unsafe
 * @typedef {import('../types.js').ConstructName} ConstructName
 */

/**
 * @param {Array<ConstructName>} stack
 * @param {Unsafe} pattern
 * @returns {boolean}
 */
function patternInScope(stack, pattern) {
  return (
    listInScope(stack, pattern.inConstruct, true) &&
    !listInScope(stack, pattern.notInConstruct, false)
  )
}

/**
 * @param {Array<ConstructName>} stack
 * @param {Unsafe['inConstruct']} list
 * @param {boolean} none
 * @returns {boolean}
 */
function listInScope(stack, list, none) {
  if (typeof list === 'string') {
    list = [list];
  }

  if (!list || list.length === 0) {
    return none
  }

  let index = -1;

  while (++index < list.length) {
    if (stack.includes(list[index])) {
      return true
    }
  }

  return false
}

/**
 * @typedef {import('../types.js').State} State
 * @typedef {import('../types.js').SafeConfig} SafeConfig
 */

/**
 * Make a string safe for embedding in markdown constructs.
 *
 * In markdown, almost all punctuation characters can, in certain cases,
 * result in something.
 * Whether they do is highly subjective to where they happen and in what
 * they happen.
 *
 * To solve this, `mdast-util-to-markdown` tracks:
 *
 * * Characters before and after something;
 * * What ‚Äúconstructs‚Äù we are in.
 *
 * This information is then used by this function to escape or encode
 * special characters.
 *
 * @param {State} state
 *   Info passed around about the current state.
 * @param {string | null | undefined} input
 *   Raw value to make safe.
 * @param {SafeConfig} config
 *   Configuration.
 * @returns {string}
 *   Serialized markdown safe for embedding.
 */
function safe(state, input, config) {
  const value = (config.before || '') + (input || '') + (config.after || '');
  /** @type {Array<number>} */
  const positions = [];
  /** @type {Array<string>} */
  const result = [];
  /** @type {Record<number, {before: boolean, after: boolean}>} */
  const infos = {};
  let index = -1;

  while (++index < state.unsafe.length) {
    const pattern = state.unsafe[index];

    if (!patternInScope(state.stack, pattern)) {
      continue
    }

    const expression = patternCompile(pattern);
    /** @type {RegExpExecArray | null} */
    let match;

    while ((match = expression.exec(value))) {
      const before = 'before' in pattern || Boolean(pattern.atBreak);
      const after = 'after' in pattern;
      const position = match.index + (before ? match[1].length : 0);

      if (positions.includes(position)) {
        if (infos[position].before && !before) {
          infos[position].before = false;
        }

        if (infos[position].after && !after) {
          infos[position].after = false;
        }
      } else {
        positions.push(position);
        infos[position] = {before, after};
      }
    }
  }

  positions.sort(numerical);

  let start = config.before ? config.before.length : 0;
  const end = value.length - (config.after ? config.after.length : 0);
  index = -1;

  while (++index < positions.length) {
    const position = positions[index];

    // Character before or after matched:
    if (position < start || position >= end) {
      continue
    }

    // If this character is supposed to be escaped because it has a condition on
    // the next character, and the next character is definitly being escaped,
    // then skip this escape.
    if (
      (position + 1 < end &&
        positions[index + 1] === position + 1 &&
        infos[position].after &&
        !infos[position + 1].before &&
        !infos[position + 1].after) ||
      (positions[index - 1] === position - 1 &&
        infos[position].before &&
        !infos[position - 1].before &&
        !infos[position - 1].after)
    ) {
      continue
    }

    if (start !== position) {
      // If we have to use a character reference, an ampersand would be more
      // correct, but as backslashes only care about punctuation, either will
      // do the trick
      result.push(escapeBackslashes(value.slice(start, position), '\\'));
    }

    start = position;

    if (
      /[!-/:-@[-`{-~]/.test(value.charAt(position)) &&
      (!config.encode || !config.encode.includes(value.charAt(position)))
    ) {
      // Character escape.
      result.push('\\');
    } else {
      // Character reference.
      result.push(
        '&#x' + value.charCodeAt(position).toString(16).toUpperCase() + ';'
      );
      start++;
    }
  }

  result.push(escapeBackslashes(value.slice(start, end), config.after));

  return result.join('')
}

/**
 * @param {number} a
 * @param {number} b
 * @returns {number}
 */
function numerical(a, b) {
  return a - b
}

/**
 * @param {string} value
 * @param {string} after
 * @returns {string}
 */
function escapeBackslashes(value, after) {
  const expression = /\\(?=[!-/:-@[-`{-~])/g;
  /** @type {Array<number>} */
  const positions = [];
  /** @type {Array<string>} */
  const results = [];
  const whole = value + after;
  let index = -1;
  let start = 0;
  /** @type {RegExpExecArray | null} */
  let match;

  while ((match = expression.exec(whole))) {
    positions.push(match.index);
  }

  while (++index < positions.length) {
    if (start !== positions[index]) {
      results.push(value.slice(start, positions[index]));
    }

    results.push('\\');
    start = positions[index];
  }

  results.push(value.slice(start));

  return results.join('')
}

/**
 * @typedef {import('../types.js').CreateTracker} CreateTracker
 * @typedef {import('../types.js').TrackCurrent} TrackCurrent
 * @typedef {import('../types.js').TrackMove} TrackMove
 * @typedef {import('../types.js').TrackShift} TrackShift
 */

/**
 * Track positional info in the output.
 *
 * @type {CreateTracker}
 */
function track(config) {
  // Defaults are used to prevent crashes when older utilities somehow activate
  // this code.
  /* c8 ignore next 5 */
  const options = config || {};
  const now = options.now || {};
  let lineShift = options.lineShift || 0;
  let line = now.line || 1;
  let column = now.column || 1;

  return {move, current, shift}

  /**
   * Get the current tracked info.
   *
   * @type {TrackCurrent}
   */
  function current() {
    return {now: {line, column}, lineShift}
  }

  /**
   * Define an increased line shift (the typical indent for lines).
   *
   * @type {TrackShift}
   */
  function shift(value) {
    lineShift += value;
  }

  /**
   * Move past some generated markdown.
   *
   * @type {TrackMove}
   */
  function move(input) {
    // eslint-disable-next-line unicorn/prefer-default-parameters
    const value = input || '';
    const chunks = value.split(/\r?\n|\r/g);
    const tail = chunks[chunks.length - 1];
    line += chunks.length - 1;
    column =
      chunks.length === 1 ? column + tail.length : 1 + tail.length + lineShift;
    return value
  }
}

/**
 * @typedef {import('mdast').FootnoteReference} FootnoteReference
 * @typedef {import('mdast').FootnoteDefinition} FootnoteDefinition
 * @typedef {import('mdast-util-from-markdown').CompileContext} CompileContext
 * @typedef {import('mdast-util-from-markdown').Extension} FromMarkdownExtension
 * @typedef {import('mdast-util-from-markdown').Handle} FromMarkdownHandle
 * @typedef {import('mdast-util-to-markdown').Options} ToMarkdownExtension
 * @typedef {import('mdast-util-to-markdown').Handle} ToMarkdownHandle
 * @typedef {import('mdast-util-to-markdown').Map} Map
 */

footnoteReference$1.peek = footnoteReferencePeek;

// To do: next major: rename `context` -> `state`, `safeOptions` to `info`, use
// utilities on `state`.

/**
 * Create an extension for `mdast-util-from-markdown` to enable GFM footnotes
 * in markdown.
 *
 * @returns {FromMarkdownExtension}
 *   Extension for `mdast-util-from-markdown`.
 */
function gfmFootnoteFromMarkdown() {
  return {
    enter: {
      gfmFootnoteDefinition: enterFootnoteDefinition,
      gfmFootnoteDefinitionLabelString: enterFootnoteDefinitionLabelString,
      gfmFootnoteCall: enterFootnoteCall,
      gfmFootnoteCallString: enterFootnoteCallString
    },
    exit: {
      gfmFootnoteDefinition: exitFootnoteDefinition,
      gfmFootnoteDefinitionLabelString: exitFootnoteDefinitionLabelString,
      gfmFootnoteCall: exitFootnoteCall,
      gfmFootnoteCallString: exitFootnoteCallString
    }
  }
}

/**
 * Create an extension for `mdast-util-to-markdown` to enable GFM footnotes
 * in markdown.
 *
 * @returns {ToMarkdownExtension}
 *   Extension for `mdast-util-to-markdown`.
 */
function gfmFootnoteToMarkdown() {
  return {
    // This is on by default already.
    unsafe: [{character: '[', inConstruct: ['phrasing', 'label', 'reference']}],
    handlers: {footnoteDefinition, footnoteReference: footnoteReference$1}
  }
}

/**
 * @this {CompileContext}
 * @type {FromMarkdownHandle}
 */
function enterFootnoteDefinition(token) {
  this.enter(
    {type: 'footnoteDefinition', identifier: '', label: '', children: []},
    token
  );
}

/**
 * @this {CompileContext}
 * @type {FromMarkdownHandle}
 */
function enterFootnoteDefinitionLabelString() {
  this.buffer();
}

/**
 * @this {CompileContext}
 * @type {FromMarkdownHandle}
 */
function exitFootnoteDefinitionLabelString(token) {
  const label = this.resume();
  const node = /** @type {FootnoteDefinition} */ (
    this.stack[this.stack.length - 1]
  );
  node.label = label;
  node.identifier = normalizeIdentifier(
    this.sliceSerialize(token)
  ).toLowerCase();
}

/**
 * @this {CompileContext}
 * @type {FromMarkdownHandle}
 */
function exitFootnoteDefinition(token) {
  this.exit(token);
}

/**
 * @this {CompileContext}
 * @type {FromMarkdownHandle}
 */
function enterFootnoteCall(token) {
  this.enter({type: 'footnoteReference', identifier: '', label: ''}, token);
}

/**
 * @this {CompileContext}
 * @type {FromMarkdownHandle}
 */
function enterFootnoteCallString() {
  this.buffer();
}

/**
 * @this {CompileContext}
 * @type {FromMarkdownHandle}
 */
function exitFootnoteCallString(token) {
  const label = this.resume();
  const node = /** @type {FootnoteDefinition} */ (
    this.stack[this.stack.length - 1]
  );
  node.label = label;
  node.identifier = normalizeIdentifier(
    this.sliceSerialize(token)
  ).toLowerCase();
}

/**
 * @this {CompileContext}
 * @type {FromMarkdownHandle}
 */
function exitFootnoteCall(token) {
  this.exit(token);
}

/**
 * @type {ToMarkdownHandle}
 * @param {FootnoteReference} node
 */
function footnoteReference$1(node, _, context, safeOptions) {
  const tracker = track(safeOptions);
  let value = tracker.move('[^');
  const exit = context.enter('footnoteReference');
  const subexit = context.enter('reference');
  value += tracker.move(
    safe(context, association(node), {
      ...tracker.current(),
      before: value,
      after: ']'
    })
  );
  subexit();
  exit();
  value += tracker.move(']');
  return value
}

/** @type {ToMarkdownHandle} */
function footnoteReferencePeek() {
  return '['
}

/**
 * @type {ToMarkdownHandle}
 * @param {FootnoteDefinition} node
 */
function footnoteDefinition(node, _, context, safeOptions) {
  const tracker = track(safeOptions);
  let value = tracker.move('[^');
  const exit = context.enter('footnoteDefinition');
  const subexit = context.enter('label');
  value += tracker.move(
    safe(context, association(node), {
      ...tracker.current(),
      before: value,
      after: ']'
    })
  );
  subexit();
  value += tracker.move(
    ']:' + (node.children && node.children.length > 0 ? ' ' : '')
  );
  tracker.shift(4);
  value += tracker.move(
    indentLines(containerFlow(node, context, tracker.current()), map)
  );
  exit();

  return value
}

/** @type {Map} */
function map(line, index, blank) {
  if (index === 0) {
    return line
  }

  return (blank ? '' : '    ') + line
}

/**
 * @typedef {import('../types.js').Handle} Handle
 * @typedef {import('../types.js').Info} Info
 * @typedef {import('../types.js').Parent} Parent
 * @typedef {import('../types.js').PhrasingContent} PhrasingContent
 * @typedef {import('../types.js').State} State
 */

/**
 * Serialize the children of a parent that contains phrasing children.
 *
 * These children will be joined flush together.
 *
 * @param {Parent & {children: Array<PhrasingContent>}} parent
 *   Parent of flow nodes.
 * @param {State} state
 *   Info passed around about the current state.
 * @param {Info} info
 *   Info on where we are in the document we are generating.
 * @returns {string}
 *   Serialized children, joined together.
 */
function containerPhrasing(parent, state, info) {
  const indexStack = state.indexStack;
  const children = parent.children || [];
  /** @type {Array<string>} */
  const results = [];
  let index = -1;
  let before = info.before;

  indexStack.push(-1);
  let tracker = state.createTracker(info);

  while (++index < children.length) {
    const child = children[index];
    /** @type {string} */
    let after;

    indexStack[indexStack.length - 1] = index;

    if (index + 1 < children.length) {
      /** @type {Handle} */
      // @ts-expect-error: hush, it‚Äôs actually a `zwitch`.
      let handle = state.handle.handlers[children[index + 1].type];
      /** @type {Handle} */
      // @ts-expect-error: hush, it‚Äôs actually a `zwitch`.
      if (handle && handle.peek) handle = handle.peek;
      after = handle
        ? handle(children[index + 1], parent, state, {
            before: '',
            after: '',
            ...tracker.current()
          }).charAt(0)
        : '';
    } else {
      after = info.after;
    }

    // In some cases, html (text) can be found in phrasing right after an eol.
    // When we‚Äôd serialize that, in most cases that would be seen as html
    // (flow).
    // As we can‚Äôt escape or so to prevent it from happening, we take a somewhat
    // reasonable approach: replace that eol with a space.
    // See: <https://github.com/syntax-tree/mdast-util-to-markdown/issues/15>
    if (
      results.length > 0 &&
      (before === '\r' || before === '\n') &&
      child.type === 'html'
    ) {
      results[results.length - 1] = results[results.length - 1].replace(
        /(\r?\n|\r)$/,
        ' '
      );
      before = ' ';

      // To do: does this work to reset tracker?
      tracker = state.createTracker(info);
      tracker.move(results.join(''));
    }

    results.push(
      tracker.move(
        state.handle(child, parent, state, {
          ...tracker.current(),
          before,
          after
        })
      )
    );

    before = results[results.length - 1].slice(-1);
  }

  indexStack.pop();

  return results.join('')
}

/**
 * @typedef {import('mdast').Delete} Delete
 *
 * @typedef {import('mdast-util-from-markdown').CompileContext} CompileContext
 * @typedef {import('mdast-util-from-markdown').Extension} FromMarkdownExtension
 * @typedef {import('mdast-util-from-markdown').Handle} FromMarkdownHandle
 *
 * @typedef {import('mdast-util-to-markdown').ConstructName} ConstructName
 * @typedef {import('mdast-util-to-markdown').Options} ToMarkdownExtension
 * @typedef {import('mdast-util-to-markdown').Handle} ToMarkdownHandle
 */

// To do: next major: expose functions.
// To do: next major: use `state`, state utilities.

/**
 * List of constructs that occur in phrasing (paragraphs, headings), but cannot
 * contain strikethrough.
 * So they sort of cancel each other out.
 * Note: could use a better name.
 *
 * Note: keep in sync with: <https://github.com/syntax-tree/mdast-util-to-markdown/blob/8ce8dbf/lib/unsafe.js#L14>
 *
 * @type {Array<ConstructName>}
 */
const constructsWithoutStrikethrough = [
  'autolink',
  'destinationLiteral',
  'destinationRaw',
  'reference',
  'titleQuote',
  'titleApostrophe'
];

handleDelete.peek = peekDelete;

/**
 * Extension for `mdast-util-from-markdown` to enable GFM strikethrough.
 *
 * @type {FromMarkdownExtension}
 */
const gfmStrikethroughFromMarkdown = {
  canContainEols: ['delete'],
  enter: {strikethrough: enterStrikethrough},
  exit: {strikethrough: exitStrikethrough}
};

/**
 * Extension for `mdast-util-to-markdown` to enable GFM strikethrough.
 *
 * @type {ToMarkdownExtension}
 */
const gfmStrikethroughToMarkdown = {
  unsafe: [
    {
      character: '~',
      inConstruct: 'phrasing',
      notInConstruct: constructsWithoutStrikethrough
    }
  ],
  handlers: {delete: handleDelete}
};

/**
 * @this {CompileContext}
 * @type {FromMarkdownHandle}
 */
function enterStrikethrough(token) {
  this.enter({type: 'delete', children: []}, token);
}

/**
 * @this {CompileContext}
 * @type {FromMarkdownHandle}
 */
function exitStrikethrough(token) {
  this.exit(token);
}

/**
 * @type {ToMarkdownHandle}
 * @param {Delete} node
 */
function handleDelete(node, _, context, safeOptions) {
  const tracker = track(safeOptions);
  const exit = context.enter('strikethrough');
  let value = tracker.move('~~');
  value += containerPhrasing(node, context, {
    ...tracker.current(),
    before: value,
    after: '~'
  });
  value += tracker.move('~~');
  exit();
  return value
}

/** @type {ToMarkdownHandle} */
function peekDelete() {
  return '~'
}

/**
 * @typedef {import('mdast').InlineCode} InlineCode
 * @typedef {import('../types.js').Parent} Parent
 * @typedef {import('../types.js').State} State
 */

inlineCode$1.peek = inlineCodePeek;

/**
 * @param {InlineCode} node
 * @param {Parent | undefined} _
 * @param {State} state
 * @returns {string}
 */
function inlineCode$1(node, _, state) {
  let value = node.value || '';
  let sequence = '`';
  let index = -1;

  // If there is a single grave accent on its own in the code, use a fence of
  // two.
  // If there are two in a row, use one.
  while (new RegExp('(^|[^`])' + sequence + '([^`]|$)').test(value)) {
    sequence += '`';
  }

  // If this is not just spaces or eols (tabs don‚Äôt count), and either the
  // first or last character are a space, eol, or tick, then pad with spaces.
  if (
    /[^ \r\n]/.test(value) &&
    ((/^[ \r\n]/.test(value) && /[ \r\n]$/.test(value)) || /^`|`$/.test(value))
  ) {
    value = ' ' + value + ' ';
  }

  // We have a potential problem: certain characters after eols could result in
  // blocks being seen.
  // For example, if someone injected the string `'\n# b'`, then that would
  // result in an ATX heading.
  // We can‚Äôt escape characters in `inlineCode`, but because eols are
  // transformed to spaces when going from markdown to HTML anyway, we can swap
  // them out.
  while (++index < state.unsafe.length) {
    const pattern = state.unsafe[index];
    const expression = patternCompile(pattern);
    /** @type {RegExpExecArray | null} */
    let match;

    // Only look for `atBreak`s.
    // Btw: note that `atBreak` patterns will always start the regex at LF or
    // CR.
    if (!pattern.atBreak) continue

    while ((match = expression.exec(value))) {
      let position = match.index;

      // Support CRLF (patterns only look for one of the characters).
      if (
        value.charCodeAt(position) === 10 /* `\n` */ &&
        value.charCodeAt(position - 1) === 13 /* `\r` */
      ) {
        position--;
      }

      value = value.slice(0, position) + ' ' + value.slice(match.index + 1);
    }
  }

  return sequence + value + sequence
}

/**
 * @returns {string}
 */
function inlineCodePeek() {
  return '`'
}

/**
 * @typedef Options
 *   Configuration (optional).
 * @property {string|null|ReadonlyArray<string|null|undefined>} [align]
 *   One style for all columns, or styles for their respective columns.
 *   Each style is either `'l'` (left), `'r'` (right), or `'c'` (center).
 *   Other values are treated as `''`, which doesn‚Äôt place the colon in the
 *   alignment row but does align left.
 *   *Only the lowercased first character is used, so `Right` is fine.*
 * @property {boolean} [padding=true]
 *   Whether to add a space of padding between delimiters and cells.
 *
 *   When `true`, there is padding:
 *
 *   ```markdown
 *   | Alpha | B     |
 *   | ----- | ----- |
 *   | C     | Delta |
 *   ```
 *
 *   When `false`, there is no padding:
 *
 *   ```markdown
 *   |Alpha|B    |
 *   |-----|-----|
 *   |C    |Delta|
 *   ```
 * @property {boolean} [delimiterStart=true]
 *   Whether to begin each row with the delimiter.
 *
 *   > üëâ **Note**: please don‚Äôt use this: it could create fragile structures
 *   > that aren‚Äôt understandable to some markdown parsers.
 *
 *   When `true`, there are starting delimiters:
 *
 *   ```markdown
 *   | Alpha | B     |
 *   | ----- | ----- |
 *   | C     | Delta |
 *   ```
 *
 *   When `false`, there are no starting delimiters:
 *
 *   ```markdown
 *   Alpha | B     |
 *   ----- | ----- |
 *   C     | Delta |
 *   ```
 * @property {boolean} [delimiterEnd=true]
 *   Whether to end each row with the delimiter.
 *
 *   > üëâ **Note**: please don‚Äôt use this: it could create fragile structures
 *   > that aren‚Äôt understandable to some markdown parsers.
 *
 *   When `true`, there are ending delimiters:
 *
 *   ```markdown
 *   | Alpha | B     |
 *   | ----- | ----- |
 *   | C     | Delta |
 *   ```
 *
 *   When `false`, there are no ending delimiters:
 *
 *   ```markdown
 *   | Alpha | B
 *   | ----- | -----
 *   | C     | Delta
 *   ```
 * @property {boolean} [alignDelimiters=true]
 *   Whether to align the delimiters.
 *   By default, they are aligned:
 *
 *   ```markdown
 *   | Alpha | B     |
 *   | ----- | ----- |
 *   | C     | Delta |
 *   ```
 *
 *   Pass `false` to make them staggered:
 *
 *   ```markdown
 *   | Alpha | B |
 *   | - | - |
 *   | C | Delta |
 *   ```
 * @property {(value: string) => number} [stringLength]
 *   Function to detect the length of table cell content.
 *   This is used when aligning the delimiters (`|`) between table cells.
 *   Full-width characters and emoji mess up delimiter alignment when viewing
 *   the markdown source.
 *   To fix this, you can pass this function, which receives the cell content
 *   and returns its ‚Äúvisible‚Äù size.
 *   Note that what is and isn‚Äôt visible depends on where the text is displayed.
 *
 *   Without such a function, the following:
 *
 *   ```js
 *   markdownTable([
 *     ['Alpha', 'Bravo'],
 *     ['‰∏≠Êñá', 'Charlie'],
 *     ['üë©‚Äç‚ù§Ô∏è‚Äçüë©', 'Delta']
 *   ])
 *   ```
 *
 *   Yields:
 *
 *   ```markdown
 *   | Alpha | Bravo |
 *   | - | - |
 *   | ‰∏≠Êñá | Charlie |
 *   | üë©‚Äç‚ù§Ô∏è‚Äçüë© | Delta |
 *   ```
 *
 *   With [`string-width`](https://github.com/sindresorhus/string-width):
 *
 *   ```js
 *   import stringWidth from 'string-width'
 *
 *   markdownTable(
 *     [
 *       ['Alpha', 'Bravo'],
 *       ['‰∏≠Êñá', 'Charlie'],
 *       ['üë©‚Äç‚ù§Ô∏è‚Äçüë©', 'Delta']
 *     ],
 *     {stringLength: stringWidth}
 *   )
 *   ```
 *
 *   Yields:
 *
 *   ```markdown
 *   | Alpha | Bravo   |
 *   | ----- | ------- |
 *   | ‰∏≠Êñá  | Charlie |
 *   | üë©‚Äç‚ù§Ô∏è‚Äçüë©    | Delta   |
 *   ```
 */

/**
 * @typedef {Options} MarkdownTableOptions
 * @todo
 *   Remove next major.
 */

/**
 * Generate a markdown ([GFM](https://docs.github.com/en/github/writing-on-github/working-with-advanced-formatting/organizing-information-with-tables)) table..
 *
 * @param {ReadonlyArray<ReadonlyArray<string|null|undefined>>} table
 *   Table data (matrix of strings).
 * @param {Options} [options]
 *   Configuration (optional).
 * @returns {string}
 */
function markdownTable(table, options = {}) {
  const align = (options.align || []).concat();
  const stringLength = options.stringLength || defaultStringLength;
  /** @type {Array<number>} Character codes as symbols for alignment per column. */
  const alignments = [];
  /** @type {Array<Array<string>>} Cells per row. */
  const cellMatrix = [];
  /** @type {Array<Array<number>>} Sizes of each cell per row. */
  const sizeMatrix = [];
  /** @type {Array<number>} */
  const longestCellByColumn = [];
  let mostCellsPerRow = 0;
  let rowIndex = -1;

  // This is a superfluous loop if we don‚Äôt align delimiters, but otherwise we‚Äôd
  // do superfluous work when aligning, so optimize for aligning.
  while (++rowIndex < table.length) {
    /** @type {Array<string>} */
    const row = [];
    /** @type {Array<number>} */
    const sizes = [];
    let columnIndex = -1;

    if (table[rowIndex].length > mostCellsPerRow) {
      mostCellsPerRow = table[rowIndex].length;
    }

    while (++columnIndex < table[rowIndex].length) {
      const cell = serialize(table[rowIndex][columnIndex]);

      if (options.alignDelimiters !== false) {
        const size = stringLength(cell);
        sizes[columnIndex] = size;

        if (
          longestCellByColumn[columnIndex] === undefined ||
          size > longestCellByColumn[columnIndex]
        ) {
          longestCellByColumn[columnIndex] = size;
        }
      }

      row.push(cell);
    }

    cellMatrix[rowIndex] = row;
    sizeMatrix[rowIndex] = sizes;
  }

  // Figure out which alignments to use.
  let columnIndex = -1;

  if (typeof align === 'object' && 'length' in align) {
    while (++columnIndex < mostCellsPerRow) {
      alignments[columnIndex] = toAlignment(align[columnIndex]);
    }
  } else {
    const code = toAlignment(align);

    while (++columnIndex < mostCellsPerRow) {
      alignments[columnIndex] = code;
    }
  }

  // Inject the alignment row.
  columnIndex = -1;
  /** @type {Array<string>} */
  const row = [];
  /** @type {Array<number>} */
  const sizes = [];

  while (++columnIndex < mostCellsPerRow) {
    const code = alignments[columnIndex];
    let before = '';
    let after = '';

    if (code === 99 /* `c` */) {
      before = ':';
      after = ':';
    } else if (code === 108 /* `l` */) {
      before = ':';
    } else if (code === 114 /* `r` */) {
      after = ':';
    }

    // There *must* be at least one hyphen-minus in each alignment cell.
    let size =
      options.alignDelimiters === false
        ? 1
        : Math.max(
            1,
            longestCellByColumn[columnIndex] - before.length - after.length
          );

    const cell = before + '-'.repeat(size) + after;

    if (options.alignDelimiters !== false) {
      size = before.length + size + after.length;

      if (size > longestCellByColumn[columnIndex]) {
        longestCellByColumn[columnIndex] = size;
      }

      sizes[columnIndex] = size;
    }

    row[columnIndex] = cell;
  }

  // Inject the alignment row.
  cellMatrix.splice(1, 0, row);
  sizeMatrix.splice(1, 0, sizes);

  rowIndex = -1;
  /** @type {Array<string>} */
  const lines = [];

  while (++rowIndex < cellMatrix.length) {
    const row = cellMatrix[rowIndex];
    const sizes = sizeMatrix[rowIndex];
    columnIndex = -1;
    /** @type {Array<string>} */
    const line = [];

    while (++columnIndex < mostCellsPerRow) {
      const cell = row[columnIndex] || '';
      let before = '';
      let after = '';

      if (options.alignDelimiters !== false) {
        const size =
          longestCellByColumn[columnIndex] - (sizes[columnIndex] || 0);
        const code = alignments[columnIndex];

        if (code === 114 /* `r` */) {
          before = ' '.repeat(size);
        } else if (code === 99 /* `c` */) {
          if (size % 2) {
            before = ' '.repeat(size / 2 + 0.5);
            after = ' '.repeat(size / 2 - 0.5);
          } else {
            before = ' '.repeat(size / 2);
            after = before;
          }
        } else {
          after = ' '.repeat(size);
        }
      }

      if (options.delimiterStart !== false && !columnIndex) {
        line.push('|');
      }

      if (
        options.padding !== false &&
        // Don‚Äôt add the opening space if we‚Äôre not aligning and the cell is
        // empty: there will be a closing space.
        !(options.alignDelimiters === false && cell === '') &&
        (options.delimiterStart !== false || columnIndex)
      ) {
        line.push(' ');
      }

      if (options.alignDelimiters !== false) {
        line.push(before);
      }

      line.push(cell);

      if (options.alignDelimiters !== false) {
        line.push(after);
      }

      if (options.padding !== false) {
        line.push(' ');
      }

      if (
        options.delimiterEnd !== false ||
        columnIndex !== mostCellsPerRow - 1
      ) {
        line.push('|');
      }
    }

    lines.push(
      options.delimiterEnd === false
        ? line.join('').replace(/ +$/, '')
        : line.join('')
    );
  }

  return lines.join('\n')
}

/**
 * @param {string|null|undefined} [value]
 * @returns {string}
 */
function serialize(value) {
  return value === null || value === undefined ? '' : String(value)
}

/**
 * @param {string} value
 * @returns {number}
 */
function defaultStringLength(value) {
  return value.length
}

/**
 * @param {string|null|undefined} value
 * @returns {number}
 */
function toAlignment(value) {
  const code = typeof value === 'string' ? value.codePointAt(0) : 0;

  return code === 67 /* `C` */ || code === 99 /* `c` */
    ? 99 /* `c` */
    : code === 76 /* `L` */ || code === 108 /* `l` */
    ? 108 /* `l` */
    : code === 82 /* `R` */ || code === 114 /* `r` */
    ? 114 /* `r` */
    : 0
}

/**
 * @typedef {import('mdast').Table} Table
 * @typedef {import('mdast').TableRow} TableRow
 * @typedef {import('mdast').TableCell} TableCell
 * @typedef {import('mdast').InlineCode} InlineCode
 *
 * @typedef {import('markdown-table').MarkdownTableOptions} MarkdownTableOptions
 *
 * @typedef {import('mdast-util-from-markdown').CompileContext} CompileContext
 * @typedef {import('mdast-util-from-markdown').Extension} FromMarkdownExtension
 * @typedef {import('mdast-util-from-markdown').Handle} FromMarkdownHandle
 *
 * @typedef {import('mdast-util-to-markdown').Options} ToMarkdownExtension
 * @typedef {import('mdast-util-to-markdown').Handle} ToMarkdownHandle
 * @typedef {import('mdast-util-to-markdown').Context} ToMarkdownContext
 * @typedef {import('mdast-util-to-markdown').SafeOptions} SafeOptions
 */

// To do: next major: use `state` and `state` utilities from `mdast-util-to-markdown`.
// To do: next major: use `defaultHandlers.inlineCode`.
// To do: next major: expose functions.

/**
 * Extension for `mdast-util-from-markdown` to enable GFM tables.
 *
 * @type {FromMarkdownExtension}
 */
const gfmTableFromMarkdown = {
  enter: {
    table: enterTable,
    tableData: enterCell,
    tableHeader: enterCell,
    tableRow: enterRow
  },
  exit: {
    codeText: exitCodeText,
    table: exitTable,
    tableData: exit,
    tableHeader: exit,
    tableRow: exit
  }
};

/**
 * @this {CompileContext}
 * @type {FromMarkdownHandle}
 */
function enterTable(token) {
  /** @type {Array<'left' | 'right' | 'center' | 'none'>} */
  // @ts-expect-error: `align` is custom.
  const align = token._align;
  this.enter(
    {
      type: 'table',
      align: align.map((d) => (d === 'none' ? null : d)),
      children: []
    },
    token
  );
  this.setData('inTable', true);
}

/**
 * @this {CompileContext}
 * @type {FromMarkdownHandle}
 */
function exitTable(token) {
  this.exit(token);
  this.setData('inTable');
}

/**
 * @this {CompileContext}
 * @type {FromMarkdownHandle}
 */
function enterRow(token) {
  this.enter({type: 'tableRow', children: []}, token);
}

/**
 * @this {CompileContext}
 * @type {FromMarkdownHandle}
 */
function exit(token) {
  this.exit(token);
}

/**
 * @this {CompileContext}
 * @type {FromMarkdownHandle}
 */
function enterCell(token) {
  this.enter({type: 'tableCell', children: []}, token);
}

// Overwrite the default code text data handler to unescape escaped pipes when
// they are in tables.
/**
 * @this {CompileContext}
 * @type {FromMarkdownHandle}
 */
function exitCodeText(token) {
  let value = this.resume();

  if (this.getData('inTable')) {
    value = value.replace(/\\([\\|])/g, replace);
  }

  const node = /** @type {InlineCode} */ (this.stack[this.stack.length - 1]);
  node.value = value;
  this.exit(token);
}

/**
 * @param {string} $0
 * @param {string} $1
 * @returns {string}
 */
function replace($0, $1) {
  // Pipes work, backslashes don‚Äôt (but can‚Äôt escape pipes).
  return $1 === '|' ? $1 : $0
}

/**
 * Create an extension for `mdast-util-to-markdown` to enable GFM tables in
 * markdown.
 *
 * @param {Options | null | undefined} [options]
 *   Configuration.
 * @returns {ToMarkdownExtension}
 *   Extension for `mdast-util-to-markdown` to enable GFM tables.
 */
function gfmTableToMarkdown(options) {
  const settings = options || {};
  const padding = settings.tableCellPadding;
  const alignDelimiters = settings.tablePipeAlign;
  const stringLength = settings.stringLength;
  const around = padding ? ' ' : '|';

  return {
    unsafe: [
      {character: '\r', inConstruct: 'tableCell'},
      {character: '\n', inConstruct: 'tableCell'},
      // A pipe, when followed by a tab or space (padding), or a dash or colon
      // (unpadded delimiter row), could result in a table.
      {atBreak: true, character: '|', after: '[\t :-]'},
      // A pipe in a cell must be encoded.
      {character: '|', inConstruct: 'tableCell'},
      // A colon must be followed by a dash, in which case it could start a
      // delimiter row.
      {atBreak: true, character: ':', after: '-'},
      // A delimiter row can also start with a dash, when followed by more
      // dashes, a colon, or a pipe.
      // This is a stricter version than the built in check for lists, thematic
      // breaks, and setex heading underlines though:
      // <https://github.com/syntax-tree/mdast-util-to-markdown/blob/51a2038/lib/unsafe.js#L57>
      {atBreak: true, character: '-', after: '[:|-]'}
    ],
    handlers: {
      table: handleTable,
      tableRow: handleTableRow,
      tableCell: handleTableCell,
      inlineCode: inlineCodeWithTable
    }
  }

  /**
   * @type {ToMarkdownHandle}
   * @param {Table} node
   */
  function handleTable(node, _, context, safeOptions) {
    return serializeData(
      handleTableAsData(node, context, safeOptions),
      node.align
    )
  }

  /**
   * This function isn‚Äôt really used normally, because we handle rows at the
   * table level.
   * But, if someone passes in a table row, this ensures we make somewhat sense.
   *
   * @type {ToMarkdownHandle}
   * @param {TableRow} node
   */
  function handleTableRow(node, _, context, safeOptions) {
    const row = handleTableRowAsData(node, context, safeOptions);
    const value = serializeData([row]);
    // `markdown-table` will always add an align row
    return value.slice(0, value.indexOf('\n'))
  }

  /**
   * @type {ToMarkdownHandle}
   * @param {TableCell} node
   */
  function handleTableCell(node, _, context, safeOptions) {
    const exit = context.enter('tableCell');
    const subexit = context.enter('phrasing');
    const value = containerPhrasing(node, context, {
      ...safeOptions,
      before: around,
      after: around
    });
    subexit();
    exit();
    return value
  }

  /**
   * @param {Array<Array<string>>} matrix
   * @param {Array<string | null | undefined> | null | undefined} [align]
   */
  function serializeData(matrix, align) {
    return markdownTable(matrix, {
      align,
      // @ts-expect-error: `markdown-table` types should support `null`.
      alignDelimiters,
      // @ts-expect-error: `markdown-table` types should support `null`.
      padding,
      // @ts-expect-error: `markdown-table` types should support `null`.
      stringLength
    })
  }

  /**
   * @param {Table} node
   * @param {ToMarkdownContext} context
   * @param {SafeOptions} safeOptions
   */
  function handleTableAsData(node, context, safeOptions) {
    const children = node.children;
    let index = -1;
    /** @type {Array<Array<string>>} */
    const result = [];
    const subexit = context.enter('table');

    while (++index < children.length) {
      result[index] = handleTableRowAsData(
        children[index],
        context,
        safeOptions
      );
    }

    subexit();

    return result
  }

  /**
   * @param {TableRow} node
   * @param {ToMarkdownContext} context
   * @param {SafeOptions} safeOptions
   */
  function handleTableRowAsData(node, context, safeOptions) {
    const children = node.children;
    let index = -1;
    /** @type {Array<string>} */
    const result = [];
    const subexit = context.enter('tableRow');

    while (++index < children.length) {
      // Note: the positional info as used here is incorrect.
      // Making it correct would be impossible due to aligning cells?
      // And it would need copy/pasting `markdown-table` into this project.
      result[index] = handleTableCell(
        children[index],
        node,
        context,
        safeOptions
      );
    }

    subexit();

    return result
  }

  /**
   * @type {ToMarkdownHandle}
   * @param {InlineCode} node
   */
  function inlineCodeWithTable(node, parent, context) {
    let value = inlineCode$1(node, parent, context);

    if (context.stack.includes('tableCell')) {
      value = value.replace(/\|/g, '\\$&');
    }

    return value
  }
}

/**
 * @typedef {import('../types.js').State} State
 * @typedef {import('../types.js').Options} Options
 */

/**
 * @param {State} state
 * @returns {Exclude<Options['bullet'], null | undefined>}
 */
function checkBullet(state) {
  const marker = state.options.bullet || '*';

  if (marker !== '*' && marker !== '+' && marker !== '-') {
    throw new Error(
      'Cannot serialize items with `' +
        marker +
        '` for `options.bullet`, expected `*`, `+`, or `-`'
    )
  }

  return marker
}

/**
 * @typedef {import('../types.js').State} State
 * @typedef {import('../types.js').Options} Options
 */

/**
 * @param {State} state
 * @returns {Exclude<Options['listItemIndent'], null | undefined>}
 */
function checkListItemIndent(state) {
  const style = state.options.listItemIndent || 'tab';

  // To do: remove in a major.
  // @ts-expect-error: deprecated.
  if (style === 1 || style === '1') {
    return 'one'
  }

  if (style !== 'tab' && style !== 'one' && style !== 'mixed') {
    throw new Error(
      'Cannot serialize items with `' +
        style +
        '` for `options.listItemIndent`, expected `tab`, `one`, or `mixed`'
    )
  }

  return style
}

/**
 * @typedef {import('mdast').ListItem} ListItem
 * @typedef {import('../types.js').Map} Map
 * @typedef {import('../types.js').Parent} Parent
 * @typedef {import('../types.js').State} State
 * @typedef {import('../types.js').Info} Info
 */

/**
 * @param {ListItem} node
 * @param {Parent | undefined} parent
 * @param {State} state
 * @param {Info} info
 * @returns {string}
 */
function listItem$1(node, parent, state, info) {
  const listItemIndent = checkListItemIndent(state);
  let bullet = state.bulletCurrent || checkBullet(state);

  // Add the marker value for ordered lists.
  if (parent && parent.type === 'list' && parent.ordered) {
    bullet =
      (typeof parent.start === 'number' && parent.start > -1
        ? parent.start
        : 1) +
      (state.options.incrementListMarker === false
        ? 0
        : parent.children.indexOf(node)) +
      bullet;
  }

  let size = bullet.length + 1;

  if (
    listItemIndent === 'tab' ||
    (listItemIndent === 'mixed' &&
      ((parent && parent.type === 'list' && parent.spread) || node.spread))
  ) {
    size = Math.ceil(size / 4) * 4;
  }

  const tracker = state.createTracker(info);
  tracker.move(bullet + ' '.repeat(size - bullet.length));
  tracker.shift(size);
  const exit = state.enter('listItem');
  const value = state.indentLines(
    state.containerFlow(node, tracker.current()),
    map
  );
  exit();

  return value

  /** @type {Map} */
  function map(line, index, blank) {
    if (index) {
      return (blank ? '' : ' '.repeat(size)) + line
    }

    return (blank ? bullet : bullet + ' '.repeat(size - bullet.length)) + line
  }
}

/**
 * @typedef {import('mdast').Content} Content
 * @typedef {import('mdast').ListItem} ListItem
 * @typedef {import('mdast').Paragraph} Paragraph
 * @typedef {import('mdast').Parent} Parent
 * @typedef {import('mdast').Root} Root
 * @typedef {import('mdast-util-from-markdown').CompileContext} CompileContext
 * @typedef {import('mdast-util-from-markdown').Extension} FromMarkdownExtension
 * @typedef {import('mdast-util-from-markdown').Handle} FromMarkdownHandle
 * @typedef {import('mdast-util-to-markdown').Options} ToMarkdownExtension
 * @typedef {import('mdast-util-to-markdown').Handle} ToMarkdownHandle
 */

// To do: next major: rename `context` -> `state`, `safeOptions` -> `info`, use
// `track` from `state`.
// To do: next major: replace exports with functions.
// To do: next major: use `defaulthandlers.listItem`.

/**
 * Extension for `mdast-util-from-markdown` to enable GFM task list items.
 *
 * @type {FromMarkdownExtension}
 */
const gfmTaskListItemFromMarkdown = {
  exit: {
    taskListCheckValueChecked: exitCheck,
    taskListCheckValueUnchecked: exitCheck,
    paragraph: exitParagraphWithTaskListItem
  }
};

/**
 * Extension for `mdast-util-to-markdown` to enable GFM task list items.
 *
 * @type {ToMarkdownExtension}
 */
const gfmTaskListItemToMarkdown = {
  unsafe: [{atBreak: true, character: '-', after: '[:|-]'}],
  handlers: {listItem: listItemWithTaskListItem}
};

/**
 * @this {CompileContext}
 * @type {FromMarkdownHandle}
 */
function exitCheck(token) {
  const node = /** @type {ListItem} */ (this.stack[this.stack.length - 2]);
  // We‚Äôre always in a paragraph, in a list item.
  node.checked = token.type === 'taskListCheckValueChecked';
}

/**
 * @this {CompileContext}
 * @type {FromMarkdownHandle}
 */
function exitParagraphWithTaskListItem(token) {
  const parent = /** @type {Parents} */ (this.stack[this.stack.length - 2]);

  if (
    parent &&
    parent.type === 'listItem' &&
    typeof parent.checked === 'boolean'
  ) {
    const node = /** @type {Paragraph} */ (this.stack[this.stack.length - 1]);
    const head = node.children[0];

    if (head && head.type === 'text') {
      const siblings = parent.children;
      let index = -1;
      /** @type {Paragraph | undefined} */
      let firstParaghraph;

      while (++index < siblings.length) {
        const sibling = siblings[index];
        if (sibling.type === 'paragraph') {
          firstParaghraph = sibling;
          break
        }
      }

      if (firstParaghraph === node) {
        // Must start with a space or a tab.
        head.value = head.value.slice(1);

        if (head.value.length === 0) {
          node.children.shift();
        } else if (
          node.position &&
          head.position &&
          typeof head.position.start.offset === 'number'
        ) {
          head.position.start.column++;
          head.position.start.offset++;
          node.position.start = Object.assign({}, head.position.start);
        }
      }
    }
  }

  this.exit(token);
}

/**
 * @type {ToMarkdownHandle}
 * @param {ListItem} node
 */
function listItemWithTaskListItem(node, parent, context, safeOptions) {
  const head = node.children[0];
  const checkable =
    typeof node.checked === 'boolean' && head && head.type === 'paragraph';
  const checkbox = '[' + (node.checked ? 'x' : ' ') + '] ';
  const tracker = track(safeOptions);

  if (checkable) {
    tracker.move(checkbox);
  }

  let value = listItem$1(node, parent, context, {
    ...safeOptions,
    ...tracker.current()
  });

  if (checkable) {
    value = value.replace(/^(?:[*+-]|\d+\.)([\r\n]| {1,3})/, check);
  }

  return value

  /**
   * @param {string} $0
   * @returns {string}
   */
  function check($0) {
    return $0 + checkbox
  }
}

/**
 * @typedef {import('mdast-util-from-markdown').Extension} FromMarkdownExtension
 * @typedef {import('mdast-util-to-markdown').Options} ToMarkdownExtension
 */

/**
 * Create an extension for `mdast-util-from-markdown` to enable GFM (autolink
 * literals, footnotes, strikethrough, tables, tasklists).
 *
 * @returns {Array<FromMarkdownExtension>}
 *   Extension for `mdast-util-from-markdown` to enable GFM (autolink literals,
 *   footnotes, strikethrough, tables, tasklists).
 */
function gfmFromMarkdown() {
  return [
    gfmAutolinkLiteralFromMarkdown,
    gfmFootnoteFromMarkdown(),
    gfmStrikethroughFromMarkdown,
    gfmTableFromMarkdown,
    gfmTaskListItemFromMarkdown
  ]
}

/**
 * Create an extension for `mdast-util-to-markdown` to enable GFM (autolink
 * literals, footnotes, strikethrough, tables, tasklists).
 *
 * @param {Options | null | undefined} [options]
 *   Configuration.
 * @returns {ToMarkdownExtension}
 *   Extension for `mdast-util-to-markdown` to enable GFM (autolink literals,
 *   footnotes, strikethrough, tables, tasklists).
 */
function gfmToMarkdown(options) {
  return {
    extensions: [
      gfmAutolinkLiteralToMarkdown,
      gfmFootnoteToMarkdown(),
      gfmStrikethroughToMarkdown,
      gfmTableToMarkdown(options),
      gfmTaskListItemToMarkdown
    ]
  }
}

/**
 * @typedef {import('mdast').Root} Root
 * @typedef {import('micromark-extension-gfm').Options & import('mdast-util-gfm').Options} Options
 */

/**
 * Plugin to support GFM (autolink literals, footnotes, strikethrough, tables, tasklists).
 *
 * @type {import('unified').Plugin<[Options?]|void[], Root>}
 */
function remarkGfm(options = {}) {
  const data = this.data();

  add('micromarkExtensions', gfm(options));
  add('fromMarkdownExtensions', gfmFromMarkdown());
  add('toMarkdownExtensions', gfmToMarkdown(options));

  /**
   * @param {string} field
   * @param {unknown} value
   */
  function add(field, value) {
    const list = /** @type {unknown[]} */ (
      // Other extensions
      /* c8 ignore next 2 */
      data[field] ? data[field] : (data[field] = [])
    );

    list.push(value);
  }
}

/**
 * @typedef {import('micromark-util-types').Construct} Construct
 * @typedef {import('micromark-util-types').Tokenizer} Tokenizer
 * @typedef {import('micromark-util-types').State} State
 */

/** @type {Construct} */
const mathFlow = {
  tokenize: tokenizeMathFenced,
  concrete: true
};
/** @type {Construct} */

const nonLazyLine = {
  tokenize: tokenizeNonLazyLine,
  partial: true
};
/** @type {Tokenizer} */

function tokenizeMathFenced(effects, ok, nok) {
  const self = this;
  const tail = self.events[self.events.length - 1];
  const initialSize =
    tail && tail[1].type === 'linePrefix'
      ? tail[2].sliceSerialize(tail[1], true).length
      : 0;
  let sizeOpen = 0;
  return start
  /** @type {State} */

  function start(code) {
    effects.enter('mathFlow');
    effects.enter('mathFlowFence');
    effects.enter('mathFlowFenceSequence');
    return sequenceOpen(code)
  }
  /** @type {State} */

  function sequenceOpen(code) {
    if (code === 36) {
      effects.consume(code);
      sizeOpen++;
      return sequenceOpen
    }

    effects.exit('mathFlowFenceSequence');
    return sizeOpen < 2
      ? nok(code)
      : factorySpace(effects, metaOpen, 'whitespace')(code)
  }
  /** @type {State} */

  function metaOpen(code) {
    if (code === null || markdownLineEnding(code)) {
      return openAfter(code)
    }

    effects.enter('mathFlowFenceMeta');
    effects.enter('chunkString', {
      contentType: 'string'
    });
    return meta(code)
  }
  /** @type {State} */

  function meta(code) {
    if (code === null || markdownLineEnding(code)) {
      effects.exit('chunkString');
      effects.exit('mathFlowFenceMeta');
      return openAfter(code)
    }

    if (code === 36) return nok(code)
    effects.consume(code);
    return meta
  }
  /** @type {State} */

  function openAfter(code) {
    effects.exit('mathFlowFence');
    return self.interrupt ? ok(code) : contentStart(code)
  }
  /** @type {State} */

  function contentStart(code) {
    if (code === null) {
      return after(code)
    }

    if (markdownLineEnding(code)) {
      return effects.attempt(
        nonLazyLine,
        effects.attempt(
          {
            tokenize: tokenizeClosingFence,
            partial: true
          },
          after,
          initialSize
            ? factorySpace(effects, contentStart, 'linePrefix', initialSize + 1)
            : contentStart
        ),
        after
      )(code)
    }

    effects.enter('mathFlowValue');
    return contentContinue(code)
  }
  /** @type {State} */

  function contentContinue(code) {
    if (code === null || markdownLineEnding(code)) {
      effects.exit('mathFlowValue');
      return contentStart(code)
    }

    effects.consume(code);
    return contentContinue
  }
  /** @type {State} */

  function after(code) {
    effects.exit('mathFlow');
    return ok(code)
  }
  /** @type {Tokenizer} */

  function tokenizeClosingFence(effects, ok, nok) {
    let size = 0;
    return factorySpace(effects, closingPrefixAfter, 'linePrefix', 4)
    /** @type {State} */

    function closingPrefixAfter(code) {
      effects.enter('mathFlowFence');
      effects.enter('mathFlowFenceSequence');
      return closingSequence(code)
    }
    /** @type {State} */

    function closingSequence(code) {
      if (code === 36) {
        effects.consume(code);
        size++;
        return closingSequence
      }

      if (size < sizeOpen) return nok(code)
      effects.exit('mathFlowFenceSequence');
      return factorySpace(effects, closingSequenceEnd, 'whitespace')(code)
    }
    /** @type {State} */

    function closingSequenceEnd(code) {
      if (code === null || markdownLineEnding(code)) {
        effects.exit('mathFlowFence');
        return ok(code)
      }

      return nok(code)
    }
  }
}
/** @type {Tokenizer} */

function tokenizeNonLazyLine(effects, ok, nok) {
  const self = this;
  return start
  /** @type {State} */

  function start(code) {
    effects.enter('lineEnding');
    effects.consume(code);
    effects.exit('lineEnding');
    return lineStart
  }
  /** @type {State} */

  function lineStart(code) {
    return self.parser.lazy[self.now().line] ? nok(code) : ok(code)
  }
}

/**
 * @typedef {import('micromark-util-types').Construct} Construct
 * @typedef {import('micromark-util-types').Resolver} Resolver
 * @typedef {import('micromark-util-types').Tokenizer} Tokenizer
 * @typedef {import('micromark-util-types').Previous} Previous
 * @typedef {import('micromark-util-types').State} State
 * @typedef {import('micromark-util-types').Token} Token
 *
 * @typedef Options
 * @property {boolean} [singleDollarTextMath=true]
 *   Whether to support math (text) with a single dollar (`boolean`, default:
 *   `true`).
 *   Single dollars work in Pandoc and many other places, but often interfere
 *   with ‚Äúnormal‚Äù dollars in text.
 */

/**
 * @param {Options} [options]
 * @returns {Construct}
 */
function mathText(options = {}) {
  let single = options.singleDollarTextMath;

  if (single === null || single === undefined) {
    single = true;
  }

  return {
    tokenize: tokenizeMathText,
    resolve: resolveMathText,
    previous
  }
  /** @type {Tokenizer} */

  function tokenizeMathText(effects, ok, nok) {
    let sizeOpen = 0;
    /** @type {number} */

    let size;
    /** @type {Token} */

    let token;
    return start
    /** @type {State} */

    function start(code) {
      effects.enter('mathText');
      effects.enter('mathTextSequence');
      return openingSequence(code)
    }
    /** @type {State} */

    function openingSequence(code) {
      if (code === 36) {
        effects.consume(code);
        sizeOpen++;
        return openingSequence
      }

      if (sizeOpen < 2 && !single) return nok(code)
      effects.exit('mathTextSequence');
      return gap(code)
    }
    /** @type {State} */

    function gap(code) {
      if (code === null) {
        return nok(code)
      } // Closing fence?
      // Could also be data.

      if (code === 36) {
        token = effects.enter('mathTextSequence');
        size = 0;
        return closingSequence(code)
      } // Tabs don‚Äôt work, and virtual spaces don‚Äôt make sense.

      if (code === 32) {
        effects.enter('space');
        effects.consume(code);
        effects.exit('space');
        return gap
      }

      if (markdownLineEnding(code)) {
        effects.enter('lineEnding');
        effects.consume(code);
        effects.exit('lineEnding');
        return gap
      } // Data.

      effects.enter('mathTextData');
      return data(code)
    } // In math.

    /** @type {State} */

    function data(code) {
      if (
        code === null ||
        code === 32 ||
        code === 36 ||
        markdownLineEnding(code)
      ) {
        effects.exit('mathTextData');
        return gap(code)
      }

      effects.consume(code);
      return data
    } // Closing fence.

    /** @type {State} */

    function closingSequence(code) {
      // More.
      if (code === 36) {
        effects.consume(code);
        size++;
        return closingSequence
      } // Done!

      if (size === sizeOpen) {
        effects.exit('mathTextSequence');
        effects.exit('mathText');
        return ok(code)
      } // More or less accents: mark as data.

      token.type = 'mathTextData';
      return data(code)
    }
  }
}
/** @type {Resolver} */

function resolveMathText(events) {
  let tailExitIndex = events.length - 4;
  let headEnterIndex = 3;
  /** @type {number} */

  let index;
  /** @type {number|undefined} */

  let enter; // If we start and end with an EOL or a space.

  if (
    (events[headEnterIndex][1].type === 'lineEnding' ||
      events[headEnterIndex][1].type === 'space') &&
    (events[tailExitIndex][1].type === 'lineEnding' ||
      events[tailExitIndex][1].type === 'space')
  ) {
    index = headEnterIndex; // And we have data.

    while (++index < tailExitIndex) {
      if (events[index][1].type === 'mathTextData') {
        // Then we have padding.
        events[tailExitIndex][1].type = 'mathTextPadding';
        events[headEnterIndex][1].type = 'mathTextPadding';
        headEnterIndex += 2;
        tailExitIndex -= 2;
        break
      }
    }
  } // Merge adjacent spaces and data.

  index = headEnterIndex - 1;
  tailExitIndex++;

  while (++index <= tailExitIndex) {
    if (enter === undefined) {
      if (index !== tailExitIndex && events[index][1].type !== 'lineEnding') {
        enter = index;
      }
    } else if (
      index === tailExitIndex ||
      events[index][1].type === 'lineEnding'
    ) {
      events[enter][1].type = 'mathTextData';

      if (index !== enter + 2) {
        events[enter][1].end = events[index - 1][1].end;
        events.splice(enter + 2, index - enter - 2);
        tailExitIndex -= index - enter - 2;
        index = enter + 2;
      }

      enter = undefined;
    }
  }

  return events
}
/** @type {Previous} */

function previous(code) {
  // If there is a previous code, there will always be a tail.
  return (
    code !== 36 ||
    this.events[this.events.length - 1][1].type === 'characterEscape'
  )
}

/**
 * @typedef {import('micromark-util-types').Extension} Extension
 * @typedef {import('./math-text').Options} Options
 */
/**
 * @param {Options} [options]
 * @returns {Extension}
 */

function math(options) {
  return {
    flow: {
      [36]: mathFlow
    },
    text: {
      [36]: mathText(options)
    }
  }
}

/**
 * Get the count of the longest repeating streak of `substring` in `value`.
 *
 * @param {string} value
 *   Content to search in.
 * @param {string} substring
 *   Substring to look for, typically one character.
 * @returns {number}
 *   Count of most frequent adjacent `substring`s in `value`.
 */
function longestStreak(value, substring) {
  const source = String(value);
  let index = source.indexOf(substring);
  let expected = index;
  let count = 0;
  let max = 0;

  if (typeof substring !== 'string') {
    throw new TypeError('Expected substring')
  }

  while (index !== -1) {
    if (index === expected) {
      if (++count > max) {
        max = count;
      }
    } else {
      count = 1;
    }

    expected = index + substring.length;
    index = source.indexOf(substring, expected);
  }

  return max
}

/**
 * @typedef {import('mdast-util-from-markdown').CompileContext} CompileContext
 * @typedef {import('mdast-util-from-markdown').Extension} FromMarkdownExtension
 * @typedef {import('mdast-util-from-markdown').Handle} FromMarkdownHandle
 * @typedef {import('mdast-util-to-markdown').Options} ToMarkdownExtension
 * @typedef {import('mdast-util-to-markdown').Handle} ToMarkdownHandle
 * @typedef {import('../index.js').Math} Math
 * @typedef {import('../index.js').InlineMath} InlineMath
 *
 * @typedef ToOptions
 *   Configuration.
 * @property {boolean | null | undefined} [singleDollarTextMath=true]
 *   Whether to support math (text) with a single dollar.
 *
 *   Single dollars work in Pandoc and many other places, but often interfere
 *   with ‚Äúnormal‚Äù dollars in text.
 *   If you turn this off, you can still use two or more dollars for text math.
 */

/**
 * Create an extension for `mdast-util-from-markdown`.
 *
 * @returns {FromMarkdownExtension}
 *   Extension for `mdast-util-from-markdown`.
 */
function mathFromMarkdown() {
  return {
    enter: {
      mathFlow: enterMathFlow,
      mathFlowFenceMeta: enterMathFlowMeta,
      mathText: enterMathText
    },
    exit: {
      mathFlow: exitMathFlow,
      mathFlowFence: exitMathFlowFence,
      mathFlowFenceMeta: exitMathFlowMeta,
      mathFlowValue: exitMathData,
      mathText: exitMathText,
      mathTextData: exitMathData
    }
  }

  /**
   * @this {CompileContext}
   * @type {FromMarkdownHandle}
   */
  function enterMathFlow(token) {
    this.enter(
      {
        type: 'math',
        meta: null,
        value: '',
        data: {
          hName: 'div',
          hProperties: {className: ['math', 'math-display']},
          hChildren: [{type: 'text', value: ''}]
        }
      },
      token
    );
  }

  /**
   * @this {CompileContext}
   * @type {FromMarkdownHandle}
   */
  function enterMathFlowMeta() {
    this.buffer();
  }

  /**
   * @this {CompileContext}
   * @type {FromMarkdownHandle}
   */
  function exitMathFlowMeta() {
    const data = this.resume();
    const node = /** @type {Math} */ (this.stack[this.stack.length - 1]);
    node.meta = data;
  }

  /**
   * @this {CompileContext}
   * @type {FromMarkdownHandle}
   */
  function exitMathFlowFence() {
    // Exit if this is the closing fence.
    if (this.getData('mathFlowInside')) return
    this.buffer();
    this.setData('mathFlowInside', true);
  }

  /**
   * @this {CompileContext}
   * @type {FromMarkdownHandle}
   */
  function exitMathFlow(token) {
    const data = this.resume().replace(/^(\r?\n|\r)|(\r?\n|\r)$/g, '');
    const node = /** @type {Math} */ (this.exit(token));
    node.value = data;
    // @ts-expect-error: we defined it.
    node.data.hChildren[0].value = data;
    this.setData('mathFlowInside');
  }

  /**
   * @this {CompileContext}
   * @type {FromMarkdownHandle}
   */
  function enterMathText(token) {
    this.enter(
      {
        type: 'inlineMath',
        value: '',
        data: {
          hName: 'span',
          hProperties: {className: ['math', 'math-inline']},
          hChildren: [{type: 'text', value: ''}]
        }
      },
      token
    );
    this.buffer();
  }

  /**
   * @this {CompileContext}
   * @type {FromMarkdownHandle}
   */
  function exitMathText(token) {
    const data = this.resume();
    const node = /** @type {Math} */ (this.exit(token));
    node.value = data;
    // @ts-expect-error: we defined it.
    node.data.hChildren[0].value = data;
  }

  /**
   * @this {CompileContext}
   * @type {FromMarkdownHandle}
   */
  function exitMathData(token) {
    this.config.enter.data.call(this, token);
    this.config.exit.data.call(this, token);
  }
}

/**
 * Create an extension for `mdast-util-to-markdown`.
 *
 * @param {ToOptions | null | undefined} [options]
 *   Configuration.
 * @returns {ToMarkdownExtension}
 *   Extension for `mdast-util-to-markdown`.
 */
function mathToMarkdown(options) {
  let single = (options || {}).singleDollarTextMath;

  if (single === null || single === undefined) {
    single = true;
  }

  inlineMath.peek = inlineMathPeek;

  return {
    unsafe: [
      {character: '\r', inConstruct: 'mathFlowMeta'},
      {character: '\n', inConstruct: 'mathFlowMeta'},
      {
        character: '$',
        after: single ? undefined : '\\$',
        inConstruct: 'phrasing'
      },
      {character: '$', inConstruct: 'mathFlowMeta'},
      {atBreak: true, character: '$', after: '\\$'}
    ],
    handlers: {math, inlineMath}
  }

  /**
   * @type {ToMarkdownHandle}
   * @param {Math} node
   */
  // To do: next major: rename `context` to state, `safeOptions` to info.
  // Note: fixing this code? Please also fix the similar code for code:
  // <https://github.com/syntax-tree/mdast-util-to-markdown/blob/main/lib/handle/code.js>
  function math(node, _, context, safeOptions) {
    const raw = node.value || '';
    const tracker = track(safeOptions);
    const sequence = '$'.repeat(Math.max(longestStreak(raw, '$') + 1, 2));
    const exit = context.enter('mathFlow');
    let value = tracker.move(sequence);

    if (node.meta) {
      const subexit = context.enter('mathFlowMeta');
      value += tracker.move(
        safe(context, node.meta, {
          before: value,
          after: '\n',
          encode: ['$'],
          ...tracker.current()
        })
      );
      subexit();
    }

    value += tracker.move('\n');

    if (raw) {
      value += tracker.move(raw + '\n');
    }

    value += tracker.move(sequence);
    exit();
    return value
  }

  /**
   * @type {ToMarkdownHandle}
   * @param {InlineMath} node
   */
  // Note: fixing this code? Please also fix the similar code for inline code:
  // <https://github.com/syntax-tree/mdast-util-to-markdown/blob/main/lib/handle/inline-code.js>
  //
  // To do: next major: rename `context` to state.
  // To do: next major: use `state` (`safe`, `track`, `patternCompile`).
  function inlineMath(node, _, context) {
    let value = node.value || '';
    let size = 1;

    if (!single) size++;

    // If there is a single dollar sign on its own in the math, use a fence of
    // two.
    // If there are two in a row, use one.
    while (
      new RegExp('(^|[^$])' + '\\$'.repeat(size) + '([^$]|$)').test(value)
    ) {
      size++;
    }

    const sequence = '$'.repeat(size);

    // If this is not just spaces or eols (tabs don‚Äôt count), and either the
    // first and last character are a space or eol, or the first or last
    // character are dollar signs, then pad with spaces.
    if (
      // Contains non-space.
      /[^ \r\n]/.test(value) &&
      // Starts with space and ends with space.
      ((/^[ \r\n]/.test(value) && /[ \r\n]$/.test(value)) ||
        // Starts or ends with dollar.
        /^\$|\$$/.test(value))
    ) {
      value = ' ' + value + ' ';
    }

    let index = -1;

    // We have a potential problem: certain characters after eols could result in
    // blocks being seen.
    // For example, if someone injected the string `'\n# b'`, then that would
    // result in an ATX heading.
    // We can‚Äôt escape characters in `inlineMath`, but because eols are
    // transformed to spaces when going from markdown to HTML anyway, we can swap
    // them out.
    while (++index < context.unsafe.length) {
      const pattern = context.unsafe[index];
      const expression = patternCompile(pattern);
      /** @type {RegExpExecArray | null} */
      let match;

      // Only look for `atBreak`s.
      // Btw: note that `atBreak` patterns will always start the regex at LF or
      // CR.
      if (!pattern.atBreak) continue

      while ((match = expression.exec(value))) {
        let position = match.index;

        // Support CRLF (patterns only look for one of the characters).
        if (
          value.codePointAt(position) === 10 /* `\n` */ &&
          value.codePointAt(position - 1) === 13 /* `\r` */
        ) {
          position--;
        }

        value = value.slice(0, position) + ' ' + value.slice(match.index + 1);
      }
    }

    return sequence + value + sequence
  }

  /**
   * @returns {string}
   */
  function inlineMathPeek() {
    return '$'
  }
}

/**
 * @typedef {import('mdast').Root} Root
 * @typedef {import('mdast-util-math').ToOptions} Options
 *
 * @typedef {import('mdast-util-math')} DoNotTouchAsThisImportIncludesMathInTree
 */

/**
 * Plugin to support math.
 *
 * @type {import('unified').Plugin<[Options?] | void[], Root, Root>}
 */
function remarkMath(options = {}) {
  const data = this.data();

  add('micromarkExtensions', math(options));
  add('fromMarkdownExtensions', mathFromMarkdown());
  add('toMarkdownExtensions', mathToMarkdown(options));

  /**
   * @param {string} field
   * @param {unknown} value
   */
  function add(field, value) {
    const list = /** @type {unknown[]} */ (
      // Other extensions
      /* c8 ignore next 2 */
      data[field] ? data[field] : (data[field] = [])
    );

    list.push(value);
  }
}

/**
 * @typedef {import('hast').Element} Element
 * @typedef {import('mdast').Blockquote} Blockquote
 * @typedef {import('../state.js').State} State
 */

/**
 * Turn an mdast `blockquote` node into hast.
 *
 * @param {State} state
 *   Info passed around.
 * @param {Blockquote} node
 *   mdast node.
 * @returns {Element}
 *   hast node.
 */
function blockquote(state, node) {
  /** @type {Element} */
  const result = {
    type: 'element',
    tagName: 'blockquote',
    properties: {},
    children: state.wrap(state.all(node), true)
  };
  state.patch(node, result);
  return state.applyData(node, result)
}

/**
 * @typedef {import('hast').Element} Element
 * @typedef {import('hast').Text} Text
 * @typedef {import('mdast').Break} Break
 * @typedef {import('../state.js').State} State
 */

/**
 * Turn an mdast `break` node into hast.
 *
 * @param {State} state
 *   Info passed around.
 * @param {Break} node
 *   mdast node.
 * @returns {Array<Element | Text>}
 *   hast element content.
 */
function hardBreak(state, node) {
  /** @type {Element} */
  const result = {type: 'element', tagName: 'br', properties: {}, children: []};
  state.patch(node, result);
  return [state.applyData(node, result), {type: 'text', value: '\n'}]
}

/**
 * @typedef {import('hast').Element} Element
 * @typedef {import('hast').Properties} Properties
 * @typedef {import('mdast').Code} Code
 * @typedef {import('../state.js').State} State

 */

/**
 * Turn an mdast `code` node into hast.
 *
 * @param {State} state
 *   Info passed around.
 * @param {Code} node
 *   mdast node.
 * @returns {Element}
 *   hast node.
 */
function code(state, node) {
  const value = node.value ? node.value + '\n' : '';
  // To do: next major, use `node.lang` w/o regex, the splitting‚Äôs been going
  // on for years in remark now.
  const lang = node.lang ? node.lang.match(/^[^ \t]+(?=[ \t]|$)/) : null;
  /** @type {Properties} */
  const properties = {};

  if (lang) {
    properties.className = ['language-' + lang];
  }

  // Create `<code>`.
  /** @type {Element} */
  let result = {
    type: 'element',
    tagName: 'code',
    properties,
    children: [{type: 'text', value}]
  };

  if (node.meta) {
    result.data = {meta: node.meta};
  }

  state.patch(node, result);
  result = state.applyData(node, result);

  // Create `<pre>`.
  result = {type: 'element', tagName: 'pre', properties: {}, children: [result]};
  state.patch(node, result);
  return result
}

/**
 * @typedef {import('hast').Element} Element
 * @typedef {import('mdast').Delete} Delete
 * @typedef {import('../state.js').State} State

 */

/**
 * Turn an mdast `delete` node into hast.
 *
 * @param {State} state
 *   Info passed around.
 * @param {Delete} node
 *   mdast node.
 * @returns {Element}
 *   hast node.
 */
function strikethrough(state, node) {
  /** @type {Element} */
  const result = {
    type: 'element',
    tagName: 'del',
    properties: {},
    children: state.all(node)
  };
  state.patch(node, result);
  return state.applyData(node, result)
}

/**
 * @typedef {import('hast').Element} Element
 * @typedef {import('mdast').Emphasis} Emphasis
 * @typedef {import('../state.js').State} State
 */

/**
 * Turn an mdast `emphasis` node into hast.
 *
 * @param {State} state
 *   Info passed around.
 * @param {Emphasis} node
 *   mdast node.
 * @returns {Element}
 *   hast node.
 */
function emphasis(state, node) {
  /** @type {Element} */
  const result = {
    type: 'element',
    tagName: 'em',
    properties: {},
    children: state.all(node)
  };
  state.patch(node, result);
  return state.applyData(node, result)
}

/**
 * @typedef {import('mdast').FootnoteReference} FootnoteReference
 * @typedef {import('hast').Element} Element
 * @typedef {import('../state.js').State} State
 */

/**
 * Turn an mdast `footnoteReference` node into hast.
 *
 * @param {State} state
 *   Info passed around.
 * @param {FootnoteReference} node
 *   mdast node.
 * @returns {Element}
 *   hast node.
 */
function footnoteReference(state, node) {
  const id = String(node.identifier).toUpperCase();
  const safeId = normalizeUri(id.toLowerCase());
  const index = state.footnoteOrder.indexOf(id);
  /** @type {number} */
  let counter;

  if (index === -1) {
    state.footnoteOrder.push(id);
    state.footnoteCounts[id] = 1;
    counter = state.footnoteOrder.length;
  } else {
    state.footnoteCounts[id]++;
    counter = index + 1;
  }

  const reuseCounter = state.footnoteCounts[id];

  /** @type {Element} */
  const link = {
    type: 'element',
    tagName: 'a',
    properties: {
      href: '#' + state.clobberPrefix + 'fn-' + safeId,
      id:
        state.clobberPrefix +
        'fnref-' +
        safeId +
        (reuseCounter > 1 ? '-' + reuseCounter : ''),
      dataFootnoteRef: true,
      ariaDescribedBy: ['footnote-label']
    },
    children: [{type: 'text', value: String(counter)}]
  };
  state.patch(node, link);

  /** @type {Element} */
  const sup = {
    type: 'element',
    tagName: 'sup',
    properties: {},
    children: [link]
  };
  state.patch(node, sup);
  return state.applyData(node, sup)
}

/**
 * @typedef {import('hast').Element} Element
 * @typedef {import('mdast').Footnote} Footnote
 * @typedef {import('../state.js').State} State
 */

// To do: when both:
// * <https://github.com/micromark/micromark-extension-footnote>
// * <https://github.com/syntax-tree/mdast-util-footnote>
// ‚Ä¶are archived, remove this (also from mdast).
// These inline notes are not used in GFM.

/**
 * Turn an mdast `footnote` node into hast.
 *
 * @param {State} state
 *   Info passed around.
 * @param {Footnote} node
 *   mdast node.
 * @returns {Element}
 *   hast node.
 */
function footnote(state, node) {
  const footnoteById = state.footnoteById;
  let no = 1;

  while (no in footnoteById) no++;

  const identifier = String(no);

  footnoteById[identifier] = {
    type: 'footnoteDefinition',
    identifier,
    children: [{type: 'paragraph', children: node.children}],
    position: node.position
  };

  return footnoteReference(state, {
    type: 'footnoteReference',
    identifier,
    position: node.position
  })
}

/**
 * @typedef {import('hast').Element} Element
 * @typedef {import('mdast').Heading} Heading
 * @typedef {import('../state.js').State} State
 */

/**
 * Turn an mdast `heading` node into hast.
 *
 * @param {State} state
 *   Info passed around.
 * @param {Heading} node
 *   mdast node.
 * @returns {Element}
 *   hast node.
 */
function heading(state, node) {
  /** @type {Element} */
  const result = {
    type: 'element',
    tagName: 'h' + node.depth,
    properties: {},
    children: state.all(node)
  };
  state.patch(node, result);
  return state.applyData(node, result)
}

/**
 * @typedef {import('hast').Element} Element
 * @typedef {import('mdast').HTML} Html
 * @typedef {import('../state.js').State} State
 * @typedef {import('../../index.js').Raw} Raw
 */

/**
 * Turn an mdast `html` node into hast (`raw` node in dangerous mode, otherwise
 * nothing).
 *
 * @param {State} state
 *   Info passed around.
 * @param {Html} node
 *   mdast node.
 * @returns {Raw | Element | null}
 *   hast node.
 */
function html(state, node) {
  if (state.dangerous) {
    /** @type {Raw} */
    const result = {type: 'raw', value: node.value};
    state.patch(node, result);
    return state.applyData(node, result)
  }

  // To do: next major: return `undefined`.
  return null
}

/**
 * @typedef {import('hast').ElementContent} ElementContent
 *
 * @typedef {import('mdast').Content} Content
 * @typedef {import('mdast').Reference} Reference
 * @typedef {import('mdast').Root} Root
 *
 * @typedef {import('./state.js').State} State
 */

/**
 * @typedef {Root | Content} Nodes
 * @typedef {Extract<Nodes, Reference>} References
 */

// To do: next major: always return array.

/**
 * Return the content of a reference without definition as plain text.
 *
 * @param {State} state
 *   Info passed around.
 * @param {References} node
 *   Reference node (image, link).
 * @returns {ElementContent | Array<ElementContent>}
 *   hast content.
 */
function revert(state, node) {
  const subtype = node.referenceType;
  let suffix = ']';

  if (subtype === 'collapsed') {
    suffix += '[]';
  } else if (subtype === 'full') {
    suffix += '[' + (node.label || node.identifier) + ']';
  }

  if (node.type === 'imageReference') {
    return {type: 'text', value: '![' + node.alt + suffix}
  }

  const contents = state.all(node);
  const head = contents[0];

  if (head && head.type === 'text') {
    head.value = '[' + head.value;
  } else {
    contents.unshift({type: 'text', value: '['});
  }

  const tail = contents[contents.length - 1];

  if (tail && tail.type === 'text') {
    tail.value += suffix;
  } else {
    contents.push({type: 'text', value: suffix});
  }

  return contents
}

/**
 * @typedef {import('hast').ElementContent} ElementContent
 * @typedef {import('hast').Element} Element
 * @typedef {import('hast').Properties} Properties
 * @typedef {import('mdast').ImageReference} ImageReference
 * @typedef {import('../state.js').State} State
 */

/**
 * Turn an mdast `imageReference` node into hast.
 *
 * @param {State} state
 *   Info passed around.
 * @param {ImageReference} node
 *   mdast node.
 * @returns {ElementContent | Array<ElementContent>}
 *   hast node.
 */
function imageReference(state, node) {
  const def = state.definition(node.identifier);

  if (!def) {
    return revert(state, node)
  }

  /** @type {Properties} */
  const properties = {src: normalizeUri(def.url || ''), alt: node.alt};

  if (def.title !== null && def.title !== undefined) {
    properties.title = def.title;
  }

  /** @type {Element} */
  const result = {type: 'element', tagName: 'img', properties, children: []};
  state.patch(node, result);
  return state.applyData(node, result)
}

/**
 * @typedef {import('hast').Element} Element
 * @typedef {import('hast').Properties} Properties
 * @typedef {import('mdast').Image} Image
 * @typedef {import('../state.js').State} State
 */

/**
 * Turn an mdast `image` node into hast.
 *
 * @param {State} state
 *   Info passed around.
 * @param {Image} node
 *   mdast node.
 * @returns {Element}
 *   hast node.
 */
function image(state, node) {
  /** @type {Properties} */
  const properties = {src: normalizeUri(node.url)};

  if (node.alt !== null && node.alt !== undefined) {
    properties.alt = node.alt;
  }

  if (node.title !== null && node.title !== undefined) {
    properties.title = node.title;
  }

  /** @type {Element} */
  const result = {type: 'element', tagName: 'img', properties, children: []};
  state.patch(node, result);
  return state.applyData(node, result)
}

/**
 * @typedef {import('hast').Element} Element
 * @typedef {import('hast').Text} Text
 * @typedef {import('mdast').InlineCode} InlineCode
 * @typedef {import('../state.js').State} State
 */

/**
 * Turn an mdast `inlineCode` node into hast.
 *
 * @param {State} state
 *   Info passed around.
 * @param {InlineCode} node
 *   mdast node.
 * @returns {Element}
 *   hast node.
 */
function inlineCode(state, node) {
  /** @type {Text} */
  const text = {type: 'text', value: node.value.replace(/\r?\n|\r/g, ' ')};
  state.patch(node, text);

  /** @type {Element} */
  const result = {
    type: 'element',
    tagName: 'code',
    properties: {},
    children: [text]
  };
  state.patch(node, result);
  return state.applyData(node, result)
}

/**
 * @typedef {import('hast').Element} Element
 * @typedef {import('hast').ElementContent} ElementContent
 * @typedef {import('hast').Properties} Properties
 * @typedef {import('mdast').LinkReference} LinkReference
 * @typedef {import('../state.js').State} State
 */

/**
 * Turn an mdast `linkReference` node into hast.
 *
 * @param {State} state
 *   Info passed around.
 * @param {LinkReference} node
 *   mdast node.
 * @returns {ElementContent | Array<ElementContent>}
 *   hast node.
 */
function linkReference(state, node) {
  const def = state.definition(node.identifier);

  if (!def) {
    return revert(state, node)
  }

  /** @type {Properties} */
  const properties = {href: normalizeUri(def.url || '')};

  if (def.title !== null && def.title !== undefined) {
    properties.title = def.title;
  }

  /** @type {Element} */
  const result = {
    type: 'element',
    tagName: 'a',
    properties,
    children: state.all(node)
  };
  state.patch(node, result);
  return state.applyData(node, result)
}

/**
 * @typedef {import('hast').Element} Element
 * @typedef {import('hast').Properties} Properties
 * @typedef {import('mdast').Link} Link
 * @typedef {import('../state.js').State} State
 */

/**
 * Turn an mdast `link` node into hast.
 *
 * @param {State} state
 *   Info passed around.
 * @param {Link} node
 *   mdast node.
 * @returns {Element}
 *   hast node.
 */
function link(state, node) {
  /** @type {Properties} */
  const properties = {href: normalizeUri(node.url)};

  if (node.title !== null && node.title !== undefined) {
    properties.title = node.title;
  }

  /** @type {Element} */
  const result = {
    type: 'element',
    tagName: 'a',
    properties,
    children: state.all(node)
  };
  state.patch(node, result);
  return state.applyData(node, result)
}

/**
 * @typedef {import('hast').Element} Element
 * @typedef {import('hast').ElementContent} ElementContent
 * @typedef {import('hast').Properties} Properties
 * @typedef {import('mdast').Content} Content
 * @typedef {import('mdast').ListItem} ListItem
 * @typedef {import('mdast').Parent} Parent
 * @typedef {import('mdast').Root} Root
 * @typedef {import('../state.js').State} State
 */

/**
 * @typedef {Root | Content} Nodes
 * @typedef {Extract<Nodes, Parent>} Parents
 */

/**
 * Turn an mdast `listItem` node into hast.
 *
 * @param {State} state
 *   Info passed around.
 * @param {ListItem} node
 *   mdast node.
 * @param {Parents | null | undefined} parent
 *   Parent of `node`.
 * @returns {Element}
 *   hast node.
 */
function listItem(state, node, parent) {
  const results = state.all(node);
  const loose = parent ? listLoose(parent) : listItemLoose(node);
  /** @type {Properties} */
  const properties = {};
  /** @type {Array<ElementContent>} */
  const children = [];

  if (typeof node.checked === 'boolean') {
    const head = results[0];
    /** @type {Element} */
    let paragraph;

    if (head && head.type === 'element' && head.tagName === 'p') {
      paragraph = head;
    } else {
      paragraph = {type: 'element', tagName: 'p', properties: {}, children: []};
      results.unshift(paragraph);
    }

    if (paragraph.children.length > 0) {
      paragraph.children.unshift({type: 'text', value: ' '});
    }

    paragraph.children.unshift({
      type: 'element',
      tagName: 'input',
      properties: {type: 'checkbox', checked: node.checked, disabled: true},
      children: []
    });

    // According to github-markdown-css, this class hides bullet.
    // See: <https://github.com/sindresorhus/github-markdown-css>.
    properties.className = ['task-list-item'];
  }

  let index = -1;

  while (++index < results.length) {
    const child = results[index];

    // Add eols before nodes, except if this is a loose, first paragraph.
    if (
      loose ||
      index !== 0 ||
      child.type !== 'element' ||
      child.tagName !== 'p'
    ) {
      children.push({type: 'text', value: '\n'});
    }

    if (child.type === 'element' && child.tagName === 'p' && !loose) {
      children.push(...child.children);
    } else {
      children.push(child);
    }
  }

  const tail = results[results.length - 1];

  // Add a final eol.
  if (tail && (loose || tail.type !== 'element' || tail.tagName !== 'p')) {
    children.push({type: 'text', value: '\n'});
  }

  /** @type {Element} */
  const result = {type: 'element', tagName: 'li', properties, children};
  state.patch(node, result);
  return state.applyData(node, result)
}

/**
 * @param {Parents} node
 * @return {Boolean}
 */
function listLoose(node) {
  let loose = false;
  if (node.type === 'list') {
    loose = node.spread || false;
    const children = node.children;
    let index = -1;

    while (!loose && ++index < children.length) {
      loose = listItemLoose(children[index]);
    }
  }

  return loose
}

/**
 * @param {ListItem} node
 * @return {Boolean}
 */
function listItemLoose(node) {
  const spread = node.spread;

  return spread === undefined || spread === null
    ? node.children.length > 1
    : spread
}

/**
 * @typedef {import('hast').Element} Element
 * @typedef {import('hast').Properties} Properties
 * @typedef {import('mdast').List} List
 * @typedef {import('../state.js').State} State
 */

/**
 * Turn an mdast `list` node into hast.
 *
 * @param {State} state
 *   Info passed around.
 * @param {List} node
 *   mdast node.
 * @returns {Element}
 *   hast node.
 */
function list(state, node) {
  /** @type {Properties} */
  const properties = {};
  const results = state.all(node);
  let index = -1;

  if (typeof node.start === 'number' && node.start !== 1) {
    properties.start = node.start;
  }

  // Like GitHub, add a class for custom styling.
  while (++index < results.length) {
    const child = results[index];

    if (
      child.type === 'element' &&
      child.tagName === 'li' &&
      child.properties &&
      Array.isArray(child.properties.className) &&
      child.properties.className.includes('task-list-item')
    ) {
      properties.className = ['contains-task-list'];
      break
    }
  }

  /** @type {Element} */
  const result = {
    type: 'element',
    tagName: node.ordered ? 'ol' : 'ul',
    properties,
    children: state.wrap(results, true)
  };
  state.patch(node, result);
  return state.applyData(node, result)
}

/**
 * @typedef {import('hast').Element} Element
 * @typedef {import('mdast').Paragraph} Paragraph
 * @typedef {import('../state.js').State} State
 */

/**
 * Turn an mdast `paragraph` node into hast.
 *
 * @param {State} state
 *   Info passed around.
 * @param {Paragraph} node
 *   mdast node.
 * @returns {Element}
 *   hast node.
 */
function paragraph(state, node) {
  /** @type {Element} */
  const result = {
    type: 'element',
    tagName: 'p',
    properties: {},
    children: state.all(node)
  };
  state.patch(node, result);
  return state.applyData(node, result)
}

/**
 * @typedef {import('hast').Root} HastRoot
 * @typedef {import('hast').Element} HastElement
 * @typedef {import('mdast').Root} MdastRoot
 * @typedef {import('../state.js').State} State
 */

/**
 * Turn an mdast `root` node into hast.
 *
 * @param {State} state
 *   Info passed around.
 * @param {MdastRoot} node
 *   mdast node.
 * @returns {HastRoot | HastElement}
 *   hast node.
 */
function root(state, node) {
  /** @type {HastRoot} */
  const result = {type: 'root', children: state.wrap(state.all(node))};
  state.patch(node, result);
  return state.applyData(node, result)
}

/**
 * @typedef {import('hast').Element} Element
 * @typedef {import('mdast').Strong} Strong
 * @typedef {import('../state.js').State} State
 */

/**
 * Turn an mdast `strong` node into hast.
 *
 * @param {State} state
 *   Info passed around.
 * @param {Strong} node
 *   mdast node.
 * @returns {Element}
 *   hast node.
 */
function strong(state, node) {
  /** @type {Element} */
  const result = {
    type: 'element',
    tagName: 'strong',
    properties: {},
    children: state.all(node)
  };
  state.patch(node, result);
  return state.applyData(node, result)
}

/**
 * @typedef {import('unist').Position} Position
 * @typedef {import('unist').Node} Node
 * @typedef {import('unist').Point} Point
 */

/**
 * @typedef NodeLike
 * @property {string} type
 * @property {PositionLike | null | undefined} [position]
 *
 * @typedef PositionLike
 * @property {PointLike | null | undefined} [start]
 * @property {PointLike | null | undefined} [end]
 *
 * @typedef PointLike
 * @property {number | null | undefined} [line]
 * @property {number | null | undefined} [column]
 * @property {number | null | undefined} [offset]
 */

/**
 * Get the starting point of `node`.
 *
 * @param node
 *   Node.
 * @returns
 *   Point.
 */
const pointStart = point('start');

/**
 * Get the ending point of `node`.
 *
 * @param node
 *   Node.
 * @returns
 *   Point.
 */
const pointEnd = point('end');

/**
 * Get the positional info of `node`.
 *
 * @param {NodeLike | Node | null | undefined} [node]
 *   Node.
 * @returns {Position}
 *   Position.
 */
function position(node) {
  return {start: pointStart(node), end: pointEnd(node)}
}

/**
 * Get the positional info of `node`.
 *
 * @param {'start' | 'end'} type
 *   Side.
 * @returns
 *   Getter.
 */
function point(type) {
  return point

  /**
   * Get the point info of `node` at a bound side.
   *
   * @param {NodeLike | Node | null | undefined} [node]
   * @returns {Point}
   */
  function point(node) {
    const point = (node && node.position && node.position[type]) || {};

    // To do: next major: don‚Äôt return points when invalid.
    return {
      // @ts-expect-error: in practice, null is allowed.
      line: point.line || null,
      // @ts-expect-error: in practice, null is allowed.
      column: point.column || null,
      // @ts-expect-error: in practice, null is allowed.
      offset: point.offset > -1 ? point.offset : null
    }
  }
}

/**
 * @typedef {import('hast').Element} Element
 * @typedef {import('mdast').Table} Table
 * @typedef {import('../state.js').State} State
 */

/**
 * Turn an mdast `table` node into hast.
 *
 * @param {State} state
 *   Info passed around.
 * @param {Table} node
 *   mdast node.
 * @returns {Element}
 *   hast node.
 */
function table(state, node) {
  const rows = state.all(node);
  const firstRow = rows.shift();
  /** @type {Array<Element>} */
  const tableContent = [];

  if (firstRow) {
    /** @type {Element} */
    const head = {
      type: 'element',
      tagName: 'thead',
      properties: {},
      children: state.wrap([firstRow], true)
    };
    state.patch(node.children[0], head);
    tableContent.push(head);
  }

  if (rows.length > 0) {
    /** @type {Element} */
    const body = {
      type: 'element',
      tagName: 'tbody',
      properties: {},
      children: state.wrap(rows, true)
    };

    const start = pointStart(node.children[1]);
    const end = pointEnd(node.children[node.children.length - 1]);
    if (start.line && end.line) body.position = {start, end};
    tableContent.push(body);
  }

  /** @type {Element} */
  const result = {
    type: 'element',
    tagName: 'table',
    properties: {},
    children: state.wrap(tableContent, true)
  };
  state.patch(node, result);
  return state.applyData(node, result)
}

/**
 * @typedef {import('hast').Properties} Properties
 * @typedef {import('hast').Element} Element
 * @typedef {import('hast').ElementContent} ElementContent
 * @typedef {import('mdast').Content} Content
 * @typedef {import('mdast').Parent} Parent
 * @typedef {import('mdast').Root} Root
 * @typedef {import('mdast').TableRow} TableRow
 * @typedef {import('../state.js').State} State
 */

/**
 * @typedef {Root | Content} Nodes
 * @typedef {Extract<Nodes, Parent>} Parents
 */

/**
 * Turn an mdast `tableRow` node into hast.
 *
 * @param {State} state
 *   Info passed around.
 * @param {TableRow} node
 *   mdast node.
 * @param {Parents | null | undefined} parent
 *   Parent of `node`.
 * @returns {Element}
 *   hast node.
 */
function tableRow(state, node, parent) {
  const siblings = parent ? parent.children : undefined;
  // Generate a body row when without parent.
  const rowIndex = siblings ? siblings.indexOf(node) : 1;
  const tagName = rowIndex === 0 ? 'th' : 'td';
  const align = parent && parent.type === 'table' ? parent.align : undefined;
  const length = align ? align.length : node.children.length;
  let cellIndex = -1;
  /** @type {Array<ElementContent>} */
  const cells = [];

  while (++cellIndex < length) {
    // Note: can also be undefined.
    const cell = node.children[cellIndex];
    /** @type {Properties} */
    const properties = {};
    const alignValue = align ? align[cellIndex] : undefined;

    if (alignValue) {
      properties.align = alignValue;
    }

    /** @type {Element} */
    let result = {type: 'element', tagName, properties, children: []};

    if (cell) {
      result.children = state.all(cell);
      state.patch(cell, result);
      result = state.applyData(node, result);
    }

    cells.push(result);
  }

  /** @type {Element} */
  const result = {
    type: 'element',
    tagName: 'tr',
    properties: {},
    children: state.wrap(cells, true)
  };
  state.patch(node, result);
  return state.applyData(node, result)
}

/**
 * @typedef {import('hast').Element} Element
 * @typedef {import('mdast').TableCell} TableCell
 * @typedef {import('../state.js').State} State
 */

/**
 * Turn an mdast `tableCell` node into hast.
 *
 * @param {State} state
 *   Info passed around.
 * @param {TableCell} node
 *   mdast node.
 * @returns {Element}
 *   hast node.
 */
function tableCell(state, node) {
  // Note: this function is normally not called: see `table-row` for how rows
  // and their cells are compiled.
  /** @type {Element} */
  const result = {
    type: 'element',
    tagName: 'td', // Assume body cell.
    properties: {},
    children: state.all(node)
  };
  state.patch(node, result);
  return state.applyData(node, result)
}

const tab = 9; /* `\t` */
const space = 32; /* ` ` */

/**
 * Remove initial and final spaces and tabs at the line breaks in `value`.
 * Does not trim initial and final spaces and tabs of the value itself.
 *
 * @param {string} value
 *   Value to trim.
 * @returns {string}
 *   Trimmed value.
 */
function trimLines(value) {
  const source = String(value);
  const search = /\r?\n|\r/g;
  let match = search.exec(source);
  let last = 0;
  /** @type {Array<string>} */
  const lines = [];

  while (match) {
    lines.push(
      trimLine(source.slice(last, match.index), last > 0, true),
      match[0]
    );

    last = match.index + match[0].length;
    match = search.exec(source);
  }

  lines.push(trimLine(source.slice(last), last > 0, false));

  return lines.join('')
}

/**
 * @param {string} value
 *   Line to trim.
 * @param {boolean} start
 *   Whether to trim the start of the line.
 * @param {boolean} end
 *   Whether to trim the end of the line.
 * @returns {string}
 *   Trimmed line.
 */
function trimLine(value, start, end) {
  let startIndex = 0;
  let endIndex = value.length;

  if (start) {
    let code = value.codePointAt(startIndex);

    while (code === tab || code === space) {
      startIndex++;
      code = value.codePointAt(startIndex);
    }
  }

  if (end) {
    let code = value.codePointAt(endIndex - 1);

    while (code === tab || code === space) {
      endIndex--;
      code = value.codePointAt(endIndex - 1);
    }
  }

  return endIndex > startIndex ? value.slice(startIndex, endIndex) : ''
}

/**
 * @typedef {import('hast').Element} HastElement
 * @typedef {import('hast').Text} HastText
 * @typedef {import('mdast').Text} MdastText
 * @typedef {import('../state.js').State} State
 */

/**
 * Turn an mdast `text` node into hast.
 *
 * @param {State} state
 *   Info passed around.
 * @param {MdastText} node
 *   mdast node.
 * @returns {HastText | HastElement}
 *   hast node.
 */
function text(state, node) {
  /** @type {HastText} */
  const result = {type: 'text', value: trimLines(String(node.value))};
  state.patch(node, result);
  return state.applyData(node, result)
}

/**
 * @typedef {import('hast').Element} Element
 * @typedef {import('mdast').ThematicBreak} ThematicBreak
 * @typedef {import('../state.js').State} State
 */

/**
 * Turn an mdast `thematicBreak` node into hast.
 *
 * @param {State} state
 *   Info passed around.
 * @param {ThematicBreak} node
 *   mdast node.
 * @returns {Element}
 *   hast node.
 */
function thematicBreak(state, node) {
  /** @type {Element} */
  const result = {
    type: 'element',
    tagName: 'hr',
    properties: {},
    children: []
  };
  state.patch(node, result);
  return state.applyData(node, result)
}

/**
 * Default handlers for nodes.
 */
const handlers = {
  blockquote,
  break: hardBreak,
  code,
  delete: strikethrough,
  emphasis,
  footnoteReference,
  footnote,
  heading,
  html,
  imageReference,
  image,
  inlineCode,
  linkReference,
  link,
  listItem,
  list,
  paragraph,
  root,
  strong,
  table,
  tableCell,
  tableRow,
  text,
  thematicBreak,
  toml: ignore,
  yaml: ignore,
  definition: ignore,
  footnoteDefinition: ignore
};

// Return nothing for nodes that are ignored.
function ignore() {
  // To do: next major: return `undefined`.
  return null
}

/**
 * @typedef PointLike
 * @property {number | null | undefined} [line]
 * @property {number | null | undefined} [column]
 * @property {number | null | undefined} [offset]
 *
 * @typedef PositionLike
 * @property {PointLike | null | undefined} [start]
 * @property {PointLike | null | undefined} [end]
 *
 * @typedef NodeLike
 * @property {PositionLike | null | undefined} [position]
 */

/**
 * Check if `node` is generated.
 *
 * @param {NodeLike | null | undefined} [node]
 *   Node to check.
 * @returns {boolean}
 *   Whether `node` is generated (does not have positional info).
 */
function generated(node) {
  return (
    !node ||
    !node.position ||
    !node.position.start ||
    !node.position.start.line ||
    !node.position.start.column ||
    !node.position.end ||
    !node.position.end.line ||
    !node.position.end.column
  )
}

/**
 * @typedef {import('mdast').Root} Root
 * @typedef {import('mdast').Content} Content
 * @typedef {import('mdast').Definition} Definition
 */

const own$1 = {}.hasOwnProperty;

/**
 * Find definitions in `tree`.
 *
 * Uses CommonMark precedence, which means that earlier definitions are
 * preferred over duplicate later definitions.
 *
 * @param {Node} tree
 *   Tree to check.
 * @returns {GetDefinition}
 *   Getter.
 */
function definitions(tree) {
  /** @type {Record<string, Definition>} */
  const cache = Object.create(null);

  if (!tree || !tree.type) {
    throw new Error('mdast-util-definitions expected node')
  }

  visit(tree, 'definition', (definition) => {
    const id = clean(definition.identifier);
    if (id && !own$1.call(cache, id)) {
      cache[id] = definition;
    }
  });

  return definition

  /** @type {GetDefinition} */
  function definition(identifier) {
    const id = clean(identifier);
    // To do: next major: return `undefined` when not found.
    return id && own$1.call(cache, id) ? cache[id] : null
  }
}

/**
 * @param {string | null | undefined} [value]
 * @returns {string}
 */
function clean(value) {
  return String(value || '').toUpperCase()
}

/**
 * @typedef {import('hast').Content} HastContent
 * @typedef {import('hast').Element} HastElement
 * @typedef {import('hast').ElementContent} HastElementContent
 * @typedef {import('hast').Properties} HastProperties
 * @typedef {import('hast').Root} HastRoot
 * @typedef {import('hast').Text} HastText
 *
 * @typedef {import('mdast').Content} MdastContent
 * @typedef {import('mdast').Definition} MdastDefinition
 * @typedef {import('mdast').FootnoteDefinition} MdastFootnoteDefinition
 * @typedef {import('mdast').Parent} MdastParent
 * @typedef {import('mdast').Root} MdastRoot
 */

const own = {}.hasOwnProperty;

/**
 * Create `state` from an mdast tree.
 *
 * @param {MdastNodes} tree
 *   mdast node to transform.
 * @param {Options | null | undefined} [options]
 *   Configuration.
 * @returns {State}
 *   `state` function.
 */
function createState(tree, options) {
  const settings = options || {};
  const dangerous = settings.allowDangerousHtml || false;
  /** @type {Record<string, MdastFootnoteDefinition>} */
  const footnoteById = {};

  // To do: next major: add `options` to state, remove:
  // `dangerous`, `clobberPrefix`, `footnoteLabel`, `footnoteLabelTagName`,
  // `footnoteLabelProperties`, `footnoteBackLabel`, `passThrough`,
  // `unknownHandler`.

  // To do: next major: move to `state.options.allowDangerousHtml`.
  state.dangerous = dangerous;
  // To do: next major: move to `state.options`.
  state.clobberPrefix =
    settings.clobberPrefix === undefined || settings.clobberPrefix === null
      ? 'user-content-'
      : settings.clobberPrefix;
  // To do: next major: move to `state.options`.
  state.footnoteLabel = settings.footnoteLabel || 'Footnotes';
  // To do: next major: move to `state.options`.
  state.footnoteLabelTagName = settings.footnoteLabelTagName || 'h2';
  // To do: next major: move to `state.options`.
  state.footnoteLabelProperties = settings.footnoteLabelProperties || {
    className: ['sr-only']
  };
  // To do: next major: move to `state.options`.
  state.footnoteBackLabel = settings.footnoteBackLabel || 'Back to content';
  // To do: next major: move to `state.options`.
  state.unknownHandler = settings.unknownHandler;
  // To do: next major: move to `state.options`.
  state.passThrough = settings.passThrough;

  state.handlers = {...handlers, ...settings.handlers};

  // To do: next major: replace utility with `definitionById` object, so we
  // only walk once (as we need footnotes too).
  state.definition = definitions(tree);
  state.footnoteById = footnoteById;
  /** @type {Array<string>} */
  state.footnoteOrder = [];
  /** @type {Record<string, number>} */
  state.footnoteCounts = {};

  state.patch = patch;
  state.applyData = applyData;
  state.one = oneBound;
  state.all = allBound;
  state.wrap = wrap;
  // To do: next major: remove `augment`.
  state.augment = augment;

  visit(tree, 'footnoteDefinition', (definition) => {
    const id = String(definition.identifier).toUpperCase();

    // Mimick CM behavior of link definitions.
    // See: <https://github.com/syntax-tree/mdast-util-definitions/blob/8290999/index.js#L26>.
    if (!own.call(footnoteById, id)) {
      footnoteById[id] = definition;
    }
  });

  // @ts-expect-error Hush, it‚Äôs fine!
  return state

  /**
   * Finalise the created `right`, a hast node, from `left`, an mdast node.
   *
   * @param {MdastNodeWithData | PositionLike | null | undefined} left
   * @param {HastElementContent} right
   * @returns {HastElementContent}
   */
  /* c8 ignore start */
  // To do: next major: remove.
  function augment(left, right) {
    // Handle `data.hName`, `data.hProperties, `data.hChildren`.
    if (left && 'data' in left && left.data) {
      /** @type {MdastData} */
      const data = left.data;

      if (data.hName) {
        if (right.type !== 'element') {
          right = {
            type: 'element',
            tagName: '',
            properties: {},
            children: []
          };
        }

        right.tagName = data.hName;
      }

      if (right.type === 'element' && data.hProperties) {
        right.properties = {...right.properties, ...data.hProperties};
      }

      if ('children' in right && right.children && data.hChildren) {
        right.children = data.hChildren;
      }
    }

    if (left) {
      const ctx = 'type' in left ? left : {position: left};

      if (!generated(ctx)) {
        // @ts-expect-error: fine.
        right.position = {start: pointStart(ctx), end: pointEnd(ctx)};
      }
    }

    return right
  }
  /* c8 ignore stop */

  /**
   * Create an element for `node`.
   *
   * @type {HFunctionProps}
   */
  /* c8 ignore start */
  // To do: next major: remove.
  function state(node, tagName, props, children) {
    if (Array.isArray(props)) {
      children = props;
      props = {};
    }

    // @ts-expect-error augmenting an element yields an element.
    return augment(node, {
      type: 'element',
      tagName,
      properties: props || {},
      children: children || []
    })
  }
  /* c8 ignore stop */

  /**
   * Transform an mdast node into a hast node.
   *
   * @param {MdastNodes} node
   *   mdast node.
   * @param {MdastParents | null | undefined} [parent]
   *   Parent of `node`.
   * @returns {HastElementContent | Array<HastElementContent> | null | undefined}
   *   Resulting hast node.
   */
  function oneBound(node, parent) {
    // @ts-expect-error: that‚Äôs a state :)
    return one(state, node, parent)
  }

  /**
   * Transform the children of an mdast node into hast nodes.
   *
   * @param {MdastNodes} parent
   *   mdast node to compile
   * @returns {Array<HastElementContent>}
   *   Resulting hast nodes.
   */
  function allBound(parent) {
    // @ts-expect-error: that‚Äôs a state :)
    return all(state, parent)
  }
}

/**
 * Copy a node‚Äôs positional info.
 *
 * @param {MdastNodes} from
 *   mdast node to copy from.
 * @param {HastNodes} to
 *   hast node to copy into.
 * @returns {void}
 *   Nothing.
 */
function patch(from, to) {
  if (from.position) to.position = position(from);
}

/**
 * Honor the `data` of `from` and maybe generate an element instead of `to`.
 *
 * @template {HastNodes} Type
 *   Node type.
 * @param {MdastNodes} from
 *   mdast node to use data from.
 * @param {Type} to
 *   hast node to change.
 * @returns {Type | HastElement}
 *   Nothing.
 */
function applyData(from, to) {
  /** @type {Type | HastElement} */
  let result = to;

  // Handle `data.hName`, `data.hProperties, `data.hChildren`.
  if (from && from.data) {
    const hName = from.data.hName;
    const hChildren = from.data.hChildren;
    const hProperties = from.data.hProperties;

    if (typeof hName === 'string') {
      // Transforming the node resulted in an element with a different name
      // than wanted:
      if (result.type === 'element') {
        result.tagName = hName;
      }
      // Transforming the node resulted in a non-element, which happens for
      // raw, text, and root nodes (unless custom handlers are passed).
      // The intent is likely to keep the content around (otherwise: pass
      // `hChildren`).
      else {
        result = {
          type: 'element',
          tagName: hName,
          properties: {},
          children: []
        };

        // To do: next major: take the children from the `root`, or inject the
        // raw/text/comment or so into the element?
        // if ('children' in node) {
        //   // @ts-expect-error: assume `children` are allowed in elements.
        //   result.children = node.children
        // } else {
        //   // @ts-expect-error: assume `node` is allowed in elements.
        //   result.children.push(node)
        // }
      }
    }

    if (result.type === 'element' && hProperties) {
      result.properties = {...result.properties, ...hProperties};
    }

    if (
      'children' in result &&
      result.children &&
      hChildren !== null &&
      hChildren !== undefined
    ) {
      // @ts-expect-error: assume valid children are defined.
      result.children = hChildren;
    }
  }

  return result
}

/**
 * Transform an mdast node into a hast node.
 *
 * @param {State} state
 *   Info passed around.
 * @param {MdastNodes} node
 *   mdast node.
 * @param {MdastParents | null | undefined} [parent]
 *   Parent of `node`.
 * @returns {HastElementContent | Array<HastElementContent> | null | undefined}
 *   Resulting hast node.
 */
// To do: next major: do not expose, keep bound.
function one(state, node, parent) {
  const type = node && node.type;

  // Fail on non-nodes.
  if (!type) {
    throw new Error('Expected node, got `' + node + '`')
  }

  if (own.call(state.handlers, type)) {
    return state.handlers[type](state, node, parent)
  }

  if (state.passThrough && state.passThrough.includes(type)) {
    // To do: next major: deep clone.
    // @ts-expect-error: types of passed through nodes are expected to be added manually.
    return 'children' in node ? {...node, children: all(state, node)} : node
  }

  if (state.unknownHandler) {
    return state.unknownHandler(state, node, parent)
  }

  return defaultUnknownHandler(state, node)
}

/**
 * Transform the children of an mdast node into hast nodes.
 *
 * @param {State} state
 *   Info passed around.
 * @param {MdastNodes} parent
 *   mdast node to compile
 * @returns {Array<HastElementContent>}
 *   Resulting hast nodes.
 */
// To do: next major: do not expose, keep bound.
function all(state, parent) {
  /** @type {Array<HastElementContent>} */
  const values = [];

  if ('children' in parent) {
    const nodes = parent.children;
    let index = -1;
    while (++index < nodes.length) {
      const result = one(state, nodes[index], parent);

      // To do: see if we van clean this? Can we merge texts?
      if (result) {
        if (index && nodes[index - 1].type === 'break') {
          if (!Array.isArray(result) && result.type === 'text') {
            result.value = result.value.replace(/^\s+/, '');
          }

          if (!Array.isArray(result) && result.type === 'element') {
            const head = result.children[0];

            if (head && head.type === 'text') {
              head.value = head.value.replace(/^\s+/, '');
            }
          }
        }

        if (Array.isArray(result)) {
          values.push(...result);
        } else {
          values.push(result);
        }
      }
    }
  }

  return values
}

/**
 * Transform an unknown node.
 *
 * @param {State} state
 *   Info passed around.
 * @param {MdastNodes} node
 *   Unknown mdast node.
 * @returns {HastText | HastElement}
 *   Resulting hast node.
 */
function defaultUnknownHandler(state, node) {
  const data = node.data || {};
  /** @type {HastText | HastElement} */
  const result =
    'value' in node &&
    !(own.call(data, 'hProperties') || own.call(data, 'hChildren'))
      ? {type: 'text', value: node.value}
      : {
          type: 'element',
          tagName: 'div',
          properties: {},
          children: all(state, node)
        };

  state.patch(node, result);
  return state.applyData(node, result)
}

/**
 * Wrap `nodes` with line endings between each node.
 *
 * @template {HastContent} Type
 *   Node type.
 * @param {Array<Type>} nodes
 *   List of nodes to wrap.
 * @param {boolean | null | undefined} [loose=false]
 *   Whether to add line endings at start and end.
 * @returns {Array<Type | HastText>}
 *   Wrapped nodes.
 */
function wrap(nodes, loose) {
  /** @type {Array<Type | HastText>} */
  const result = [];
  let index = -1;

  if (loose) {
    result.push({type: 'text', value: '\n'});
  }

  while (++index < nodes.length) {
    if (index) result.push({type: 'text', value: '\n'});
    result.push(nodes[index]);
  }

  if (loose && nodes.length > 0) {
    result.push({type: 'text', value: '\n'});
  }

  return result
}

/**
 * @typedef {import('hast').Element} Element
 * @typedef {import('hast').ElementContent} ElementContent
 *
 * @typedef {import('./state.js').State} State
 */

/**
 * Generate a hast footer for called footnote definitions.
 *
 * @param {State} state
 *   Info passed around.
 * @returns {Element | undefined}
 *   `section` element or `undefined`.
 */
function footer(state) {
  /** @type {Array<ElementContent>} */
  const listItems = [];
  let index = -1;

  while (++index < state.footnoteOrder.length) {
    const def = state.footnoteById[state.footnoteOrder[index]];

    if (!def) {
      continue
    }

    const content = state.all(def);
    const id = String(def.identifier).toUpperCase();
    const safeId = normalizeUri(id.toLowerCase());
    let referenceIndex = 0;
    /** @type {Array<ElementContent>} */
    const backReferences = [];

    while (++referenceIndex <= state.footnoteCounts[id]) {
      /** @type {Element} */
      const backReference = {
        type: 'element',
        tagName: 'a',
        properties: {
          href:
            '#' +
            state.clobberPrefix +
            'fnref-' +
            safeId +
            (referenceIndex > 1 ? '-' + referenceIndex : ''),
          dataFootnoteBackref: true,
          className: ['data-footnote-backref'],
          ariaLabel: state.footnoteBackLabel
        },
        children: [{type: 'text', value: '‚Ü©'}]
      };

      if (referenceIndex > 1) {
        backReference.children.push({
          type: 'element',
          tagName: 'sup',
          children: [{type: 'text', value: String(referenceIndex)}]
        });
      }

      if (backReferences.length > 0) {
        backReferences.push({type: 'text', value: ' '});
      }

      backReferences.push(backReference);
    }

    const tail = content[content.length - 1];

    if (tail && tail.type === 'element' && tail.tagName === 'p') {
      const tailTail = tail.children[tail.children.length - 1];
      if (tailTail && tailTail.type === 'text') {
        tailTail.value += ' ';
      } else {
        tail.children.push({type: 'text', value: ' '});
      }

      tail.children.push(...backReferences);
    } else {
      content.push(...backReferences);
    }

    /** @type {Element} */
    const listItem = {
      type: 'element',
      tagName: 'li',
      properties: {id: state.clobberPrefix + 'fn-' + safeId},
      children: state.wrap(content, true)
    };

    state.patch(def, listItem);

    listItems.push(listItem);
  }

  if (listItems.length === 0) {
    return
  }

  return {
    type: 'element',
    tagName: 'section',
    properties: {dataFootnotes: true, className: ['footnotes']},
    children: [
      {
        type: 'element',
        tagName: state.footnoteLabelTagName,
        properties: {
          // To do: use structured clone.
          ...JSON.parse(JSON.stringify(state.footnoteLabelProperties)),
          id: 'footnote-label'
        },
        children: [{type: 'text', value: state.footnoteLabel}]
      },
      {type: 'text', value: '\n'},
      {
        type: 'element',
        tagName: 'ol',
        properties: {},
        children: state.wrap(listItems, true)
      },
      {type: 'text', value: '\n'}
    ]
  }
}

/**
 * @typedef {import('hast').Content} HastContent
 * @typedef {import('hast').Root} HastRoot
 *
 * @typedef {import('mdast').Content} MdastContent
 * @typedef {import('mdast').Root} MdastRoot
 *
 * @typedef {import('./state.js').Options} Options
 */

/**
 * Transform mdast to hast.
 *
 * ##### Notes
 *
 * ###### HTML
 *
 * Raw HTML is available in mdast as `html` nodes and can be embedded in hast
 * as semistandard `raw` nodes.
 * Most utilities ignore `raw` nodes but two notable ones don‚Äôt:
 *
 * *   `hast-util-to-html` also has an option `allowDangerousHtml` which will
 *     output the raw HTML.
 *     This is typically discouraged as noted by the option name but is useful
 *     if you completely trust authors
 * *   `hast-util-raw` can handle the raw embedded HTML strings by parsing them
 *     into standard hast nodes (`element`, `text`, etc).
 *     This is a heavy task as it needs a full HTML parser, but it is the only
 *     way to support untrusted content
 *
 * ###### Footnotes
 *
 * Many options supported here relate to footnotes.
 * Footnotes are not specified by CommonMark, which we follow by default.
 * They are supported by GitHub, so footnotes can be enabled in markdown with
 * `mdast-util-gfm`.
 *
 * The options `footnoteBackLabel` and `footnoteLabel` define natural language
 * that explains footnotes, which is hidden for sighted users but shown to
 * assistive technology.
 * When your page is not in English, you must define translated values.
 *
 * Back references use ARIA attributes, but the section label itself uses a
 * heading that is hidden with an `sr-only` class.
 * To show it to sighted users, define different attributes in
 * `footnoteLabelProperties`.
 *
 * ###### Clobbering
 *
 * Footnotes introduces a problem, as it links footnote calls to footnote
 * definitions on the page through `id` attributes generated from user content,
 * which results in DOM clobbering.
 *
 * DOM clobbering is this:
 *
 * ```html
 * <p id=x></p>
 * <script>alert(x) // `x` now refers to the DOM `p#x` element</script>
 * ```
 *
 * Elements by their ID are made available by browsers on the `window` object,
 * which is a security risk.
 * Using a prefix solves this problem.
 *
 * More information on how to handle clobbering and the prefix is explained in
 * Example: headings (DOM clobbering) in `rehype-sanitize`.
 *
 * ###### Unknown nodes
 *
 * Unknown nodes are nodes with a type that isn‚Äôt in `handlers` or `passThrough`.
 * The default behavior for unknown nodes is:
 *
 * *   when the node has a `value` (and doesn‚Äôt have `data.hName`,
 *     `data.hProperties`, or `data.hChildren`, see later), create a hast `text`
 *     node
 * *   otherwise, create a `<div>` element (which could be changed with
 *     `data.hName`), with its children mapped from mdast to hast as well
 *
 * This behavior can be changed by passing an `unknownHandler`.
 *
 * @param {MdastNodes} tree
 *   mdast tree.
 * @param {Options | null | undefined} [options]
 *   Configuration.
 * @returns {HastNodes | null | undefined}
 *   hast tree.
 */
// To do: next major: always return a single `root`.
function toHast(tree, options) {
  const state = createState(tree, options);
  const node = state.one(tree, null);
  const foot = footer(state);

  if (foot) {
    // @ts-expect-error If there‚Äôs a footer, there were definitions, meaning block
    // content.
    // So assume `node` is a parent node.
    node.children.push({type: 'text', value: '\n'}, foot);
  }

  // To do: next major: always return root?
  return Array.isArray(node) ? {type: 'root', children: node} : node
}

/**
 * @typedef {import('hast').Root} HastRoot
 * @typedef {import('mdast').Root} MdastRoot
 * @typedef {import('mdast-util-to-hast').Options} Options
 * @typedef {import('unified').Processor<any, any, any, any>} Processor
 *
 * @typedef {import('mdast-util-to-hast')} DoNotTouchAsThisImportIncludesRawInTree
 */

// Note: the `<MdastRoot, HastRoot>` overload doesn‚Äôt seem to work :'(

/**
 * Plugin that turns markdown into HTML to support rehype.
 *
 * *   If a destination processor is given, that processor runs with a new HTML
 *     (hast) tree (bridge-mode).
 *     As the given processor runs with a hast tree, and rehype plugins support
 *     hast, that means rehype plugins can be used with the given processor.
 *     The hast tree is discarded in the end.
 *     It‚Äôs highly unlikely that you want to do this.
 * *   The common case is to not pass a destination processor, in which case the
 *     current processor continues running with a new HTML (hast) tree
 *     (mutate-mode).
 *     As the current processor continues with a hast tree, and rehype plugins
 *     support hast, that means rehype plugins can be used after
 *     `remark-rehype`.
 *     It‚Äôs likely that this is what you want to do.
 *
 * @param destination
 *   Optional unified processor.
 * @param options
 *   Options passed to `mdast-util-to-hast`.
 */
const remarkRehype =
  /** @type {(import('unified').Plugin<[Processor, Options?]|[null|undefined, Options?]|[Options]|[], MdastRoot>)} */
  (
    function (destination, options) {
      return destination && 'run' in destination
        ? bridge(destination, options)
        : mutate(destination || options)
    }
  );

var remarkRehype$1 = remarkRehype;

/**
 * Bridge-mode.
 * Runs the destination with the new hast tree.
 *
 * @type {import('unified').Plugin<[Processor, Options?], MdastRoot>}
 */
function bridge(destination, options) {
  return (node, file, next) => {
    destination.run(toHast(node, options), file, (error) => {
      next(error);
    });
  }
}

/**
 * Mutate-mode.
 * Further plugins run on the hast tree.
 *
 * @type {import('unified').Plugin<[Options?]|void[], MdastRoot, HastRoot>}
 */
function mutate(options) {
  // @ts-expect-error: assume a corresponding node is returned by `toHast`.
  return (node) => toHast(node, options)
}

const processor = unified()
  .use(remarkParse)
  .use(remarkBreaks)
  .use(remarkFrontmatter)
  .use(remarkGemoji)
  .use(remarkGfm)
  .use(remarkMath)
  .use(remarkRehype$1);

console.log(processor.parse("## hi"));

export { processor };
